# Referência da API OpenAI

## Links Rápidos

*   [Playground](https://platform.openai.com/playground)
*   [Dashboard](https://platform.openai.com/dashboard)
*   [Docs](https://platform.openai.com/docs)
*   [API reference](https://platform.openai.com/docs/api-reference) (Esta página)

## Introdução

Esta referência da API descreve as APIs RESTful, de streaming e em tempo real que você pode usar para interagir com a plataforma OpenAI. As APIs REST podem ser usadas via HTTP em qualquer ambiente que suporte solicitações HTTP. SDKs específicos de linguagem estão listados na [página de bibliotecas](https://platform.openai.com/docs/libraries).

## Autenticação

A API OpenAI usa chaves de API para autenticação. Crie, gerencie e saiba mais sobre chaves de API nas [configurações da sua organização](https://platform.openai.com/account/api-keys).

**Lembre-se que sua chave de API é um segredo!** Não a compartilhe com outros nem a exponha em qualquer código do lado do cliente (navegadores, aplicativos). As chaves de API devem ser carregadas com segurança de uma variável de ambiente ou serviço de gerenciamento de chaves no servidor.

As chaves de API devem ser fornecidas via autenticação HTTP Bearer.

```http
Authorization: Bearer SEU_OPENAI_API_KEY
```

Se você pertencer a várias organizações ou acessar projetos por meio de uma chave de API de usuário legada, passe um cabeçalho para especificar qual organização e projeto usar para uma solicitação de API:

```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: org-BT9rveT3EtJjCenbVVmA389N" \
  -H "OpenAI-Project: $PROJECT_ID"
```

O uso dessas solicitações de API conta como uso para a organização e projeto especificados. IDs de organização podem ser encontrados na sua [página de configurações da organização](https://platform.openai.com/settings/organization). IDs de projeto podem ser encontrados na sua [página de configurações gerais](https://platform.openai.com/settings/projects) selecionando o projeto específico.

## Depurando Requisições

Além dos códigos de erro retornados nas respostas da API, você pode inspecionar os cabeçalhos de resposta HTTP que contêm o ID exclusivo de uma solicitação de API específica ou informações sobre a limitação de taxa aplicada às suas solicitações. Abaixo está uma lista incompleta de cabeçalhos HTTP retornados com as respostas da API:

**Meta informações da API**

*   `openai-organization`: A organização associada à requisição
*   `openai-processing-ms`: Tempo gasto processando sua requisição de API
*   `openai-version`: Versão da API REST usada para esta requisição (atualmente 2020-10-01)
*   `x-request-id`: Identificador exclusivo para esta requisição de API (usado na solução de problemas)

**Informações de Limitação de Taxa**

*   `x-ratelimit-limit-requests`
*   `x-ratelimit-limit-tokens`
*   `x-ratelimit-remaining-requests`
*   `x-ratelimit-remaining-tokens`
*   `x-ratelimit-reset-requests`
*   `x-ratelimit-reset-tokens`

A OpenAI recomenda registrar os IDs das requisições em implantações de produção para uma solução de problemas mais eficiente com nossa equipe de suporte, caso surja a necessidade. Nossos SDKs oficiais fornecem uma propriedade nos objetos de resposta de nível superior contendo o valor do cabeçalho `x-request-id`.

## Compatibilidade Retroativa

A OpenAI está comprometida em fornecer estabilidade aos usuários da API, evitando alterações que quebrem a compatibilidade nas versões principais da API sempre que razoavelmente possível. Isso inclui:

*   A API REST (atualmente v1)
*   Nossos SDKs primários (SDKs lançados aderem ao versionamento semântico)
*   Famílias de modelos (como `gpt-4o` ou `o4-mini`)

O comportamento de prompt do modelo entre snapshots está sujeito a alterações. As saídas do modelo são, por natureza, variáveis, portanto, espere mudanças no prompt e no comportamento do modelo entre snapshots. Por exemplo, se você mudou de `gpt-4o-2024-05-13` para `gpt-4o-2024-08-06`, as mesmas mensagens de sistema ou de usuário podem funcionar de forma diferente entre as versões. A melhor maneira de garantir um comportamento de prompt consistente e saída do modelo é usar [versões de modelo fixadas](https://platform.openai.com/docs/models/model-endpoint-compatibility) e implementar [avaliações (evals)](https://platform.openai.com/docs/guides/evals) para suas aplicações.

**Alterações de API retrocompatíveis:**

*   Adição de novos recursos (URLs) à API REST e SDKs
*   Adição de novos parâmetros de API opcionais
*   Adição de novas propriedades a objetos de resposta JSON ou dados de eventos
*   Alteração da ordem das propriedades em um objeto de resposta JSON
*   Alteração do comprimento ou formato de strings opacas, como identificadores de recursos e UUIDs
*   Adição de novos tipos de eventos (seja em streaming ou na API Realtime)

Consulte o [changelog](https://platform.openai.com/docs/changelog) para obter uma lista de alterações retrocompatíveis e raras alterações que quebram a compatibilidade.

---

## Responses

A interface mais avançada da OpenAI para gerar respostas de modelo. Suporta entradas de texto e imagem, e saídas de texto. Crie interações com estado com o modelo, usando a saída de respostas anteriores como entrada. Estenda as capacidades do modelo com ferramentas integradas para pesquisa de arquivos, pesquisa na web, uso do computador e mais. Permita que o modelo acesse sistemas e dados externos usando chamadas de função.

**Guias relacionados:**

*   [Quickstart](https://platform.openai.com/docs/quickstart?context=responses)
*   [Text inputs and outputs](https://platform.openai.com/docs/guides/responses/text-inputs-and-outputs)
*   [Image inputs](https://platform.openai.com/docs/guides/responses/image-inputs)
*   [Structured Outputs](https://platform.openai.com/docs/guides/responses/structured-outputs)
*   [Function calling](https://platform.openai.com/docs/guides/responses/function-calling)
*   [Conversation state](https://platform.openai.com/docs/guides/responses/conversation-state)
*   [Extend the models with tools](https://platform.openai.com/docs/guides/responses/tools)

### Criar uma resposta do modelo

**POST** `/v1/responses`

Cria uma resposta do modelo. Forneça entradas de texto ou imagem para gerar saídas de texto ou JSON. Faça com que o modelo chame seu próprio código personalizado ou use ferramentas integradas como pesquisa na web ou pesquisa de arquivos para usar seus próprios dados como entrada para a resposta do modelo.

#### Corpo da Requisição

*   `input`: `string` ou `array` - **Obrigatório**
    *   Entradas de texto, imagem ou arquivo para o modelo, usadas para gerar uma resposta.
    *   > **Saiba mais:**
    *   > *   [Text inputs and outputs](https://platform.openai.com/docs/guides/responses/text-inputs-and-outputs)
    *   > *   [Image inputs](https://platform.openai.com/docs/guides/responses/image-inputs)
    *   > *   [File inputs](https://platform.openai.com/docs/guides/responses/file-inputs)
    *   > *   [Conversation state](https://platform.openai.com/docs/guides/responses/conversation-state)
    *   > *   [Function calling](https://platform.openai.com/docs/guides/responses/function-calling)
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `model`: `string` - **Obrigatório**
    *   ID do modelo usado para gerar a resposta, como `gpt-4o` ou `o3`. A OpenAI oferece uma ampla gama de modelos com diferentes capacidades, características de desempenho e preços. Consulte o [guia de modelos](https://platform.openai.com/docs/models) para navegar e comparar os modelos disponíveis.

*   `include`: `array` ou `null` - *Opcional*
    *   Especifique dados de saída adicionais para incluir na resposta do modelo. Valores atualmente suportados são:
        *   `file_search_call.results`: Inclui os resultados da pesquisa da chamada da ferramenta de pesquisa de arquivos.
        *   `message.input_image.image_url`: Inclui URLs de imagem da mensagem de entrada.
        *   `computer_call_output.output.image_url`: Inclui URLs de imagem da saída da chamada do computador.

*   `instructions`: `string` ou `null` - *Opcional*
    *   Insere uma mensagem de sistema (ou desenvolvedor) como o primeiro item no contexto do modelo.
    *   Ao usar junto com `previous_response_id`, as instruções de uma resposta anterior não serão transportadas para a próxima resposta. Isso simplifica a troca de mensagens de sistema (ou desenvolvedor) em novas respostas.

*   `max_output_tokens`: `integer` ou `null` - *Opcional*
    *   Um limite superior para o número de tokens que podem ser gerados para uma resposta, incluindo tokens de saída visíveis e tokens de raciocínio.

*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor que podem ser anexados a um objeto. Isso pode ser útil para armazenar informações adicionais sobre o objeto em um formato estruturado e consultar objetos via API ou pelo painel.
    *   Chaves são strings com comprimento máximo de 64 caracteres. Valores são strings com comprimento máximo de 512 caracteres.

*   `parallel_tool_calls`: `boolean` ou `null` - *Opcional* - **Padrão:** `true`
    *   Se permite que o modelo execute chamadas de ferramentas em paralelo.

*   `previous_response_id`: `string` ou `null` - *Opcional*
    *   O ID exclusivo da resposta anterior ao modelo. Use isso para criar conversas de múltiplos turnos. Saiba mais sobre o [estado da conversa](https://platform.openai.com/docs/guides/responses/conversation-state).

*   `reasoning`: `object` ou `null` - *Opcional* - *Apenas modelos da série o*
    *   Opções de configuração para modelos de raciocínio.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `service_tier`: `string` ou `null` - *Opcional* - **Padrão:** `auto`
    *   Especifica o nível de latência a ser usado para processar a requisição. Este parâmetro é relevante para clientes inscritos no serviço de nível scale:
        *   Se definido como 'auto', e o Projeto estiver habilitado para o nível Scale, o sistema utilizará créditos do nível scale até que se esgotem.
        *   Se definido como 'auto', e o Projeto não estiver habilitado para o nível Scale, a requisição será processada usando o nível de serviço padrão com um SLA de tempo de atividade mais baixo e sem garantia de latência.
        *   Se definido como 'default', a requisição será processada usando o nível de serviço padrão com um SLA de tempo de atividade mais baixo e sem garantia de latência.
        *   Se definido como 'flex', a requisição será processada com o nível de serviço Flex Processing. [Saiba mais](https://platform.openai.com/docs/guides/rate-limits/flex).
    *   Quando não definido, o comportamento padrão é 'auto'.
    *   Quando este parâmetro é definido, o corpo da resposta incluirá o `service_tier` utilizado.

*   `store`: `boolean` ou `null` - *Opcional* - **Padrão:** `true`
    *   Se armazena a resposta do modelo gerada para recuperação posterior via API.

*   `stream`: `boolean` ou `null` - *Opcional* - **Padrão:** `false`
    *   Se definido como `true`, os dados da resposta do modelo serão transmitidos para o cliente conforme são gerados usando server-sent events. Veja a seção [Streaming](#streaming) abaixo para mais informações.

*   `temperature`: `number` ou `null` - *Opcional* - **Padrão:** `1`
    *   Qual temperatura de amostragem usar, entre 0 e 2. Valores mais altos como 0.8 tornarão a saída mais aleatória, enquanto valores mais baixos como 0.2 a tornarão mais focada e determinística. Geralmente recomendamos alterar este ou `top_p`, mas não ambos.

*   `text`: `object` - *Opcional*
    *   Opções de configuração para uma resposta de texto do modelo. Pode ser texto simples ou dados JSON estruturados.
    *   > **Saiba mais:**
    *   > *   [Text inputs and outputs](https://platform.openai.com/docs/guides/responses/text-inputs-and-outputs)
    *   > *   [Structured Outputs](https://platform.openai.com/docs/guides/responses/structured-outputs)
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `tool_choice`: `string` ou `object` - *Opcional*
    *   Como o modelo deve selecionar qual(is) ferramenta(s) usar ao gerar uma resposta. Consulte o parâmetro `tools` para ver como especificar quais ferramentas o modelo pode chamar.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `tools`: `array` - *Opcional*
    *   Um array de ferramentas que o modelo pode chamar ao gerar uma resposta. Você pode especificar qual ferramenta usar definindo o parâmetro `tool_choice`.
    *   As duas categorias de ferramentas que você pode fornecer ao modelo são:
        *   **Ferramentas integradas:** Ferramentas fornecidas pela OpenAI que estendem as capacidades do modelo, como pesquisa na web ou pesquisa de arquivos. [Saiba mais sobre ferramentas integradas](https://platform.openai.com/docs/guides/responses/tools).
        *   **Chamadas de função (ferramentas personalizadas):** Funções definidas por você, permitindo que o modelo chame seu próprio código. [Saiba mais sobre chamada de função](https://platform.openai.com/docs/guides/responses/function-calling).
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `top_p`: `number` ou `null` - *Opcional* - **Padrão:** `1`
    *   Uma alternativa à amostragem com temperatura, chamada amostragem de núcleo (nucleus sampling), onde o modelo considera os resultados dos tokens com massa de probabilidade `top_p`. Assim, 0.1 significa que apenas os tokens que compõem os 10% superiores da massa de probabilidade são considerados.
    *   Geralmente recomendamos alterar este ou `temperature`, mas não ambos.

*   `truncation`: `string` ou `null` - *Opcional* - **Padrão:** `disabled`
    *   A estratégia de truncamento a ser usada para a resposta do modelo.
        *   `auto`: Se o contexto desta resposta e das anteriores exceder o tamanho da janela de contexto do modelo, o modelo truncará a resposta para caber na janela de contexto, descartando itens de entrada no meio da conversa.
        *   `disabled` (padrão): Se uma resposta do modelo exceder o tamanho da janela de contexto para um modelo, a requisição falhará com um erro 400.

*   `user`: `string` - *Opcional*
    *   Um identificador único representando seu usuário final, que pode ajudar a OpenAI a monitorar e detectar abusos. [Saiba mais](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

#### Retorna

Retorna um objeto [Response](#the-response-object).

#### Exemplos

##### Exemplo: Entrada de Texto

```bash
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "input": "Tell me a three sentence bedtime story about a unicorn."
  }'
```

```json
# Resposta
{
  "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
  "object": "response",
  "created_at": 1741476542,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1-2025-04-14",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 36,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 87,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 123
  },
  "user": null,
  "metadata": {}
}
```

> *(Nota: Exemplos para Image input, Web search, File search, Streaming, Functions, Reasoning não foram fornecidos no texto original, mas seriam colocados aqui se estivessem)*

---

### Obter uma resposta do modelo

**GET** `/v1/responses/{response_id}`

Recupera uma resposta do modelo com o ID fornecido.

#### Parâmetros de Caminho

*   `response_id`: `string` - **Obrigatório**
    *   O ID da resposta a ser recuperada.

#### Parâmetros de Consulta

*   `include`: `array` - *Opcional*
    *   Campos adicionais para incluir na resposta. Veja o parâmetro `include` para a criação de Resposta acima para mais informações.

#### Retorna

O objeto [Response](#the-response-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/responses/resp_123 \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
  "object": "response",
  "created_at": 1741386163,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4o-2024-08-06",
  "output": [
    {
      "type": "message",
      "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "Silent circuits hum,  \nThoughts emerge in data streams—  \nDigital dawn breaks.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 32,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 18,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 50
  },
  "user": null,
  "metadata": {}
}
```

---

### Excluir uma resposta do modelo

**DELETE** `/v1/responses/{response_id}`

Exclui uma resposta do modelo com o ID fornecido.

#### Parâmetros de Caminho

*   `response_id`: `string` - **Obrigatório**
    *   O ID da resposta a ser excluída.

#### Retorna

Uma mensagem de sucesso.

#### Exemplo de Requisição

```bash
curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "resp_6786a1bec27481909a17d673315b29f6",
  "object": "response",
  "deleted": true
}
```

---

### Listar itens de entrada

**GET** `/v1/responses/{response_id}/input_items`

Retorna uma lista de itens de entrada para uma determinada resposta.

#### Parâmetros de Caminho

*   `response_id`: `string` - **Obrigatório**
    *   O ID da resposta para recuperar os itens de entrada.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional*
    *   Um ID de item para listar itens depois, usado na paginação.
*   `before`: `string` - *Opcional*
    *   Um ID de item para listar itens antes, usado na paginação.
*   `include`: `array` - *Opcional*
    *   Campos adicionais para incluir na resposta. Veja o parâmetro `include` para a criação de Resposta acima para mais informações.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20`
    *   Um limite no número de objetos a serem retornados. O limite pode variar entre 1 e 100, e o padrão é 20.
*   `order`: `string` - *Opcional* - **Padrão:** `asc`
    *   A ordem para retornar os itens de entrada. O padrão é `asc`.
        *   `asc`: Retorna os itens de entrada em ordem ascendente.
        *   `desc`: Retorna os itens de entrada em ordem descendente.

#### Retorna

Uma lista de objetos de [item de entrada](#the-input-item-list).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/responses/resp_abc123/input_items \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "msg_abc123",
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Tell me a three sentence bedtime story about a unicorn."
        }
      ]
    }
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc123",
  "has_more": false
}
```

---

### O objeto Response

*   `created_at`: `number`
    *   Timestamp Unix (em segundos) de quando esta Resposta foi criada.
*   `error`: `object` ou `null`
    *   Um objeto de erro retornado quando o modelo falha ao gerar uma Resposta.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>
*   `id`: `string`
    *   Identificador único para esta Resposta.
*   `incomplete_details`: `object` ou `null`
    *   Detalhes sobre por que a resposta está incompleta.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>
*   `instructions`: `string` ou `null`
    *   Insere uma mensagem de sistema (ou desenvolvedor) como o primeiro item no contexto do modelo. (Mesma descrição da requisição)
*   `max_output_tokens`: `integer` ou `null`
    *   Um limite superior para o número de tokens que podem ser gerados para uma resposta. (Mesma descrição da requisição)
*   `metadata`: `map`
    *   Conjunto de 16 pares chave-valor que podem ser anexados a um objeto. (Mesma descrição da requisição)
*   `model`: `string`
    *   ID do modelo usado para gerar a resposta. (Mesma descrição da requisição)
*   `object`: `string`
    *   O tipo de objeto deste recurso - sempre definido como `response`.
*   `output`: `array`
    *   Um array de itens de conteúdo gerados pelo modelo.
    *   *O comprimento e a ordem dos itens no array de saída dependem da resposta do modelo.*
    *   *Em vez de acessar o primeiro item no array de saída e presumir que é uma mensagem do assistente com o conteúdo gerado pelo modelo, você pode considerar usar a propriedade `output_text` onde suportado nos SDKs.*
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>
*   `output_text`: `string` ou `null` - (*SDK Only*)
    *   Propriedade de conveniência apenas do SDK que contém a saída de texto agregada de todos os itens `output_text` no array `output`, se houver algum presente. Suportado nos SDKs Python e JavaScript.
*   `parallel_tool_calls`: `boolean`
    *   Se permite que o modelo execute chamadas de ferramentas em paralelo.
*   `previous_response_id`: `string` ou `null`
    *   O ID exclusivo da resposta anterior ao modelo. (Mesma descrição da requisição)
*   `reasoning`: `object` ou `null` - (*Apenas modelos da série o*)
    *   Opções de configuração para modelos de raciocínio.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>
*   `service_tier`: `string` ou `null`
    *   Especifica o nível de latência usado para processar a requisição. (Mesma descrição da requisição)
*   `status`: `string`
    *   O status da geração da resposta. Um de `completed`, `failed`, `in_progress` ou `incomplete`.
*   `temperature`: `number` ou `null`
    *   Qual temperatura de amostragem usar. (Mesma descrição da requisição)
*   `text`: `object`
    *   Opções de configuração para uma resposta de texto do modelo. (Mesma descrição da requisição)
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>
*   `tool_choice`: `string` ou `object`
    *   Como o modelo deve selecionar qual(is) ferramenta(s) usar. (Mesma descrição da requisição)
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>
*   `tools`: `array`
    *   Um array de ferramentas que o modelo pode chamar. (Mesma descrição da requisição)
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>
*   `top_p`: `number` ou `null`
    *   Alternativa à amostragem com temperatura (nucleus sampling). (Mesma descrição da requisição)
*   `truncation`: `string` ou `null`
    *   A estratégia de truncamento usada para a resposta do modelo. (Mesma descrição da requisição)
*   `usage`: `object`
    *   Representa detalhes de uso de tokens, incluindo tokens de entrada, tokens de saída, uma detalhamento dos tokens de saída e o total de tokens usados.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>
*   `user`: `string`
    *   Um identificador único representando seu usuário final. (Mesma descrição da requisição)

#### Objeto Response Exemplo

```json
{
  "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
  "object": "response",
  "created_at": 1741476777,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4o-2024-08-06",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 52,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 380
  },
  "user": null,
  "metadata": {}
}
```

---

### A Lista de Itens de Entrada

Uma lista de itens de Resposta.

*   `data`: `array`
    *   Uma lista de itens usados para gerar esta resposta.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>
*   `first_id`: `string`
    *   O ID do primeiro item na lista.
*   `has_more`: `boolean`
    *   Se existem mais itens disponíveis.
*   `last_id`: `string`
    *   O ID do último item na lista.
*   `object`: `string`
    *   O tipo de objeto retornado, deve ser `list`.

#### Objeto Lista de Itens de Entrada Exemplo

```json
{
  "object": "list",
  "data": [
    {
      "id": "msg_abc123",
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Tell me a three sentence bedtime story about a unicorn."
        }
      ]
    }
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc123",
  "has_more": false
}
```

---

### Streaming

Quando você cria uma Resposta com `stream` definido como `true`, o servidor emitirá eventos server-sent para o cliente enquanto a Resposta é gerada. Esta seção contém os eventos que são emitidos pelo servidor.

[Saiba mais sobre streaming de respostas](https://platform.openai.com/docs/guides/responses/streaming).

#### `response.created`

Um evento que é emitido quando uma resposta é criada.

*   `response`: `object`
    *   A resposta que foi criada.
    *   <details><summary>Mostrar propriedades</summary> (As propriedades são as mesmas do [objeto Response](#the-response-object), mas com status inicial)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.created`.

##### Objeto `response.created` Exemplo

```json
{
  "type": "response.created",
  "response": {
    "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
    "object": "response",
    "created_at": 1741487325,
    "status": "in_progress",
    "error": null,
    "incomplete_details": null,
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-2024-08-06",
    "output": [],
    "parallel_tool_calls": true,
    "previous_response_id": null,
    "reasoning": {
      "effort": null,
      "summary": null
    },
    "store": true,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": null,
    "user": null,
    "metadata": {}
  }
}
```

#### `response.in_progress`

Emitido quando a resposta está em andamento.

*   `response`: `object`
    *   A resposta que está em andamento.
    *   <details><summary>Mostrar propriedades</summary> (As propriedades são as mesmas do [objeto Response](#the-response-object), mas com status `in_progress`)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.in_progress`.

##### Objeto `response.in_progress` Exemplo

```json
{
  "type": "response.in_progress",
  "response": {
    "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
    "object": "response",
    "created_at": 1741487325,
    "status": "in_progress",
    // ... (restante das propriedades como em response.created)
    "usage": null,
    "user": null,
    "metadata": {}
  }
}
```

#### `response.completed`

Emitido quando a resposta do modelo está completa.

*   `response`: `object`
    *   Propriedades da resposta completa.
    *   <details><summary>Mostrar propriedades</summary> (As propriedades são as mesmas do [objeto Response](#the-response-object), mas com status `completed` e dados de uso)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.completed`.

##### Objeto `response.completed` Exemplo

```json
{
  "type": "response.completed",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "completed",
    "error": null,
    "incomplete_details": null,
    // "input": [], (Campo não presente no objeto Response padrão)
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-mini-2024-07-18",
    "output": [
      {
        "id": "msg_123",
        "type": "message",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
            "annotations": []
          }
        ]
      }
    ],
    "previous_response_id": null,
    // "reasoning_effort": null, (Campo não presente no objeto Response padrão, talvez `reasoning`?)
    "store": false,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": { // Note: Exemplo mostra 0, o que é incomum para uma resposta completa
      "input_tokens": 0,
      "output_tokens": 0,
      "output_tokens_details": {
        "reasoning_tokens": 0
      },
      "total_tokens": 0
    },
    "user": null,
    "metadata": {}
  }
}
```

#### `response.failed`

Um evento que é emitido quando uma resposta falha.

*   `response`: `object`
    *   A resposta que falhou.
    *   <details><summary>Mostrar propriedades</summary> (As propriedades são as mesmas do [objeto Response](#the-response-object), mas com status `failed` e um objeto `error`)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.failed`.

##### Objeto `response.failed` Exemplo

```json
{
  "type": "response.failed",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "failed",
    "error": {
      "code": "server_error",
      "message": "The model failed to generate a response."
    },
    "incomplete_details": null,
    // ... (restante das propriedades como em response.completed, mas `output` vazio e `usage` null)
    "usage": null,
    "user": null,
    "metadata": {}
  }
}
```

#### `response.incomplete`

Um evento que é emitido quando uma resposta termina como incompleta.

*   `response`: `object`
    *   A resposta que ficou incompleta.
    *   <details><summary>Mostrar propriedades</summary> (As propriedades são as mesmas do [objeto Response](#the-response-object), mas com status `incomplete` e um objeto `incomplete_details`)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.incomplete`.

##### Objeto `response.incomplete` Exemplo

```json
{
  "type": "response.incomplete",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "incomplete",
    "error": null,
    "incomplete_details": {
      "reason": "max_tokens"
    },
    // ... (restante das propriedades como em response.completed, mas `output` vazio e `usage` null)
    "usage": null,
    "user": null,
    "metadata": {}
  }
}
```

#### `response.output_item.added`

Emitido quando um novo item de saída é adicionado.

*   `item`: `object`
    *   O item de saída que foi adicionado.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original, mas geralmente é um objeto `message` ou `tool_call`)</details>
*   `output_index`: `integer`
    *   O índice do item de saída que foi adicionado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.output_item.added`.

##### Objeto `response.output_item.added` Exemplo

```json
{
  "type": "response.output_item.added",
  "output_index": 0,
  "item": {
    "id": "msg_123",
    "status": "in_progress",
    "type": "message",
    "role": "assistant",
    "content": []
  }
}
```

#### `response.output_item.done`

Emitido quando um item de saída é marcado como concluído.

*   `item`: `object`
    *   O item de saída que foi marcado como concluído.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>
*   `output_index`: `integer`
    *   O índice do item de saída que foi marcado como concluído.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.output_item.done`.

##### Objeto `response.output_item.done` Exemplo

```json
{
  "type": "response.output_item.done",
  "output_index": 0,
  "item": {
    "id": "msg_123",
    "status": "completed",
    "type": "message",
    "role": "assistant",
    "content": [
      {
        "type": "output_text",
        "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
        "annotations": []
      }
    ]
  }
}
```

#### `response.content_part.added`

Emitido quando uma nova parte de conteúdo é adicionada.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo que foi adicionada.
*   `item_id`: `string`
    *   O ID do item de saída ao qual a parte de conteúdo foi adicionada.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a parte de conteúdo foi adicionada.
*   `part`: `object`
    *   A parte de conteúdo que foi adicionada.
    *   <details><summary>Mostrar tipos possíveis</summary> (Geralmente `output_text`, `output_image`, etc.)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.content_part.added`.

##### Objeto `response.content_part.added` Exemplo

```json
{
  "type": "response.content_part.added",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "part": {
    "type": "output_text",
    "text": "",
    "annotations": []
  }
}
```

#### `response.content_part.done`

Emitido quando uma parte de conteúdo é concluída.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo que está concluída.
*   `item_id`: `string`
    *   O ID do item de saída ao qual a parte de conteúdo foi adicionada.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a parte de conteúdo foi adicionada.
*   `part`: `object`
    *   A parte de conteúdo que está concluída.
    *   <details><summary>Mostrar tipos possíveis</summary> (Geralmente `output_text`, `output_image`, etc.)</details>
*   `type`: `string`
    *   O tipo do evento. Sempre `response.content_part.done`.

##### Objeto `response.content_part.done` Exemplo

```json
{
  "type": "response.content_part.done",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "part": {
    "type": "output_text",
    "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
    "annotations": []
  }
}
```

#### `response.output_text.delta`

Emitido quando há um delta de texto adicional.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo à qual o delta de texto foi adicionado.
*   `delta`: `string`
    *   O delta de texto que foi adicionado.
*   `item_id`: `string`
    *   O ID do item de saída ao qual o delta de texto foi adicionado.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual o delta de texto foi adicionado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.output_text.delta`.

##### Objeto `response.output_text.delta` Exemplo

```json
{
  "type": "response.output_text.delta",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "delta": "In"
}
```

#### `response.output_text.annotation.added`

Emitido quando uma anotação de texto é adicionada.

*   `annotation`: `object` (Tipo específico não detalhado, mas exemplos incluem `file_citation`)
*   `annotation_index`: `integer`
    *   O índice da anotação que foi adicionada.
*   `content_index`: `integer`
    *   O índice da parte de conteúdo à qual a anotação de texto foi adicionada.
*   `item_id`: `string`
    *   O ID do item de saída ao qual a anotação de texto foi adicionada.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a anotação de texto foi adicionada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.output_text.annotation.added`.

##### Objeto `response.output_text.annotation.added` Exemplo

```json
{
  "type": "response.output_text.annotation.added",
  "item_id": "msg_abc123",
  "output_index": 1,
  "content_index": 0,
  "annotation_index": 0,
  "annotation": {
    "type": "file_citation",
    "index": 390,
    "file_id": "file-4wDz5b167pAf72nx1h9eiN",
    "filename": "dragons.pdf"
  }
}
```

#### `response.output_text.done`

Emitido quando o conteúdo de texto é finalizado.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo cujo conteúdo de texto foi finalizado.
*   `item_id`: `string`
    *   O ID do item de saída cujo conteúdo de texto foi finalizado.
*   `output_index`: `integer`
    *   O índice do item de saída cujo conteúdo de texto foi finalizado.
*   `text`: `string`
    *   O conteúdo de texto que foi finalizado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.output_text.done`.

##### Objeto `response.output_text.done` Exemplo

```json
{
  "type": "response.output_text.done",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic."
}
```

#### `response.refusal.delta`

Emitido quando há um texto parcial de recusa.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo à qual o texto de recusa é adicionado.
*   `delta`: `string`
    *   O texto de recusa que é adicionado.
*   `item_id`: `string`
    *   O ID do item de saída ao qual o texto de recusa é adicionado.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual o texto de recusa é adicionado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.refusal.delta`.

##### Objeto `response.refusal.delta` Exemplo

```json
{
  "type": "response.refusal.delta",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "delta": "refusal text so far"
}
```

#### `response.refusal.done`

Emitido quando o texto de recusa é finalizado.

*   `content_index`: `integer`
    *   O índice da parte de conteúdo cujo texto de recusa foi finalizado.
*   `item_id`: `string`
    *   O ID do item de saída cujo texto de recusa foi finalizado.
*   `output_index`: `integer`
    *   O índice do item de saída cujo texto de recusa foi finalizado.
*   `refusal`: `string`
    *   O texto de recusa que foi finalizado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.refusal.done`.

##### Objeto `response.refusal.done` Exemplo

```json
{
  "type": "response.refusal.done",
  "item_id": "item-abc",
  "output_index": 1,
  "content_index": 2,
  "refusal": "final refusal text"
}
```

#### `response.function_call_arguments.delta`

Emitido quando há um delta parcial dos argumentos da chamada de função.

*   `delta`: `string`
    *   O delta dos argumentos da chamada de função que é adicionado.
*   `item_id`: `string`
    *   O ID do item de saída ao qual o delta dos argumentos da chamada de função é adicionado.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual o delta dos argumentos da chamada de função é adicionado.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.function_call_arguments.delta`.

##### Objeto `response.function_call_arguments.delta` Exemplo

```json
{
  "type": "response.function_call_arguments.delta",
  "item_id": "item-abc",
  "output_index": 0,
  "delta": "{ \"arg\":"
}
```

#### `response.function_call_arguments.done`

Emitido quando os argumentos da chamada de função são finalizados.

*   `arguments`: `string`
    *   Os argumentos da chamada de função.
*   `item_id`: `string`
    *   O ID do item.
*   `output_index`: `integer`
    *   O índice do item de saída.
*   `type`: `string` (Não especificado, mas assume-se `response.function_call_arguments.done`)

##### Objeto `response.function_call_arguments.done` Exemplo

```json
{
  "type": "response.function_call_arguments.done",
  "item_id": "item-abc",
  "output_index": 1,
  "arguments": "{ \"arg\": 123 }"
}
```

#### `response.file_search_call.in_progress`

Emitido quando uma chamada de pesquisa de arquivo é iniciada.

*   `item_id`: `string`
    *   O ID do item de saída ao qual a chamada de pesquisa de arquivo foi iniciada.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a chamada de pesquisa de arquivo foi iniciada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.file_search_call.in_progress`.

##### Objeto `response.file_search_call.in_progress` Exemplo

```json
{
  "type": "response.file_search_call.in_progress",
  "output_index": 0,
  "item_id": "fs_123"
}
```

#### `response.file_search_call.searching`

Emitido quando uma pesquisa de arquivo está sendo realizada.

*   `item_id`: `string`
    *   O ID do item de saída ao qual a chamada de pesquisa de arquivo foi iniciada.
*   `output_index`: `integer`
    *   O índice do item de saída que a chamada de pesquisa de arquivo está pesquisando.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.file_search_call.searching`.

##### Objeto `response.file_search_call.searching` Exemplo

```json
{
  "type": "response.file_search_call.searching",
  "output_index": 0,
  "item_id": "fs_123"
}
```

#### `response.file_search_call.completed`

Emitido quando uma chamada de pesquisa de arquivo é concluída (resultados encontrados).

*   `item_id`: `string`
    *   O ID do item de saída ao qual a chamada de pesquisa de arquivo foi iniciada.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a chamada de pesquisa de arquivo foi iniciada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.file_search_call.completed`.

##### Objeto `response.file_search_call.completed` Exemplo

```json
{
  "type": "response.file_search_call.completed",
  "output_index": 0,
  "item_id": "fs_123"
}
```

#### `response.web_search_call.in_progress`

Emitido quando uma chamada de pesquisa na web é iniciada.

*   `item_id`: `string`
    *   ID único para o item de saída associado à chamada de pesquisa na web.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a chamada de pesquisa na web está associada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.web_search_call.in_progress`.

##### Objeto `response.web_search_call.in_progress` Exemplo

```json
{
  "type": "response.web_search_call.in_progress",
  "output_index": 0,
  "item_id": "ws_123"
}
```

#### `response.web_search_call.searching`

Emitido quando uma chamada de pesquisa na web está sendo executada.

*   `item_id`: `string`
    *   ID único para o item de saída associado à chamada de pesquisa na web.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a chamada de pesquisa na web está associada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.web_search_call.searching`.

##### Objeto `response.web_search_call.searching` Exemplo

```json
{
  "type": "response.web_search_call.searching",
  "output_index": 0,
  "item_id": "ws_123"
}
```

#### `response.web_search_call.completed`

Emitido quando uma chamada de pesquisa na web é concluída.

*   `item_id`: `string`
    *   ID único para o item de saída associado à chamada de pesquisa na web.
*   `output_index`: `integer`
    *   O índice do item de saída ao qual a chamada de pesquisa na web está associada.
*   `type`: `string`
    *   O tipo do evento. Sempre `response.web_search_call.completed`.

##### Objeto `response.web_search_call.completed` Exemplo

```json
{
  "type": "response.web_search_call.completed",
  "output_index": 0,
  "item_id": "ws_123"
}
```

#### `error`

Emitido quando ocorre um erro.

*   `code`: `string` ou `null`
    *   O código do erro.
*   `message`: `string`
    *   A mensagem de erro.
*   `param`: `string` ou `null`
    *   O parâmetro do erro.
*   `type`: `string`
    *   O tipo do evento. Sempre `error`.

##### Objeto `error` Exemplo

```json
{
  "type": "error",
  "code": "ERR_SOMETHING",
  "message": "Something went wrong",
  "param": null
}
```

---

## Chat Completions

O endpoint da API Chat Completions gerará uma resposta do modelo a partir de uma lista de mensagens que compõem uma conversa.

**Guias relacionados:**

*   [Quickstart](https://platform.openai.com/docs/quickstart?context=chat)
*   [Text inputs and outputs](https://platform.openai.com/docs/guides/chat/text-inputs-and-outputs)
*   [Image inputs](https://platform.openai.com/docs/guides/chat/image-inputs)
*   [Audio inputs and outputs](https://platform.openai.com/docs/guides/chat/audio-inputs-and-outputs)
*   [Structured Outputs](https://platform.openai.com/docs/guides/chat/structured-outputs)
*   [Function calling](https://platform.openai.com/docs/guides/chat/function-calling)
*   [Conversation state](https://platform.openai.com/docs/guides/chat/conversation-state)

> **Nota:** Iniciando um novo projeto? Recomendamos experimentar [Responses](#responses) para aproveitar os recursos mais recentes da plataforma OpenAI. [Compare Chat Completions com Responses](https://platform.openai.com/docs/guides/chat/comparing-endpoints).

### Criar conclusão de chat

**POST** `/v1/chat/completions`

> **Nota:** Iniciando um novo projeto? Recomendamos experimentar [Responses](#responses) para aproveitar os recursos mais recentes da plataforma OpenAI. [Compare Chat Completions com Responses](https://platform.openai.com/docs/guides/chat/comparing-endpoints).

Cria uma resposta do modelo para a conversa de chat fornecida. Saiba mais nos guias de [geração de texto](https://platform.openai.com/docs/guides/chat/text-inputs-and-outputs), [visão](https://platform.openai.com/docs/guides/chat/image-inputs) e [áudio](https://platform.openai.com/docs/guides/chat/audio-inputs-and-outputs).

O suporte a parâmetros pode diferir dependendo do modelo usado para gerar a resposta, particularmente para modelos de raciocínio mais recentes. Parâmetros que são suportados apenas para modelos de raciocínio são anotados abaixo. Para o estado atual de parâmetros não suportados em modelos de raciocínio, consulte o [guia de raciocínio](https://platform.openai.com/docs/guides/reasoning).

#### Corpo da Requisição

*   `messages`: `array` - **Obrigatório**
    *   Uma lista de mensagens que compõem a conversa até agora. Dependendo do modelo que você usa, diferentes tipos de mensagem (modalidades) são suportados, como texto, imagens e áudio.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `model`: `string` - **Obrigatório**
    *   ID do modelo usado para gerar a resposta, como `gpt-4o` ou `o3`. Consulte o [guia de modelos](https://platform.openai.com/docs/models).

*   `audio`: `object` ou `null` - *Opcional*
    *   Parâmetros para saída de áudio. Obrigatório quando a saída de áudio é solicitada com `modalities: ["audio"]`. [Saiba mais](https://platform.openai.com/docs/guides/chat/audio-inputs-and-outputs).
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `frequency_penalty`: `number` ou `null` - *Opcional* - **Padrão:** `0`
    *   Número entre -2.0 e 2.0. Valores positivos penalizam novos tokens com base em sua frequência existente no texto até agora, diminuindo a probabilidade do modelo repetir a mesma linha literalmente. [Saiba mais](https://platform.openai.com/docs/guides/chat/logit-bias-and-logprobs).

*   `function_call`: (**Deprecated**) `string` ou `object` - *Opcional*
    *   *Obsoleto em favor de `tool_choice`.*
    *   Controla qual função (se houver) é chamada pelo modelo.
        *   `none` significa que o modelo não chamará uma função e, em vez disso, gera uma mensagem.
        *   `auto` significa que o modelo pode escolher entre gerar uma mensagem ou chamar uma função.
        *   Especificar uma função específica via `{"name": "my_function"}` força o modelo a chamar essa função.
    *   `none` é o padrão quando nenhuma função está presente. `auto` é o padrão se funções estiverem presentes.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `functions`: (**Deprecated**) `array` - *Opcional*
    *   *Obsoleto em favor de `tools`.*
    *   Uma lista de funções para as quais o modelo pode gerar entradas JSON.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `logit_bias`: `map` - *Opcional* - **Padrão:** `null`
    *   Modifica a probabilidade de tokens especificados aparecerem na conclusão. Aceita um objeto JSON que mapeia tokens (especificados por seu ID de token no tokenizador) para um valor de bias associado de -100 a 100. [Saiba mais](https://platform.openai.com/docs/guides/chat/logit-bias-and-logprobs).

*   `logprobs`: `boolean` ou `null` - *Opcional* - **Padrão:** `false`
    *   Se deve retornar log probabilidades dos tokens de saída ou não. Se `true`, retorna as log probabilidades de cada token de saída retornado no conteúdo da mensagem.

*   `max_completion_tokens`: `integer` ou `null` - *Opcional*
    *   Um limite superior para o número de tokens que podem ser gerados para uma conclusão, incluindo tokens de saída visíveis e tokens de raciocínio.

*   `max_tokens`: (**Deprecated**) `integer` ou `null` - *Opcional*
    *   *Obsoleto em favor de `max_completion_tokens`, e não compatível com modelos da série o.*
    *   O número máximo de tokens que podem ser gerados na conclusão do chat.

*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição da seção Responses)

*   `modalities`: `array` ou `null` - *Opcional*
    *   Tipos de saída que você gostaria que o modelo gerasse. Padrão: `["text"]`. Modelo `gpt-4o-audio-preview` pode usar `["text", "audio"]`.

*   `n`: `integer` ou `null` - *Opcional* - **Padrão:** `1`
    *   Quantas opções de conclusão de chat gerar para cada mensagem de entrada. Cobrança baseada no número total de tokens gerados em todas as opções. Mantenha `n` como 1 para minimizar custos.

*   `parallel_tool_calls`: `boolean` - *Opcional* - **Padrão:** `true`
    *   Se habilita a chamada de função paralela durante o uso da ferramenta.

*   `prediction`: `object` - *Opcional*
    *   Configuração para uma Saída Prevista, que pode melhorar muito os tempos de resposta quando grandes partes da resposta do modelo são conhecidas antecipadamente. [Saiba mais](https://platform.openai.com/docs/guides/chat/predicted-outputs).
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `presence_penalty`: `number` ou `null` - *Opcional* - **Padrão:** `0`
    *   Número entre -2.0 e 2.0. Valores positivos penalizam novos tokens com base em se eles aparecem no texto até agora, aumentando a probabilidade do modelo falar sobre novos tópicos. [Saiba mais](https://platform.openai.com/docs/guides/chat/logit-bias-and-logprobs).

*   `reasoning_effort`: `string` ou `null` - *Opcional* - **Padrão:** `medium` - *Apenas modelos da série o*
    *   Restringe o esforço em raciocínio para modelos de raciocínio. Valores suportados: `low`, `medium`, `high`. Reduzir o esforço de raciocínio pode resultar em respostas mais rápidas e menos tokens usados em raciocínio.

*   `response_format`: `object` - *Opcional*
    *   Um objeto especificando o formato que o modelo deve produzir.
        *   `{ "type": "json_schema", "json_schema": {...} }` habilita [Structured Outputs](https://platform.openai.com/docs/guides/chat/structured-outputs).
        *   `{ "type": "json_object" }` habilita o modo JSON mais antigo. `json_schema` é preferível.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `seed`: `integer` ou `null` - *Opcional* - *Beta*
    *   Se especificado, nosso sistema fará o melhor esforço para amostrar deterministicamente. A determinismo não é garantido; consulte o parâmetro de resposta `system_fingerprint`.

*   `service_tier`: `string` ou `null` - *Opcional* - **Padrão:** `auto`
    *   Especifica o nível de latência a ser usado. (Mesma descrição da seção Responses)

*   `stop`: `string` / `array` / `null` - *Opcional* - **Padrão:** `null`
    *   *Não suportado com os modelos de raciocínio mais recentes o3 e o4-mini.*
    *   Até 4 sequências onde a API parará de gerar mais tokens.

*   `store`: `boolean` ou `null` - *Opcional* - **Padrão:** `false`
    *   Se armazena ou não a saída desta requisição de conclusão de chat para uso em nossos produtos de destilação de modelo ou evals.

*   `stream`: `boolean` ou `null` - *Opcional* - **Padrão:** `false`
    *   Se `true`, os dados da resposta do modelo serão transmitidos. Veja a seção [Streaming](#streaming-1) abaixo e o [guia de respostas de streaming](https://platform.openai.com/docs/guides/chat/streaming).

*   `stream_options`: `object` ou `null` - *Opcional* - **Padrão:** `null`
    *   Opções para resposta de streaming. Defina apenas quando `stream: true`.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `temperature`: `number` ou `null` - *Opcional* - **Padrão:** `1`
    *   Qual temperatura de amostragem usar, entre 0 e 2. (Mesma descrição da seção Responses)

*   `tool_choice`: `string` ou `object` - *Opcional*
    *   Controla qual(is) ferramenta(s) é(são) chamada(s) pelo modelo.
        *   `none`: O modelo não chama nenhuma ferramenta.
        *   `auto`: O modelo pode escolher entre gerar uma mensagem ou chamar uma ou mais ferramentas (padrão se ferramentas estiverem presentes).
        *   `required`: O modelo deve chamar uma ou mais ferramentas.
        *   Especificar uma ferramenta específica via `{"type": "function", "function": {"name": "my_function"}}` força o modelo a chamar essa ferramenta.
    *   `none` é o padrão quando nenhuma ferramenta está presente.
    *   <details><summary>Mostrar tipos possíveis</summary> (O conteúdo específico dos tipos não foi fornecido no texto original)</details>

*   `tools`: `array` - *Opcional*
    *   Uma lista de ferramentas que o modelo pode chamar. Atualmente, apenas funções são suportadas como ferramenta. Máximo de 128 funções.
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

*   `top_logprobs`: `integer` ou `null` - *Opcional*
    *   Um inteiro entre 0 e 20 especificando o número de tokens mais prováveis a retornar em cada posição de token, cada um com uma probabilidade de log associada. `logprobs` deve ser definido como `true` se este parâmetro for usado.

*   `top_p`: `number` ou `null` - *Opcional* - **Padrão:** `1`
    *   Alternativa à amostragem com temperatura (nucleus sampling). (Mesma descrição da seção Responses)

*   `user`: `string` - *Opcional*
    *   Um identificador único representando seu usuário final. [Saiba mais](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

*   `web_search_options`: `object` - *Opcional*
    *   Esta ferramenta pesquisa na web por resultados relevantes para usar em uma resposta. [Saiba mais sobre a ferramenta de pesquisa na web](https://platform.openai.com/docs/guides/chat/web-search).
    *   <details><summary>Mostrar propriedades</summary> (O conteúdo específico das propriedades não foi fornecido no texto original)</details>

#### Retorna

Retorna um objeto [chat completion](#the-chat-completion-object), ou uma sequência transmitida de objetos [chat completion chunk](#the-chat-completion-chunk-object) se a requisição for transmitida.

#### Exemplos

##### Exemplo: Padrão

```bash
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "developer",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

```json
# Resposta
{
  "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
  "object": "chat.completion",
  "created": 1741569952,
  "model": "gpt-4.1-2025-04-14",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I assist you today?",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default"
}
```

> *(Nota: Exemplos para Image input, Streaming, Functions, Logprobs não foram fornecidos no texto original, mas seriam colocados aqui se estivessem)*

---

### Obter conclusão de chat

**GET** `/v1/chat/completions/{completion_id}`

Obtém uma conclusão de chat armazenada. Somente Conclusões de Chat que foram criadas com o parâmetro `store` definido como `true` serão retornadas.

#### Parâmetros de Caminho

*   `completion_id`: `string` - **Obrigatório**
    *   O ID da conclusão de chat a ser recuperada.

#### Retorna

O objeto [ChatCompletion](#the-chat-completion-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "chat.completion",
  "id": "chatcmpl-abc123",
  "model": "gpt-4o-2024-08-06",
  "created": 1738960610,
  "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
  "tool_choice": null,
  "usage": {
    "total_tokens": 31,
    "completion_tokens": 18,
    "prompt_tokens": 13
  },
  "seed": 4944116822809979520,
  "top_p": 1.0,
  "temperature": 1.0,
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0,
  "system_fingerprint": "fp_50cad350e4",
  "input_user": null,
  "service_tier": "default",
  "tools": null,
  "metadata": {},
  "choices": [
    {
      "index": 0,
      "message": {
        "content": "Mind of circuits hum,  \nLearning patterns in silence—  \nFuture's quiet spark.",
        "role": "assistant",
        "tool_calls": null,
        "function_call": null
      },
      "finish_reason": "stop",
      "logprobs": null
    }
  ],
  "response_format": null
}
```

---

### Obter mensagens de chat

**GET** `/v1/chat/completions/{completion_id}/messages`

Obtém as mensagens em uma conclusão de chat armazenada. Somente Conclusões de Chat que foram criadas com o parâmetro `store` definido como `true` serão retornadas.

#### Parâmetros de Caminho

*   `completion_id`: `string` - **Obrigatório**
    *   O ID da conclusão de chat da qual recuperar mensagens.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional*
    *   Identificador para a última mensagem da requisição de paginação anterior.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20`
    *   Número de mensagens a serem recuperadas.
*   `order`: `string` - *Opcional* - **Padrão:** `asc`
    *   Ordem de classificação para mensagens por timestamp. Use `asc` para ordem ascendente ou `desc` para ordem descendente. Padrão `asc`.

#### Retorna

Uma lista de mensagens para a conclusão de chat especificada.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "role": "user",
      "content": "write a haiku about ai",
      "name": null,
      "content_parts": null
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "has_more": false
}
```

---

### Listar Conclusões de Chat

**GET** `/v1/chat/completions`

Lista Conclusões de Chat armazenadas. Somente Conclusões de Chat que foram armazenadas com o parâmetro `store` definido como `true` serão retornadas.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional*
    *   Identificador para a última conclusão de chat da requisição de paginação anterior.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20`
    *   Número de Conclusões de Chat a serem recuperadas.
*   `metadata`: `map` - *Opcional*
    *   Uma lista de chaves de metadados para filtrar as Conclusões de Chat. Exemplo: `metadata[key1]=value1&metadata[key2]=value2`
*   `model`: `string` - *Opcional*
    *   O modelo usado para gerar as Conclusões de Chat.
*   `order`: `string` - *Opcional* - **Padrão:** `asc`
    *   Ordem de classificação para Conclusões de Chat por timestamp. Use `asc` para ordem ascendente ou `desc` para ordem descendente. Padrão `asc`.

#### Retorna

Uma lista de Conclusões de Chat correspondentes aos filtros especificados.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "chat.completion",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "model": "gpt-4.1-2025-04-14",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {},
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "Mind of circuits hum,  \nLearning patterns in silence—  \nFuture's quiet spark.",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "has_more": false
}
```

---

### Atualizar conclusão de chat

**POST** `/v1/chat/completions/{completion_id}`

Modifica uma conclusão de chat armazenada. Somente Conclusões de Chat que foram criadas com o parâmetro `store` definido como `true` podem ser modificadas. Atualmente, a única modificação suportada é atualizar o campo `metadata`.

#### Parâmetros de Caminho

*   `completion_id`: `string` - **Obrigatório**
    *   O ID da conclusão de chat a ser atualizada.

#### Corpo da Requisição

*   `metadata`: `map` - **Obrigatório**
    *   Conjunto de 16 pares chave-valor. (Mesma descrição da seção Responses)

#### Retorna

O objeto [ChatCompletion](#the-chat-completion-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"metadata": {"foo": "bar"}}'
```

#### Resposta

```json
{
  "object": "chat.completion",
  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "model": "gpt-4o-2024-08-06",
  "created": 1738960610,
  "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
  "tool_choice": null,
  "usage": {
    "total_tokens": 31,
    "completion_tokens": 18,
    "prompt_tokens": 13
  },
  "seed": 4944116822809979520,
  "top_p": 1.0,
  "temperature": 1.0,
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0,
  "system_fingerprint": "fp_50cad350e4",
  "input_user": null,
  "service_tier": "default",
  "tools": null,
  "metadata": {
    "foo": "bar"
  },
  "choices": [
    {
      "index": 0,
      "message": {
        "content": "Mind of circuits hum,  \nLearning patterns in silence—  \nFuture's quiet spark.",
        "role": "assistant",
        "tool_calls": null,
        "function_call": null
      },
      "finish_reason": "stop",
      "logprobs": null
    }
  ],
  "response_format": null
}
```

---

### Excluir conclusão de chat

**DELETE** `/v1/chat/completions/{completion_id}`

Exclui uma conclusão de chat armazenada. Somente Conclusões de Chat que foram criadas com o parâmetro `store` definido como `true` podem ser excluídas.

#### Parâmetros de Caminho

*   `completion_id`: `string` - **Obrigatório**
    *   O ID da conclusão de chat a ser excluída.

#### Retorna

Um objeto de confirmação de exclusão.

#### Exemplo de Requisição

```bash
curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "chat.completion.deleted",
  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "deleted": true
}
```

---

### O objeto Chat Completion

Representa uma resposta de conclusão de chat retornada pelo modelo, com base na entrada fornecida.

*   `choices`: `array`
    *   Uma lista de opções de conclusão de chat. Pode ser mais de uma se `n` for maior que 1.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `index`, `message`, `logprobs`, `finish_reason`)</details>
*   `created`: `integer`
    *   O timestamp Unix (em segundos) de quando a conclusão do chat foi criada.
*   `id`: `string`
    *   Um identificador único para a conclusão do chat.
*   `model`: `string`
    *   O modelo usado para a conclusão do chat.
*   `object`: `string`
    *   O tipo de objeto, que é sempre `chat.completion`.
*   `service_tier`: `string` ou `null`
    *   Especifica o nível de latência usado. (Mesma descrição da seção Responses)
*   `system_fingerprint`: `string`
    *   Esta impressão digital representa a configuração de backend com a qual o modelo é executado. Pode ser usada em conjunto com o parâmetro de requisição `seed`.
*   `usage`: `object`
    *   Estatísticas de uso para a requisição de conclusão.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `prompt_tokens`, `completion_tokens`, `total_tokens`, `prompt_tokens_details`, `completion_tokens_details`)</details>

#### Objeto Chat Completion Exemplo

```json
{
  "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
  "object": "chat.completion",
  "created": 1741570283,
  "model": "gpt-4o-2024-08-06",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1117,
    "completion_tokens": 46,
    "total_tokens": 1163,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_fc9f1d7035"
}
```

---

### O objeto Lista de Conclusão de Chat

Um objeto representando uma lista de Conclusões de Chat.

*   `data`: `array`
    *   Um array de objetos de conclusão de chat.
    *   <details><summary>Mostrar propriedades</summary> (Cada item é um [objeto Chat Completion](#the-chat-completion-object))</details>
*   `first_id`: `string`
    *   O identificador da primeira conclusão de chat no array `data`.
*   `has_more`: `boolean`
    *   Indica se há mais Conclusões de Chat disponíveis.
*   `last_id`: `string`
    *   O identificador da última conclusão de chat no array `data`.
*   `object`: `string`
    *   O tipo deste objeto. É sempre definido como `"list"`.

#### Objeto Lista de Conclusão de Chat Exemplo

```json
{
  "object": "list",
  "data": [
    {
      "object": "chat.completion",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      // ... (restante das propriedades como no exemplo anterior)
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "has_more": false
}
```

---

### O objeto Lista de Mensagens de Conclusão de Chat

Um objeto representando uma lista de mensagens de conclusão de chat.

*   `data`: `array`
    *   Um array de objetos de mensagem de conclusão de chat.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `id`, `role`, `content`, `name`, `content_parts`)</details>
*   `first_id`: `string`
    *   O identificador da primeira mensagem de chat no array `data`.
*   `has_more`: `boolean`
    *   Indica se há mais mensagens de chat disponíveis.
*   `last_id`: `string`
    *   O identificador da última mensagem de chat no array `data`.
*   `object`: `string`
    *   O tipo deste objeto. É sempre definido como `"list"`.

#### Objeto Lista de Mensagens de Conclusão de Chat Exemplo

```json
{
  "object": "list",
  "data": [
    {
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "role": "user",
      "content": "write a haiku about ai",
      "name": null,
      "content_parts": null
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "has_more": false
}
```

---

### Streaming

Transmita Conclusões de Chat em tempo real. Receba pedaços (chunks) de conclusões retornadas do modelo usando server-sent events. [Saiba mais](https://platform.openai.com/docs/guides/chat/streaming).

#### O objeto Chat Completion Chunk

Representa um pedaço transmitido de uma resposta de conclusão de chat retornada pelo modelo, com base na entrada fornecida. [Saiba mais](https://platform.openai.com/docs/guides/chat/streaming#chunk-format).

*   `choices`: `array`
    *   Uma lista de opções de conclusão de chat. Pode conter mais de um elemento se `n` for maior que 1. Também pode estar vazio para o último pedaço se você definir `stream_options: {"include_usage": true}`.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `index`, `delta`, `logprobs`, `finish_reason`)</details>
*   `created`: `integer`
    *   O timestamp Unix (em segundos) de quando a conclusão do chat foi criada. Cada pedaço tem o mesmo timestamp.
*   `id`: `string`
    *   Um identificador único para a conclusão do chat. Cada pedaço tem o mesmo ID.
*   `model`: `string`
    *   O modelo para gerar a conclusão.
*   `object`: `string`
    *   O tipo de objeto, que é sempre `chat.completion.chunk`.
*   `service_tier`: `string` ou `null`
    *   Especifica o nível de latência usado. (Mesma descrição da seção Responses)
*   `system_fingerprint`: `string`
    *   Esta impressão digital representa a configuração de backend com a qual o modelo é executado.
*   `usage`: `object` ou `null`
    *   Estatísticas de uso para a requisição de conclusão. Presente apenas no último chunk se `stream_options: {"include_usage": true}` for definido.
    *   <details><summary>Mostrar propriedades</summary> (Mesmas propriedades do `usage` no objeto Chat Completion não-streaming)</details>

#### Objeto Chat Completion Chunk Exemplo (Sequência de Eventos)

```json
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}
```

```json
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}
```

... (mais chunks com deltas de conteúdo) ...

```json
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

---

## Realtime (Beta)

Comunique-se com um modelo da classe GPT-4o em tempo real usando WebRTC ou WebSockets. Suporta entradas e saídas de texto e áudio, juntamente com transcrições de áudio. [Saiba mais sobre a API Realtime](https://platform.openai.com/docs/guides/realtime).

### Tokens de Sessão

Endpoint da API REST para gerar tokens de sessão efêmeros para uso em aplicações do lado do cliente.

#### Criar sessão

**POST** `/v1/realtime/sessions`

Cria um token de API efêmero para uso em aplicações do lado do cliente com a API Realtime. Pode ser configurado com os mesmos parâmetros de sessão do evento do cliente `session.update`.

Responde com um objeto de sessão, mais uma chave `client_secret` que contém um token de API efêmero utilizável que pode ser usado para autenticar clientes de navegador para a API Realtime.

##### Corpo da Requisição

*   `input_audio_format`: `string` - *Opcional* - **Padrão:** `pcm16`
    *   O formato do áudio de entrada. Opções são `pcm16`, `g711_ulaw` ou `g711_alaw`. Para `pcm16`, o áudio de entrada deve ser PCM de 16 bits a uma taxa de amostragem de 24kHz, canal único (mono) e ordem de bytes little-endian.
*   `input_audio_noise_reduction`: `object` - *Opcional* - **Padrão:** `null`
    *   Configuração para redução de ruído do áudio de entrada. Pode ser definido como `null` para desligar. [Saiba mais](https://platform.openai.com/docs/guides/realtime/audio-processing#noise-reduction).
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `type` como `near_field` ou `far_field`)</details>
*   `input_audio_transcription`: `object` - *Opcional*
    *   Configuração para transcrição de áudio de entrada, padrão desligado (`null`). [Saiba mais](https://platform.openai.com/docs/guides/realtime/transcriptions).
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `model`, `language`, `prompt`)</details>
*   `instructions`: `string` - *Opcional*
    *   As instruções de sistema padrão (ou seja, mensagem de sistema) pré-anexadas às chamadas do modelo.
*   `max_response_output_tokens`: `integer` ou `"inf"` - *Opcional* - **Padrão:** `inf`
    *   Número máximo de tokens de saída para uma única resposta do assistente, incluindo chamadas de ferramenta. Inteiro entre 1 e 4096 ou `inf`.
*   `modalities`: `array` - *Opcional*
    *   O conjunto de modalidades com as quais o modelo pode responder. Para desativar o áudio, defina como `["text"]`.
*   `model`: `string` - *Opcional*
    *   O modelo Realtime usado para esta sessão.
*   `output_audio_format`: `string` - *Opcional* - **Padrão:** `pcm16`
    *   O formato do áudio de saída. Opções `pcm16`, `g711_ulaw` ou `g711_alaw`. Para `pcm16`, o áudio de saída é amostrado a 24kHz.
*   `temperature`: `number` - *Opcional* - **Padrão:** `0.8`
    *   Temperatura de amostragem para o modelo, limitada a [0.6, 1.2]. Para modelos de áudio, 0.8 é altamente recomendado.
*   `tool_choice`: `string` - *Opcional* - **Padrão:** `auto`
    *   Como o modelo escolhe ferramentas. Opções: `auto`, `none`, `required` ou especificar uma função.
*   `tools`: `array` - *Opcional*
    *   Ferramentas (funções) disponíveis para o modelo.
    *   <details><summary>Mostrar propriedades</summary> (Estrutura similar à seção Chat Completions)</details>
*   `turn_detection`: `object` - *Opcional*
    *   Configuração para detecção de turno, Server VAD ou Semantic VAD. [Saiba mais](https://platform.openai.com/docs/guides/realtime/turn-detection).
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `type`, `threshold`, `prefix_padding_ms`, `silence_duration_ms`, etc.)</details>
*   `voice`: `string` - *Opcional*
    *   A voz que o modelo usa para responder. Opções: `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer` e `verse`. Não pode ser alterada após a primeira resposta de áudio.

##### Retorna

O objeto de sessão Realtime criado, mais uma chave efêmera (`client_secret`).

##### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/realtime/sessions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-realtime-preview",
    "modalities": ["audio", "text"],
    "instructions": "You are a friendly assistant."
  }'
```

##### Resposta

```json
{
  "id": "sess_001",
  "object": "realtime.session",
  "model": "gpt-4o-realtime-preview",
  "modalities": ["audio", "text"],
  "instructions": "You are a friendly assistant.",
  "voice": "alloy",
  "input_audio_format": "pcm16",
  "output_audio_format": "pcm16",
  "input_audio_transcription": {
      "model": "whisper-1"
  },
  "turn_detection": null,
  "tools": [],
  "tool_choice": "none",
  "temperature": 0.7,
  "max_response_output_tokens": 200,
  "client_secret": {
    "value": "ek_abc123",
    "expires_at": 1234567890
  }
}
```

---

#### Criar sessão de transcrição

**POST** `/v1/realtime/transcription_sessions`

Cria um token de API efêmero para uso em aplicações do lado do cliente com a API Realtime especificamente para transcrições em tempo real. Pode ser configurado com os mesmos parâmetros de sessão do evento do cliente `transcription_session.update`.

Responde com um objeto de sessão, mais uma chave `client_secret`.

##### Corpo da Requisição

*   `include`: `array` - *Opcional*
    *   O conjunto de itens para incluir na transcrição. Itens disponíveis atualmente: `null`. (Isto parece incompleto ou incorreto no original - pode ser para logprobs, etc.)
*   `input_audio_format`: `string` - *Opcional* - **Padrão:** `pcm16`
    *   Formato do áudio de entrada. (Mesma descrição de Criar sessão)
*   `input_audio_noise_reduction`: `object` - *Opcional* - **Padrão:** `null`
    *   Configuração para redução de ruído. (Mesma descrição de Criar sessão)
    *   <details><summary>Mostrar propriedades</summary></details>
*   `input_audio_transcription`: `object` - *Opcional*
    *   Configuração para transcrição de áudio de entrada. (Mesma descrição de Criar sessão)
    *   <details><summary>Mostrar propriedades</summary></details>
*   `modalities`: `array` - *Opcional*
    *   Conjunto de modalidades que o modelo pode responder. (Mesma descrição de Criar sessão)
*   `turn_detection`: `object` - *Opcional*
    *   Configuração para detecção de turno. (Mesma descrição de Criar sessão)
    *   <details><summary>Mostrar propriedades</summary></details>

##### Retorna

O objeto de sessão de transcrição Realtime criado, mais uma chave efêmera (`client_secret`).

##### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{}'
```

##### Resposta

```json
{
  "id": "sess_BBwZc7cFV3XizEyKGDCGL",
  "object": "realtime.transcription_session",
  "modalities": ["audio", "text"],
  "turn_detection": {
    "type": "server_vad",
    "threshold": 0.5,
    "prefix_padding_ms": 300,
    "silence_duration_ms": 200
  },
  "input_audio_format": "pcm16",
  "input_audio_transcription": {
    "model": "gpt-4o-transcribe",
    "language": null,
    "prompt": ""
  },
  "client_secret": null // Exemplo mostra null, mas a descrição diz que retorna a chave
}
```

---

### O objeto Session

Uma nova configuração de sessão Realtime, com uma chave efêmera. TTL padrão para chaves é de um minuto.

*   `client_secret`: `object`
    *   Chave efêmera retornada pela API.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `value`, `expires_at`)</details>
*   `input_audio_format`: `string` - Formato do áudio de entrada.
*   `input_audio_transcription`: `object` - Configuração para transcrição de áudio de entrada.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `instructions`: `string` - Instruções de sistema padrão.
*   `max_response_output_tokens`: `integer` ou `"inf"` - Número máximo de tokens de saída.
*   `modalities`: `array` - Conjunto de modalidades de resposta.
*   `output_audio_format`: `string` - Formato do áudio de saída.
*   `temperature`: `number` - Temperatura de amostragem.
*   `tool_choice`: `string` - Como o modelo escolhe ferramentas.
*   `tools`: `array` - Ferramentas disponíveis.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `turn_detection`: `object` - Configuração para detecção de turno.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `voice`: `string` - Voz usada pelo modelo.

#### Objeto Session Exemplo

```json
{
  "id": "sess_001",
  "object": "realtime.session",
  "model": "gpt-4o-realtime-preview",
  "modalities": ["audio", "text"],
  "instructions": "You are a friendly assistant.",
  "voice": "alloy",
  "input_audio_format": "pcm16",
  "output_audio_format": "pcm16",
  "input_audio_transcription": {
      "model": "whisper-1"
  },
  "turn_detection": null,
  "tools": [],
  "tool_choice": "none",
  "temperature": 0.7,
  "max_response_output_tokens": 200,
  "client_secret": {
    "value": "ek_abc123",
    "expires_at": 1234567890
  }
}
```

---

### O objeto Transcription Session

Uma nova configuração de sessão de transcrição Realtime.

*   `client_secret`: `object`
    *   Chave efêmera retornada pela API. Presente apenas quando a sessão é criada via API REST.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `input_audio_format`: `string` - Formato do áudio de entrada.
*   `input_audio_transcription`: `object` - Configuração do modelo de transcrição.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `modalities`: `array` - Conjunto de modalidades de resposta.
*   `turn_detection`: `object` - Configuração para detecção de turno.
    *   <details><summary>Mostrar propriedades</summary></details>

#### Objeto Transcription Session Exemplo

```json
{
  "id": "sess_BBwZc7cFV3XizEyKGDCGL",
  "object": "realtime.transcription_session",
  // "expires_at": 1742188264, (Campo não listado nas propriedades, mas presente no exemplo)
  "modalities": ["audio", "text"],
  "turn_detection": {
    "type": "server_vad",
    "threshold": 0.5,
    "prefix_padding_ms": 300,
    "silence_duration_ms": 200
  },
  "input_audio_format": "pcm16",
  "input_audio_transcription": {
    "model": "gpt-4o-transcribe",
    "language": null,
    "prompt": ""
  },
  "client_secret": null
}
```

---

### Eventos do Cliente (Client Events)

Estes são eventos que o servidor WebSocket Realtime da OpenAI aceitará do cliente.

#### `session.update`

Envia este evento para atualizar a configuração padrão da sessão.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `session`: `object` - Objeto de configuração da sessão Realtime.
    *   <details><summary>Mostrar propriedades</summary> (Mesmas propriedades do [objeto Session](#the-session-object), exceto `client_secret`, `id`, `object`, `model`)</details>
*   `type`: `string` - Deve ser `session.update`.

##### Objeto `session.update` Exemplo

```json
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500,
            "create_response": true
        },
        "tools": [
            {
                "type": "function",
                "name": "get_weather",
                "description": "Get the current weather...",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": { "type": "string" }
                    },
                    "required": ["location"]
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

#### `input_audio_buffer.append`

Envia este evento para anexar bytes de áudio ao buffer de áudio de entrada.

*   `audio`: `string` - Bytes de áudio codificados em Base64.
*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `type`: `string` - Deve ser `input_audio_buffer.append`.

##### Objeto `input_audio_buffer.append` Exemplo

```json
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

#### `input_audio_buffer.commit`

Envia este evento para confirmar o buffer de áudio de entrada do usuário.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `type`: `string` - Deve ser `input_audio_buffer.commit`.

##### Objeto `input_audio_buffer.commit` Exemplo

```json
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

#### `input_audio_buffer.clear`

Envia este evento para limpar os bytes de áudio no buffer.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `type`: `string` - Deve ser `input_audio_buffer.clear`.

##### Objeto `input_audio_buffer.clear` Exemplo

```json
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

#### `conversation.item.create`

Adiciona um novo Item ao contexto da Conversa.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `item`: `object` - O item a ser adicionado à conversa.
    *   <details><summary>Mostrar propriedades</summary> (Ex: tipo `message`, `role`, `content`)</details>
*   `previous_item_id`: `string` - O ID do item precedente. `null` para anexar, `root` para início.
*   `type`: `string` - Deve ser `conversation.item.create`.

##### Objeto `conversation.item.create` Exemplo

```json
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [
            {
                "type": "input_text",
                "text": "Hello, how are you?"
            }
        ]
    }
}
```

#### `conversation.item.retrieve`

Envia este evento para recuperar a representação do servidor de um item específico.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `item_id`: `string` - O ID do item a ser recuperado.
*   `type`: `string` - Deve ser `conversation.item.retrieve`.

##### Objeto `conversation.item.retrieve` Exemplo

```json
{
    "event_id": "event_901",
    "type": "conversation.item.retrieve",
    "item_id": "msg_003"
}
```

#### `conversation.item.truncate`

Envia este evento para truncar o áudio de uma mensagem anterior do assistente.

*   `audio_end_ms`: `integer` - Duração inclusiva até a qual o áudio é truncado (ms).
*   `content_index`: `integer` - O índice da parte do conteúdo a truncar (geralmente 0).
*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `item_id`: `string` - O ID do item da mensagem do assistente a truncar.
*   `type`: `string` - Deve ser `conversation.item.truncate`.

##### Objeto `conversation.item.truncate` Exemplo

```json
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

#### `conversation.item.delete`

Envia este evento para remover qualquer item do histórico da conversa.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `item_id`: `string` - O ID do item a ser excluído.
*   `type`: `string` - Deve ser `conversation.item.delete`.

##### Objeto `conversation.item.delete` Exemplo

```json
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

#### `response.create`

Instrui o servidor a criar uma Resposta (acionar inferência do modelo).

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `response`: `object` - Cria uma nova resposta Realtime com estes parâmetros.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `modalities`, `instructions`, `voice`, `tools`, `temperature`, etc., que sobrescrevem a configuração da sessão para esta resposta)</details>
*   `type`: `string` - Deve ser `response.create`.

##### Objeto `response.create` Exemplo

```json
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [
            {
                "type": "function",
                "name": "calculate_sum",
                "description": "Calculates the sum of two numbers.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "a": { "type": "number" },
                        "b": { "type": "number" }
                    },
                    "required": ["a", "b"]
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_output_tokens": 1024
    }
}
```

#### `response.cancel`

Envia este evento para cancelar uma resposta em andamento.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `response_id`: `string` - ID de resposta específico para cancelar (opcional, cancela o padrão se não fornecido).
*   `type`: `string` - Deve ser `response.cancel`.

##### Objeto `response.cancel` Exemplo

```json
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

#### `transcription_session.update`

Envia este evento para atualizar uma sessão de transcrição.

*   `event_id`: `string` - *Opcional* ID gerado pelo cliente.
*   `session`: `object` - Objeto de configuração da sessão de transcrição Realtime.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `input_audio_format`, `input_audio_transcription`, `turn_detection`, `input_audio_noise_reduction`, `include`)</details>
*   `type`: `string` - Deve ser `transcription_session.update`.

##### Objeto `transcription_session.update` Exemplo

```json
{
  "type": "transcription_session.update",
  "session": {
    "input_audio_format": "pcm16",
    "input_audio_transcription": {
      "model": "gpt-4o-transcribe",
      "prompt": "",
      "language": ""
    },
    "turn_detection": {
      "type": "server_vad",
      "threshold": 0.5,
      "prefix_padding_ms": 300,
      "silence_duration_ms": 500,
      "create_response": true,
    },
    "input_audio_noise_reduction": {
      "type": "near_field"
    },
    "include": [
      "item.input_audio_transcription.logprobs"
    ]
  }
}
```

---

### Eventos do Servidor (Server Events)

Estes são eventos emitidos do servidor WebSocket Realtime da OpenAI para o cliente.

#### `error`

Retornado quando ocorre um erro.

*   `error`: `object` - Detalhes do erro.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `type`, `code`, `message`, `param`, `event_id` do cliente)</details>
*   `event_id`: `string` - O ID único do evento do servidor.
*   `type`: `string` - Deve ser `error`.

##### Objeto `error` Exemplo

```json
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567" // ID do evento do cliente que causou o erro
    }
}
```

#### `session.created`

Retornado quando uma Sessão é criada.

*   `event_id`: `string` - ID único do evento do servidor.
*   `session`: `object` - Configuração do objeto de sessão Realtime.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como no [objeto Session](#the-session-object), exceto `client_secret`)</details>
*   `type`: `string` - Deve ser `session.created`.

##### Objeto `session.created` Exemplo

```json
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

#### `session.updated`

Retornado quando uma sessão é atualizada com um evento `session.update`.

*   `event_id`: `string` - ID único do evento do servidor.
*   `session`: `object` - Configuração do objeto de sessão Realtime.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `type`: `string` - Deve ser `session.updated`.

##### Objeto `session.updated` Exemplo

```json
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        // ... propriedades atualizadas
        "max_response_output_tokens": 200
    }
}
```

#### `conversation.created`

Retornado quando uma conversa é criada.

*   `conversation`: `object` - O recurso de conversa.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `id`, `object`)</details>
*   `event_id`: `string` - ID único do evento do servidor.
*   `type`: `string` - Deve ser `conversation.created`.

##### Objeto `conversation.created` Exemplo

```json
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

#### `conversation.item.created`

Retornado quando um item de conversa é criado.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item`: `object` - O item adicionado à conversa.
    *   <details><summary>Mostrar propriedades</summary> (Ex: tipo `message`, `role`, `content`, `status`, `id`, `object`)</details>
*   `previous_item_id`: `string` - ID do item precedente.
*   `type`: `string` - Deve ser `conversation.item.created`.

##### Objeto `conversation.item.created` Exemplo

```json
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed", // Status inicial pode ser in_progress
        "role": "user",
        "content": [] // Conteúdo será adicionado em eventos posteriores
    }
}
```

#### `conversation.item.retrieved`

Retornado quando um item de conversa é recuperado com `conversation.item.retrieve`.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item`: `object` - O item recuperado.
    *   <details><summary>Mostrar propriedades</summary> (Pode incluir detalhes como `transcript` e `audio` base64)</details>
*   `type`: `string` - Deve ser `conversation.item.retrieved`.

##### Objeto `conversation.item.retrieved` Exemplo

```json
{
    "event_id": "event_1920", // ID do evento de recuperação, não o de criação
    "type": "conversation.item.retrieved", // Corrigido de created para retrieved
    // "previous_item_id": "msg_002", // Não relevante para retrieve
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [
            {
                "type": "input_audio",
                "transcript": "hello how are you", // Pode vir de evento transcription.completed
                "audio": "base64encodedaudio==" // Áudio processado (pós-VAD/NR)
            }
        ]
    }
}
```

#### `conversation.item.input_audio_transcription.completed`

Saída da transcrição de áudio para áudio do usuário.

*   `content_index`: `integer` - Índice da parte do conteúdo contendo o áudio.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do usuário contendo o áudio.
*   `logprobs`: `array` ou `null` - Log probabilidades da transcrição.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `transcript`: `string` - O texto transcrito.
*   `type`: `string` - Deve ser `conversation.item.input_audio_transcription.completed`.

##### Objeto `conversation.item.input_audio_transcription.completed` Exemplo

```json
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
    // "logprobs": null // Exemplo não incluiu logprobs
}
```

#### `conversation.item.input_audio_transcription.delta`

Retornado quando o valor de texto de uma parte de conteúdo de transcrição de áudio de entrada é atualizado.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `delta`: `string` - O delta de texto.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `logprobs`: `array` ou `null` - Log probabilidades da transcrição.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `type`: `string` - Deve ser `conversation.item.input_audio_transcription.delta`.

##### Objeto `conversation.item.input_audio_transcription.delta` Exemplo

```json
{
  "type": "conversation.item.input_audio_transcription.delta",
  "event_id": "event_001",
  "item_id": "item_001",
  "content_index": 0,
  "delta": "Hello"
  // "logprobs": null // Exemplo não incluiu logprobs
}
```

#### `conversation.item.input_audio_transcription.failed`

Retornado quando a transcrição de áudio de entrada falha para uma mensagem do usuário.

*   `content_index`: `integer` - Índice da parte do conteúdo contendo o áudio.
*   `error`: `object` - Detalhes do erro de transcrição.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do usuário.
*   `type`: `string` - Deve ser `conversation.item.input_audio_transcription.failed`.

##### Objeto `conversation.item.input_audio_transcription.failed` Exemplo

```json
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

#### `conversation.item.truncated`

Retornado quando um item de mensagem de áudio anterior do assistente é truncado.

*   `audio_end_ms`: `integer` - Duração até a qual o áudio foi truncado (ms).
*   `content_index`: `integer` - Índice da parte do conteúdo que foi truncada.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do assistente que foi truncado.
*   `type`: `string` - Deve ser `conversation.item.truncated`.

##### Objeto `conversation.item.truncated` Exemplo

```json
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

#### `conversation.item.deleted`

Retornado quando um item na conversa é excluído pelo cliente.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item que foi excluído.
*   `type`: `string` - Deve ser `conversation.item.deleted`.

##### Objeto `conversation.item.deleted` Exemplo

```json
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

#### `input_audio_buffer.committed`

Retornado quando um buffer de áudio de entrada é confirmado.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do usuário que será criado.
*   `previous_item_id`: `string` - ID do item precedente.
*   `type`: `string` - Deve ser `input_audio_buffer.committed`.

##### Objeto `input_audio_buffer.committed` Exemplo

```json
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

#### `input_audio_buffer.cleared`

Retornado quando o buffer de áudio de entrada é limpo pelo cliente.

*   `event_id`: `string` - ID único do evento do servidor.
*   `type`: `string` - Deve ser `input_audio_buffer.cleared`.

##### Objeto `input_audio_buffer.cleared` Exemplo

```json
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

#### `input_audio_buffer.speech_started`

Enviado pelo servidor no modo `server_vad` para indicar que a fala foi detectada.

*   `audio_start_ms`: `integer` - Milissegundos desde o início do áudio quando a fala foi detectada.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do usuário que será criado quando a fala parar.
*   `type`: `string` - Deve ser `input_audio_buffer.speech_started`.

##### Objeto `input_audio_buffer.speech_started` Exemplo

```json
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

#### `input_audio_buffer.speech_stopped`

Retornado no modo `server_vad` quando o servidor detecta o fim da fala.

*   `audio_end_ms`: `integer` - Milissegundos desde o início da sessão quando a fala parou.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da mensagem do usuário que será criado.
*   `type`: `string` - Deve ser `input_audio_buffer.speech_stopped`.

##### Objeto `input_audio_buffer.speech_stopped` Exemplo

```json
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

#### `response.created`

Retornado quando uma nova Resposta é criada.

*   `event_id`: `string` - ID único do evento do servidor.
*   `response`: `object` - O recurso de resposta.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `id`, `object`, `status`, `output`, `usage`)</details>
*   `type`: `string` - Deve ser `response.created`.

##### Objeto `response.created` Exemplo

```json
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

#### `response.done`

Retornado quando uma Resposta termina de transmitir.

*   `event_id`: `string` - ID único do evento do servidor.
*   `response`: `object` - O recurso de resposta (sem dados de áudio brutos).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `type`: `string` - Deve ser `response.done`.

##### Objeto `response.done` Exemplo

```json
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [
            {
                "id": "msg_006",
                "object": "realtime.item",
                "type": "message",
                "status": "completed",
                "role": "assistant",
                "content": [
                    {
                        "type": "text",
                        "text": "Sure, how can I assist you today?"
                    }
                ]
            }
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

#### `response.output_item.added`

Retornado quando um novo Item é criado durante a geração da Resposta.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item`: `object` - O item adicionado.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.output_item.added`.

##### Objeto `response.output_item.added` Exemplo

```json
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

#### `response.output_item.done`

Retornado quando um Item termina de transmitir.

*   `event_id`: `string` - ID único do evento do servidor.
*   `item`: `object` - O item concluído.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.output_item.done`.

##### Objeto `response.output_item.done` Exemplo

```json
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "Sure, I can help with that."
            }
        ]
    }
}
```

#### `response.content_part.added`

Retornado quando uma nova parte de conteúdo é adicionada a um item de mensagem do assistente.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `part`: `object` - A parte do conteúdo adicionada.
    *   <details><summary>Mostrar propriedades</summary> (Ex: tipo `text`, `audio`)</details>
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.content_part.added`.

##### Objeto `response.content_part.added` Exemplo

```json
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

#### `response.content_part.done`

Retornado quando uma parte de conteúdo termina de transmitir.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `part`: `object` - A parte do conteúdo concluída.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.content_part.done`.

##### Objeto `response.content_part.done` Exemplo

```json
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

#### `response.text.delta`

Retornado quando o valor de texto de uma parte de conteúdo "text" é atualizado.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `delta`: `string` - O delta de texto.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.text.delta`.

##### Objeto `response.text.delta` Exemplo

```json
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

#### `response.text.done`

Retornado quando o valor de texto de uma parte de conteúdo "text" termina de transmitir.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `text`: `string` - O conteúdo de texto final.
*   `type`: `string` - Deve ser `response.text.done`.

##### Objeto `response.text.done` Exemplo

```json
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

#### `response.audio_transcript.delta`

Retornado quando a transcrição gerada pelo modelo da saída de áudio é atualizada.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `delta`: `string` - O delta da transcrição.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.audio_transcript.delta`.

##### Objeto `response.audio_transcript.delta` Exemplo

```json
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

#### `response.audio_transcript.done`

Retornado quando a transcrição gerada pelo modelo da saída de áudio termina de transmitir.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `transcript`: `string` - A transcrição final do áudio.
*   `type`: `string` - Deve ser `response.audio_transcript.done`.

##### Objeto `response.audio_transcript.done` Exemplo

```json
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

#### `response.audio.delta`

Retornado quando o áudio gerado pelo modelo é atualizado.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `delta`: `string` - Delta de dados de áudio codificados em Base64.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.audio.delta`.

##### Objeto `response.audio.delta` Exemplo

```json
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

#### `response.audio.done`

Retornado quando o áudio gerado pelo modelo é concluído.

*   `content_index`: `integer` - Índice da parte do conteúdo.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.audio.done`.

##### Objeto `response.audio.done` Exemplo

```json
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

#### `response.function_call_arguments.delta`

Retornado quando os argumentos da chamada de função gerados pelo modelo são atualizados.

*   `call_id`: `string` - O ID da chamada de função.
*   `delta`: `string` - O delta dos argumentos como uma string JSON.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da chamada de função.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.function_call_arguments.delta`.

##### Objeto `response.function_call_arguments.delta` Exemplo

```json
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

#### `response.function_call_arguments.done`

Retornado quando os argumentos da chamada de função gerados pelo modelo terminam de transmitir.

*   `arguments`: `string` - Os argumentos finais como uma string JSON.
*   `call_id`: `string` - O ID da chamada de função.
*   `event_id`: `string` - ID único do evento do servidor.
*   `item_id`: `string` - ID do item da chamada de função.
*   `output_index`: `integer` - Índice do item de saída.
*   `response_id`: `string` - ID da Resposta.
*   `type`: `string` - Deve ser `response.function_call_arguments.done`.

##### Objeto `response.function_call_arguments.done` Exemplo

```json
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

#### `transcription_session.updated`

Retornado quando uma sessão de transcrição é atualizada com um evento `transcription_session.update`.

*   `event_id`: `string` - ID único do evento do servidor.
*   `session`: `object` - Uma nova configuração de sessão de transcrição Realtime.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como no [objeto Transcription Session](#the-transcription-session-object))</details>
*   `type`: `string` - Deve ser `transcription_session.updated`.

##### Objeto `transcription_session.updated` Exemplo

```json
{
  "event_id": "event_5678",
  "type": "transcription_session.updated",
  "session": {
    "id": "sess_001",
    "object": "realtime.transcription_session",
    "input_audio_format": "pcm16",
    "input_audio_transcription": {
      "model": "gpt-4o-transcribe",
      "prompt": "",
      "language": ""
    },
    "turn_detection": {
      "type": "server_vad",
      "threshold": 0.5,
      "prefix_padding_ms": 300,
      "silence_duration_ms": 500,
      "create_response": true
    },
    "input_audio_noise_reduction": {
      "type": "near_field"
    },
    "include": [
      "item.input_audio_transcription.avg_logprob" // Exemplo mostra avg_logprob, não logprobs como no evento de cliente
    ]
  }
}
```

#### `rate_limits.updated`

Emitido no início de uma Resposta para indicar os limites de taxa atualizados.

*   `event_id`: `string` - ID único do evento do servidor.
*   `rate_limits`: `array` - Lista de informações de limite de taxa.
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `name`, `limit`, `remaining`, `reset_seconds`)</details>
*   `type`: `string` - Deve ser `rate_limits.updated`.

##### Objeto `rate_limits.updated` Exemplo

```json
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [
        {
            "name": "requests",
            "limit": 1000,
            "remaining": 999,
            "reset_seconds": 60
        },
        {
            "name": "tokens",
            "limit": 50000,
            "remaining": 49950,
            "reset_seconds": 60
        }
    ]
}
```

---

## Áudio

Aprenda como transformar áudio em texto ou texto em áudio.

**Guia relacionado:** [Speech to text](https://platform.openai.com/docs/guides/speech-to-text)

### Criar fala (Speech)

**POST** `/v1/audio/speech`

Gera áudio a partir do texto de entrada.

#### Corpo da Requisição

*   `input`: `string` - **Obrigatório**
    *   O texto para gerar áudio. Comprimento máximo de 4096 caracteres.
*   `model`: `string` - **Obrigatório**
    *   Um dos modelos TTS disponíveis: `tts-1`, `tts-1-hd` ou `gpt-4o-mini-tts`.
*   `voice`: `string` - **Obrigatório**
    *   A voz a ser usada. Vozes suportadas: `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer` e `verse`. [Previews das vozes](https://platform.openai.com/docs/guides/speech-to-text/overview#voice-options).
*   `instructions`: `string` - *Opcional*
    *   Controle a voz do seu áudio gerado com instruções adicionais. Não funciona com `tts-1` ou `tts-1-hd`.
*   `response_format`: `string` - *Opcional* - **Padrão:** `mp3`
    *   O formato do áudio. Formatos suportados: `mp3`, `opus`, `aac`, `flac`, `wav` e `pcm`.
*   `speed`: `number` - *Opcional* - **Padrão:** `1`
    *   A velocidade do áudio gerado. Selecione um valor de 0.25 a 4.0. 1.0 é o padrão.

#### Retorna

O conteúdo do arquivo de áudio.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-mini-tts",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

*(A resposta é o próprio arquivo de áudio binário)*

---

### Criar transcrição

**POST** `/v1/audio/transcriptions`

Transcreve áudio para o idioma de entrada.

#### Corpo da Requisição

*   `file`: `file` - **Obrigatório**
    *   O objeto do arquivo de áudio (não o nome do arquivo) para transcrever, em um destes formatos: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav` ou `webm`.
*   `model`: `string` - **Obrigatório**
    *   ID do modelo a ser usado. Opções: `gpt-4o-transcribe`, `gpt-4o-mini-transcribe` e `whisper-1`.
*   `include[]`: `array` - *Opcional*
    *   Informações adicionais para incluir na resposta da transcrição. `logprobs` retornará as probabilidades logarítmicas dos tokens. `logprobs` funciona apenas com `response_format` definido como `json` e apenas com os modelos `gpt-4o-transcribe` e `gpt-4o-mini-transcribe`.
*   `language`: `string` - *Opcional*
    *   O idioma do áudio de entrada. Fornecer o idioma no formato ISO-639-1 (ex: `en`) melhorará a precisão e a latência.
*   `prompt`: `string` - *Opcional*
    *   Um texto opcional para guiar o estilo do modelo ou continuar um segmento de áudio anterior. O prompt deve corresponder ao idioma do áudio.
*   `response_format`: `string` - *Opcional* - **Padrão:** `json`
    *   O formato da saída, em uma destas opções: `json`, `text`, `srt`, `verbose_json` ou `vtt`. Para `gpt-4o-transcribe` e `gpt-4o-mini-transcribe`, o único formato suportado é `json`.
*   `stream`: `boolean` ou `null` - *Opcional* - **Padrão:** `false`
    *   Se `true`, os dados da resposta do modelo serão transmitidos. Veja a seção [Streaming](https://platform.openai.com/docs/guides/speech-to-text/streaming) do guia Speech-to-Text. *Nota: Streaming não é suportado para o modelo `whisper-1`.*
*   `temperature`: `number` - *Opcional* - **Padrão:** `0`
    *   A temperatura de amostragem, entre 0 e 1. (Mesma descrição de outros endpoints).
*   `timestamp_granularities[]`: `array` - *Opcional* - **Padrão:** `segment`
    *   As granularidades de timestamp a serem preenchidas. `response_format` deve ser `verbose_json`. Opções suportadas: `word`, `segment`. *Nota: Não há latência adicional para timestamps de segmento, mas gerar timestamps de palavra incorre em latência adicional.*

#### Retorna

O objeto de transcrição, um objeto de transcrição verboso ou um stream de eventos de transcrição.

#### Exemplos

##### Exemplo: Padrão

```bash
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="gpt-4o-transcribe"
```

```json
# Resposta
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

> *(Nota: Exemplos para Streaming, Logprobs, Word timestamps, Segment timestamps não foram fornecidos no texto original, mas seriam colocados aqui se estivessem)*

---

### Criar tradução

**POST** `/v1/audio/translations`

Traduz áudio para inglês.

#### Corpo da Requisição

*   `file`: `file` - **Obrigatório**
    *   O objeto do arquivo de áudio (não o nome do arquivo) para traduzir, em um destes formatos: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav` ou `webm`.
*   `model`: `string` ou `"whisper-1"` - **Obrigatório**
    *   ID do modelo a ser usado. Apenas `whisper-1` está disponível atualmente.
*   `prompt`: `string` - *Opcional*
    *   Um texto opcional para guiar o estilo do modelo ou continuar um segmento de áudio anterior. O prompt deve estar em inglês.
*   `response_format`: `string` - *Opcional* - **Padrão:** `json`
    *   O formato da saída: `json`, `text`, `srt`, `verbose_json` ou `vtt`.
*   `temperature`: `number` - *Opcional* - **Padrão:** `0`
    *   A temperatura de amostragem, entre 0 e 1. (Mesma descrição de outros endpoints).

#### Retorna

O texto traduzido.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

#### Resposta

```json
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

---

### O objeto Transcription (JSON)

Representa uma resposta de transcrição retornada pelo modelo.

*   `logprobs`: `array`
    *   As probabilidades logarítmicas dos tokens na transcrição. Retornado apenas com `gpt-4o-transcribe` e `gpt-4o-mini-transcribe` se `logprobs` for adicionado ao array `include`.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `text`: `string`
    *   O texto transcrito.

#### Objeto Transcription (JSON) Exemplo

```json
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
  // "logprobs": [...] // Não incluído no exemplo padrão
}
```

---

### O objeto Transcription (Verbose JSON)

Representa uma resposta de transcrição json verbosa retornada pelo modelo.

*   `duration`: `number`
    *   A duração do áudio de entrada.
*   `language`: `string`
    *   O idioma do áudio de entrada.
*   `segments`: `array`
    *   Segmentos do texto transcrito e seus detalhes correspondentes.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `id`, `seek`, `start`, `end`, `text`, `tokens`, `temperature`, `avg_logprob`, `compression_ratio`, `no_speech_prob`)</details>
*   `text`: `string`
    *   O texto transcrito.
*   `words`: `array`
    *   Palavras extraídas e seus timestamps correspondentes. (Presente apenas se `timestamp_granularities` inclui `word`)
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `word`, `start`, `end`)</details>

#### Objeto Transcription (Verbose JSON) Exemplo

```json
{
  // "task": "transcribe", // Não listado nas propriedades, mas presente no exemplo
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 3.319999933242798,
      "text": " The beach was a popular spot on a hot summer day.",
      "tokens": [
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2860786020755768,
      "compression_ratio": 1.2363636493682861,
      "no_speech_prob": 0.00985979475080967
    },
    // ... mais segmentos ...
  ],
  // "words": [...] // Não incluído no exemplo padrão
}
```

---

### Evento de Stream (transcript.text.delta)

Emitido quando há um delta de texto adicional.

*   `delta`: `string` - O delta de texto transcrito adicionalmente.
*   `logprobs`: `array` - Log probabilidades do delta (se incluído na requisição).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `type`: `string` - Sempre `transcript.text.delta`.

#### Evento de Stream (transcript.text.delta) Exemplo

```json
{
  "type": "transcript.text.delta",
  "delta": " wonderful"
  // "logprobs": [...] // Não incluído no exemplo
}
```

---

### Evento de Stream (transcript.text.done)

Emitido quando a transcrição está completa.

*   `logprobs`: `array` - Log probabilidades dos tokens individuais (se incluído na requisição).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `text`: `string` - O texto que foi transcrito.
*   `type`: `string` - Sempre `transcript.text.done`.

#### Evento de Stream (transcript.text.done) Exemplo

```json
{
  "type": "transcript.text.done",
  "text": "I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world."
  // "logprobs": [...] // Não incluído no exemplo
}
```

---

## Embeddings

Obtenha uma representação vetorial de uma entrada fornecida que pode ser facilmente consumida por modelos de aprendizado de máquina e algoritmos.

**Guia relacionado:** [Embeddings](https://platform.openai.com/docs/guides/embeddings)

### Criar embeddings

**POST** `/v1/embeddings`

Cria um vetor de embedding representando o texto de entrada.

#### Corpo da Requisição

*   `input`: `string` ou `array` - **Obrigatório**
    *   Texto de entrada para embutir, codificado como uma string ou array de tokens. Para embutir múltiplas entradas em uma única requisição, passe um array de strings ou array de arrays de tokens. A entrada não deve exceder o máximo de tokens de entrada para o modelo (8192 tokens para `text-embedding-ada-002`), não pode ser uma string vazia, e qualquer array deve ter 2048 dimensões ou menos. [Exemplo de código Python para contar tokens](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb). Alguns modelos também podem impor um limite no número total de tokens somados entre as entradas.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `model`: `string` - **Obrigatório**
    *   ID do modelo a ser usado. Use a API [List models](#list-models) ou veja a [Visão geral dos modelos](https://platform.openai.com/docs/models).
*   `dimensions`: `integer` - *Opcional*
    *   O número de dimensões que os embeddings de saída resultantes devem ter. Suportado apenas em `text-embedding-3` e modelos posteriores.
*   `encoding_format`: `string` - *Opcional* - **Padrão:** `float`
    *   O formato para retornar os embeddings. Pode ser `float` ou `base64`.
*   `user`: `string` - *Opcional*
    *   Um identificador único representando seu usuário final. [Saiba mais](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

#### Retorna

Uma lista de objetos [embedding](#the-embedding-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        // ... (1536 floats no total para ada-002)
        -0.0028842222
      ],
      "index": 0
    }
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

---

### O objeto Embedding

Representa um vetor de embedding retornado pelo endpoint de embedding.

*   `embedding`: `array`
    *   O vetor de embedding, que é uma lista de floats. O comprimento do vetor depende do modelo, conforme listado no [guia de embedding](https://platform.openai.com/docs/guides/embeddings/embedding-models).
*   `index`: `integer`
    *   O índice do embedding na lista de embeddings.
*   `object`: `string`
    *   O tipo de objeto, que é sempre `"embedding"`.

#### Objeto Embedding Exemplo

```json
{
  "object": "embedding",
  "embedding": [
    0.0023064255,
    -0.009327292,
    // ... (1536 floats no total para ada-002)
    -0.0028842222
  ],
  "index": 0
}
```

---

## Evals

Crie, gerencie e execute evals na plataforma OpenAI.

**Guia relacionado:** [Evals](https://platform.openai.com/docs/guides/evals)

### Criar eval

**POST** `/v1/evals`

Cria a estrutura de uma avaliação que pode ser usada para testar o desempenho de um modelo. Uma avaliação é um conjunto de critérios de teste e uma fonte de dados. Após criar uma avaliação, você pode executá-la em diferentes modelos e parâmetros de modelo. Suportamos vários tipos de avaliadores (graders) e fontes de dados. Para mais informações, consulte o [guia Evals](https://platform.openai.com/docs/guides/evals).

#### Corpo da Requisição

*   `data_source_config`: `object` - **Obrigatório**
    *   A configuração para a fonte de dados usada para as execuções da avaliação.
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `stored_completions`, `custom`)</details>
*   `testing_criteria`: `array` - **Obrigatório**
    *   Uma lista de avaliadores (graders) para todas as execuções de eval neste grupo.
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `label_model`, `string_check`)</details>
*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição de outros endpoints)
*   `name`: `string` - *Opcional*
    *   O nome da avaliação.
*   `share_with_openai`: `boolean` - *Opcional* - **Padrão:** `false`
    *   Indica se a avaliação é compartilhada com a OpenAI.

#### Retorna

O objeto [Eval](#the-eval-object) criado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "name": "Sentiment",
        "data_source_config": {
          "type": "stored_completions",
          "metadata": {
              "usecase": "chatbot"
          }
        },
        "testing_criteria": [
          {
            "type": "label_model",
            "model": "o3-mini",
            "input": [
              {
                "role": "developer",
                "content": "Classify the sentiment of the following statement as one of \'positive\', \'neutral\', or \'negative\'"
              },
              {
                "role": "user",
                "content": "Statement: {{item.input}}"
              }
            ],
            "passing_labels": [
              "positive"
            ],
            "labels": [
              "positive",
              "neutral",
              "negative"
            ],
            "name": "Example label grader"
          }
        ],
        "share_with_openai": false,
        "metadata": {
            "description": "An eval for sentiment analysis"
        }
      }'
```

#### Resposta

```json
{
  "object": "eval",
  "id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
  "data_source_config": {
    "type": "stored_completions",
    "metadata": {
      "usecase": "chatbot"
    },
    "schema": { // O schema é inferido ou padrão, não estava na requisição
      "type": "object",
      "properties": {
        "item": {
          "type": "object"
        },
        "sample": {
          "type": "object"
        }
      },
      "required": [
        "item",
        "sample"
      ]
    }
  },
  "testing_criteria": [
    {
      "name": "Example label grader",
      "type": "label_model",
      "model": "o3-mini",
      "input": [ // Formato de input foi transformado para a estrutura interna
        {
          "type": "message",
          "role": "developer",
          "content": {
            "type": "input_text",
            "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
          }
        },
        {
          "type": "message",
          "role": "user",
          "content": {
            "type": "input_text",
            "text": "Statement: {{item.input}}"
          }
        }
      ],
      "passing_labels": [
        "positive"
      ],
      "labels": [
        "positive",
        "neutral",
        "negative"
      ]
      // "sampling_params": null // Adicionado na resposta, não na requisição
    }
  ],
  "name": "Sentiment",
  "created_at": 1740110490,
  "metadata": {
    "description": "An eval for sentiment analysis"
  },
  "share_with_openai": false
}
```

---

### Obter um eval

**GET** `/v1/evals/{eval_id}`

Obtém uma avaliação por ID.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório**
    *   O ID da avaliação a ser recuperada.

#### Retorna

O objeto [Eval](#the-eval-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "eval",
  "id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "data_source_config": {
    "type": "custom",
    "schema": {
      "type": "object",
      "properties": {
        "item": {
          "type": "object",
          "properties": {
            "input": {
              "type": "string"
            },
            "ground_truth": {
              "type": "string"
            }
          },
          "required": [
            "input",
            "ground_truth"
          ]
        }
      },
      "required": [
        "item"
      ]
    }
  },
  "testing_criteria": [
    {
      "name": "String check",
      "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2", // ID interno do grader
      "type": "string_check",
      "input": "{{item.input}}",
      "reference": "{{item.ground_truth}}",
      "operation": "eq"
    }
  ],
  "name": "External Data Eval",
  "created_at": 1739314509,
  "metadata": {},
  "share_with_openai": false
}
```

---

### Atualizar um eval

**POST** `/v1/evals/{eval_id}`

Atualiza certas propriedades de uma avaliação.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório**
    *   O ID da avaliação a ser atualizada.

#### Corpo da Requisição

*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição de outros endpoints)
*   `name`: `string` - *Opcional*
    *   Renomeia a avaliação.

#### Retorna

O objeto [Eval](#the-eval-object) correspondente à versão atualizada.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"name": "Updated Eval", "metadata": {"description": "Updated description"}}'
```

#### Resposta

```json
{
  "object": "eval",
  "id": "eval_67abd54d9b0081909a86353f6fb9317a",
  // ... (data_source_config e testing_criteria permanecem os mesmos)
  "name": "Updated Eval", // Nome atualizado
  "created_at": 1739314509,
  "metadata": {"description": "Updated description"}, // Metadata atualizada
  "share_with_openai": false
}
```

---

### Excluir um eval

**DELETE** `/v1/evals/{eval_id}`

Exclui uma avaliação.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório**
    *   O ID da avaliação a ser excluída.

#### Retorna

Um objeto de confirmação de exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "eval.deleted",
  "deleted": true,
  "eval_id": "eval_abc123" // ID da eval excluída
}
```

---

### Listar evals

**GET** `/v1/evals`

Lista avaliações para um projeto.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de evals a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `asc` - Ordem de classificação (`asc` ou `desc`).
*   `order_by`: `string` - *Opcional* - **Padrão:** `created_at` - Campo para ordenar (`created_at` ou `updated_at`).

#### Retorna

Uma lista de evals correspondentes aos filtros especificados.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals?limit=1 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "object": "eval",
      "data_source_config": {
        "type": "stored_completions",
        "metadata": {
          "usecase": "push_notifications_summarizer"
        },
        "schema": {
            // ... schema ...
        }
      },
      "testing_criteria": [
        {
          "name": "Push Notification Summary Grader",
          "id": "Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673",
          "type": "label_model",
          "model": "o3-mini",
          "input": [
            // ... input messages ...
          ],
          "passing_labels": [
            "correct"
          ],
          "labels": [
            "correct",
            "incorrect"
          ],
          "sampling_params": null
        }
      ],
      "name": "Push Notification Summary Grader",
      "created_at": 1739314509,
      "metadata": {
        "description": "A stored completions eval for push notification summaries"
      },
      "share_with_openai": false
    }
    // ... mais evals podem estar aqui se limit > 1
  ],
  "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "last_id": "eval_67aa884cf6688190b58f657d4441c8b7", // ID do último item na página
  "has_more": true // Indica se há mais páginas
}
```

---

### Obter execuções de eval (Get eval runs)

**GET** `/v1/evals/{eval_id}/runs`

Obtém uma lista de execuções para uma avaliação.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório**
    *   O ID da avaliação para recuperar execuções.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de execuções a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `asc` - Ordem de classificação (`asc` ou `desc`).
*   `status`: `string` - *Opcional* - Filtrar execuções por status (`queued`, `in_progress`, `failed`, `completed`, `canceled`).

#### Retorna

Uma lista de objetos [EvalRun](#the-eval-run-object) correspondentes ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "eval.run",
      "id": "evalrun_67e0c7d31560819090d60c0780591042",
      "eval_id": "eval_67e0c726d560819083f19a957c4c640b",
      "report_url": "https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b",
      "status": "completed",
      "model": "o3-mini",
      "name": "bulk_with_negative_examples_o3-mini",
      "created_at": 1742784467,
      "result_counts": {
        "total": 1,
        "errored": 0,
        "failed": 0,
        "passed": 1
      },
      "per_model_usage": [
        {
          "model_name": "o3-mini",
          "invocation_count": 1,
          "prompt_tokens": 563,
          "completion_tokens": 874,
          "total_tokens": 1437,
          "cached_tokens": 0
        }
      ],
      "per_testing_criteria_results": [
        {
          "testing_criteria": "Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1",
          "passed": 1,
          "failed": 0
        }
      ],
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            // ... conteúdo da fonte de dados ...
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            // ... template de mensagens ...
          ]
        },
        "model": "o3-mini",
        "sampling_params": null
      },
      "error": null,
      "metadata": {}
    }
    // ... mais execuções ...
  ],
  "first_id": "evalrun_67e0c7d31560819090d60c0780591042",
  "last_id": "evalrun_67e0c7d31560819090d60c0780591042", // Exemplo tinha o mesmo ID, pode ser diferente
  "has_more": true
}
```

---

### Obter uma execução de eval (Get an eval run)

**GET** `/v1/evals/{eval_id}/runs/{run_id}`

Obtém uma execução de avaliação por ID.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação.
*   `run_id`: `string` - **Obrigatório** - ID da execução a ser recuperada.

#### Retorna

O objeto [EvalRun](#the-eval-run-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "eval.run",
  "id": "evalrun_67abd54d60ec8190832b46859da808f7",
  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
  "status": "queued",
  "model": "gpt-4o-mini",
  "name": "gpt-4o-mini",
  "created_at": 1743092069,
  "result_counts": {
    "total": 0,
    "errored": 0,
    "failed": 0,
    "passed": 0
  },
  "per_model_usage": null,
  "per_testing_criteria_results": null,
  "data_source": {
    "type": "completions",
    "source": {
      "type": "file_content",
      "content": [
        // ... lista de itens de dados ...
      ]
    },
    "input_messages": {
      "type": "template",
      "template": [
        // ... template de mensagens ...
      ]
    },
    "model": "gpt-4o-mini",
    "sampling_params": {
      "seed": 42,
      "temperature": 1.0,
      "top_p": 1.0,
      "max_completions_tokens": 2048
    }
  },
  "error": null,
  "metadata": {}
}
```

---

### Criar execução de eval (Create eval run)

**POST** `/v1/evals/{eval_id}/runs`

Cria uma nova execução de avaliação. Este é o endpoint que iniciará a avaliação (grading).

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação para criar uma execução.

#### Corpo da Requisição

*   `data_source`: `object` - **Obrigatório** - Detalhes sobre a fonte de dados da execução.
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `completions`, `custom`; pode incluir `source`, `input_messages`, `model`, `sampling_params`)</details>
*   `metadata`: `map` - *Opcional* - Conjunto de 16 pares chave-valor.
*   `name`: `string` - *Opcional* - O nome da execução.

#### Retorna

O objeto [EvalRun](#the-eval-run-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \
  -X POST \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "name":"gpt-4o-mini",
        "data_source":{
          "type":"completions",
          "input_messages":{
            "type":"template",
            "template":[
              {"role":"developer","content":"Categorize a given news headline..."},
              {"role":"user","content":"{{item.input}}"}
             ]
          },
          "sampling_params":{"temperature":1,"max_completions_tokens":2048,"top_p":1,"seed":42},
          "model":"gpt-4o-mini",
          "source":{
            "type":"file_content",
            "content":[{"item":{"input":"Tech Company Launches Advanced Artificial Intelligence Platform","ground_truth":"Technology"}}]
          }
        }
      }'
```

#### Resposta

```json
{
  "object": "eval.run",
  "id": "evalrun_67e57965b480819094274e3a32235e4c",
  "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
  "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c",
  "status": "queued",
  "model": "gpt-4o-mini",
  "name": "gpt-4o-mini",
  "created_at": 1743092069,
  "result_counts": {
    "total": 0, // Inicialmente 0
    "errored": 0,
    "failed": 0,
    "passed": 0
  },
  "per_model_usage": null, // Calculado após conclusão
  "per_testing_criteria_results": null, // Calculado após conclusão
  "data_source": {
    // ... detalhes da fonte de dados da requisição ...
  },
  "error": null,
  "metadata": {}
}
```

---

### Cancelar execução de eval (Cancel eval run)

**POST** `/v1/evals/{eval_id}/runs/{run_id}/cancel`

Cancela uma execução de avaliação em andamento.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação.
*   `run_id`: `string` - **Obrigatório** - ID da execução a ser cancelada.

#### Retorna

O objeto [EvalRun](#the-eval-run-object) atualizado refletindo que a execução foi cancelada.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \
  -X POST \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "eval.run",
  "id": "evalrun_67abd54d60ec8190832b46859da808f7",
  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "report_url": "...",
  "status": "canceled", // Status atualizado
  "model": "gpt-4o-mini",
  "name": "gpt-4o-mini",
  "created_at": 1743092069,
  // ... restante do objeto eval run ...
}
```

---

### Excluir execução de eval (Delete eval run)

**DELETE** `/v1/evals/{eval_id}/runs/{run_id}`

Exclui uma execução de eval.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação.
*   `run_id`: `string` - **Obrigatório** - ID da execução a ser excluída.

#### Retorna

Um objeto contendo o status da operação de exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "eval.run.deleted",
  "deleted": true,
  "run_id": "evalrun_abc456" // ID da execução excluída
}
```

---

### Obter um item de saída de uma execução de eval

**GET** `/v1/evals/{eval_id}/runs/{run_id}/output_items/{output_item_id}`

Obtém um item de saída de execução de avaliação por ID.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação.
*   `output_item_id`: `string` - **Obrigatório** - ID do item de saída.
*   `run_id`: `string` - **Obrigatório** - ID da execução.

#### Retorna

O objeto [EvalRunOutputItem](#the-eval-run-output-item-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "eval.run.output_item",
  "id": "outputitem_67e5796c28e081909917bf79f6e6214d", // O ID no exemplo é diferente do path
  "created_at": 1743092076,
  "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "status": "pass", // pass, fail, error
  "datasource_item_id": 5, // Índice ou ID do item na fonte de dados
  "datasource_item": { // O item original da fonte de dados
    "input": "Stock Markets Rally After Positive Economic Data Released",
    "ground_truth": "Markets"
  },
  "results": [ // Resultados dos critérios de teste (graders)
    {
      "name": "String check-a2486074-d803-4445-b431-ad2262e85d47", // ID interno do grader
      "sample": null, // Amostra do grader, se aplicável
      "passed": true,
      "score": 1.0
    }
  ],
  "sample": { // Amostra da execução do modelo para este item
    "input": [
      // ... mensagens de entrada para o modelo ...
    ],
    "output": [
      // ... mensagem de saída do modelo ...
    ],
    "finish_reason": "stop",
    "model": "gpt-4o-mini-2024-07-18",
    "usage": {
      "total_tokens": 325,
      "completion_tokens": 2,
      "prompt_tokens": 323,
      "cached_tokens": 0
    },
    "error": null,
    "temperature": 1.0,
    "max_completion_tokens": 2048,
    "top_p": 1.0,
    "seed": 42
  }
}
```

---

### Obter itens de saída de execução de eval (Get eval run output items)

**GET** `/v1/evals/{eval_id}/runs/{run_id}/output_items`

Obtém uma lista de itens de saída para uma execução de avaliação.

#### Parâmetros de Caminho

*   `eval_id`: `string` - **Obrigatório** - ID da avaliação.
*   `run_id`: `string` - **Obrigatório** - ID da execução.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de itens a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `asc` - Ordem de classificação (`asc` ou `desc`).
*   `status`: `string` - *Opcional* - Filtrar itens por status (`failed` ou `pass`).

#### Retorna

Uma lista de objetos [EvalRunOutputItem](#the-eval-run-output-item-object) correspondentes ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "eval.run.output_item",
      "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "created_at": 1743092076,
      "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a", // Note: O exemplo tem eval_id diferente do path
      "status": "pass",
      "datasource_item_id": 5,
      "datasource_item": { /* ... */ },
      "results": [ /* ... */ ],
      "sample": { /* ... */ }
    }
    // ... mais itens de saída ...
  ],
  "first_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
  "last_id": "outputitem_67e5796c28e081909917bf79f6e6214d", // Exemplo tinha o mesmo ID
  "has_more": true // ou false
}
```

---

### O objeto Eval

Um objeto Eval com uma configuração de fonte de dados e critérios de teste.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `data_source_config`: `object` - Configuração das fontes de dados.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `id`: `string` - Identificador único.
*   `metadata`: `map` - Metadados.
*   `name`: `string` - Nome da avaliação.
*   `object`: `string` - Tipo do objeto (`eval`).
*   `share_with_openai`: `boolean` - Se compartilhado com OpenAI.
*   `testing_criteria`: `array` - Lista de critérios de teste (graders).
    *   <details><summary>Mostrar tipos possíveis</summary></details>

#### Objeto Eval Exemplo

```json
{
  "object": "eval",
  "id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "data_source_config": {
    "type": "custom",
    "item_schema": { // Este campo não está na definição padrão, mas sim 'schema'
      "type": "object",
      "properties": {
        "label": {"type": "string"},
      },
      "required": ["label"]
    },
    "include_sample_schema": true // Este campo não está na definição padrão
  },
  "testing_criteria": [
    {
      "name": "My string check grader",
      "type": "string_check",
      "input": "{{sample.output_text}}",
      "reference": "{{item.label}}",
      "operation": "eq",
    }
  ],
  "name": "External Data Eval",
  "created_at": 1739314509,
  "metadata": {
    "test": "synthetics",
  },
  "share_with_openai": false
}
```

---

### O objeto Eval Run

Um esquema representando uma execução de avaliação.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `data_source`: `object` - Informações sobre a fonte de dados da execução.
*   `error`: `object` - Objeto de erro, se a execução falhou.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `eval_id`: `string` - ID da avaliação associada.
*   `id`: `string` - Identificador único da execução.
*   `metadata`: `map` - Metadados.
*   `model`: `string` - Modelo avaliado, se aplicável.
*   `name`: `string` - Nome da execução.
*   `object`: `string` - Tipo do objeto (`eval.run`).
*   `per_model_usage`: `array` - Estatísticas de uso por modelo.
    *   <details
    <details><summary>Mostrar propriedades</summary> (Cada item tem `model_name`, `invocation_count`, `prompt_tokens`, `completion_tokens`, `total_tokens`, `cached_tokens`)</details>
*   `per_testing_criteria_results`: `array` - Resultados por critério de teste.
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `testing_criteria` (ID), `passed`, `failed`)</details>
*   `report_url`: `string` - URL para o relatório da execução no painel da UI.
*   `result_counts`: `object` - Contadores resumindo os resultados.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades: `total`, `errored`, `failed`, `passed`)</details>
*   `status`: `string` - Status da execução (`queued`, `in_progress`, `failed`, `completed`, `canceled`).

#### Objeto Eval Run Exemplo

```json
{
  "object": "eval.run",
  "id": "evalrun_67e57965b480819094274e3a32235e4c",
  "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
  "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c",
  "status": "queued", // Status pode mudar para completed, failed, etc.
  "model": "gpt-4o-mini",
  "name": "gpt-4o-mini",
  "created_at": 1743092069,
  "result_counts": { // Atualizado quando concluído
    "total": 0,
    "errored": 0,
    "failed": 0,
    "passed": 0
  },
  "per_model_usage": null, // Preenchido quando concluído
  "per_testing_criteria_results": null, // Preenchido quando concluído
  "data_source": {
    // ... detalhes da fonte de dados ...
  },
  "error": null,
  "metadata": {}
}
```

---

### O objeto Eval Run Output Item

Um esquema representando um item de saída de execução de avaliação.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `datasource_item`: `object` - Detalhes do item da fonte de dados de entrada.
*   `datasource_item_id`: `integer` - O identificador para o item da fonte de dados.
*   `eval_id`: `string` - O identificador do grupo de avaliação.
*   `id`: `string` - Identificador único do item de saída.
*   `object`: `string` - Tipo do objeto (`eval.run.output_item`).
*   `results`: `array` - Uma lista de resultados da execução da avaliação.
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `name`, `type`, `score`, `passed`)</details>
*   `run_id`: `string` - O identificador da execução da avaliação associada.
*   `sample`: `object` - Uma amostra contendo a entrada e saída da execução da avaliação.
    *   <details><summary>Mostrar propriedades</summary> (Inclui `input` (mensagens), `output` (mensagens), `finish_reason`, `model`, `usage`, `error`, `temperature`, etc.)</details>
*   `status`: `string` - O status da execução da avaliação (`pass`, `fail`, `error`).

#### Objeto Eval Run Output Item Exemplo

```json
{
  "object": "eval.run.output_item",
  "id": "outputitem_67abd55eb6548190bb580745d5644a33",
  "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
  "created_at": 1739314509,
  "status": "pass",
  "datasource_item_id": 137, // Corrigido de 5 para 137 como no exemplo
  "datasource_item": {
      "teacher": "To grade essays, I only check for style, content, and grammar.", // Exemplo diferente do anterior
      "student": "I am a student who is trying to write the best essay."
  },
  "results": [
    {
      "name": "String Check Grader", // Corrigido para corresponder ao exemplo
      "type": "string-check-grader", // Corrigido para corresponder ao exemplo
      "score": 1.0,
      "passed": true,
      // "sample": null // Removido do exemplo original
    }
  ],
  "sample": {
    "input": [
      {
        "role": "system", // Corrigido de developer para system
        "content": "You are an evaluator bot..."
        // "tool_call_id": null, // Removido do exemplo original
        // "tool_calls": null,
        // "function_call": null
      },
      {
        "role": "user",
        "content": "You are assessing..."
        // "tool_call_id": null, // Removido do exemplo original
        // "tool_calls": null,
        // "function_call": null
      }
    ],
    "output": [
      {
        "role": "assistant",
        "content": "The rubric is not clear nor concise."
        // "tool_call_id": null, // Removido do exemplo original
        // "tool_calls": null,
        // "function_call": null
      }
    ],
    "finish_reason": "stop",
    "model": "gpt-4o-2024-08-06", // Corrigido para corresponder ao exemplo
    "usage": {
      "total_tokens": 521, // Corrigido para corresponder ao exemplo
      "completion_tokens": 2, // Corrigido para corresponder ao exemplo
      "prompt_tokens": 519, // Corrigido para corresponder ao exemplo
      "cached_tokens": 0
    },
    "error": null,
    "temperature": 1.0,
    "max_completion_tokens": 2048,
    "top_p": 1.0,
    "seed": 42
  }
}
```

---

## Fine-tuning

Gerencie trabalhos de fine-tuning para adaptar um modelo aos seus dados de treinamento específicos.

**Guia relacionado:** [Fine-tune models](https://platform.openai.com/docs/guides/fine-tuning)

### Criar trabalho de fine-tuning

**POST** `/v1/fine_tuning/jobs`

Cria um trabalho de fine-tuning que inicia o processo de criação de um novo modelo a partir de um conjunto de dados fornecido.

A resposta inclui detalhes do trabalho enfileirado, incluindo o status do trabalho e o nome dos modelos ajustados (fine-tuned) após a conclusão.

[Saiba mais sobre fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)

#### Corpo da Requisição

*   `model`: `string` - **Obrigatório**
    *   O nome do modelo a ser ajustado. Você pode selecionar um dos [modelos suportados](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
*   `training_file`: `string` - **Obrigatório**
    *   O ID de um arquivo carregado que contém dados de treinamento.
    *   Veja [upload file](#upload-file) para como carregar um arquivo.
    *   Seu conjunto de dados deve ser formatado como um arquivo JSONL. Além disso, você deve carregar seu arquivo com o propósito `fine-tune`.
    *   O conteúdo do arquivo deve diferir dependendo se o modelo usa o formato de chat, completions, ou se o método de fine-tuning usa o formato de preferência.
    *   Veja o [guia de fine-tuning](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset) para mais detalhes.
*   `hyperparameters`: (**Deprecated**) `object` - *Opcional*
    *   *Obsoleto em favor de `method`. Passe sob o parâmetro `method`.*
    *   Os hiperparâmetros usados para o trabalho de fine-tuning.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `n_epochs`, `batch_size`, `learning_rate_multiplier`)</details>
*   `integrations`: `array` ou `null` - *Opcional*
    *   Uma lista de integrações para habilitar para seu trabalho de fine-tuning.
    *   <details><summary>Mostrar propriedades</summary> (Ex: tipo `wandb` com propriedades `project`, `name`, `entity`, `tags`)</details>
*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição de outros endpoints)
*   `method`: `object` - *Opcional*
    *   O método usado para fine-tuning.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades incluem `type` (`supervised` ou `preference`), e um objeto aninhado correspondente com `hyperparameters`)</details>
*   `seed`: `integer` ou `null` - *Opcional*
    *   A semente controla a reprodutibilidade do trabalho. Passar a mesma semente e parâmetros de trabalho deve produzir os mesmos resultados, mas pode diferir em casos raros. Se uma semente não for especificada, uma será gerada para você.
*   `suffix`: `string` ou `null` - *Opcional* - **Padrão:** `null`
    *   Uma string de até 64 caracteres que será adicionada ao nome do seu modelo ajustado.
    *   Por exemplo, um sufixo `"custom-model-name"` produziria um nome de modelo como `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.
*   `validation_file`: `string` ou `null` - *Opcional*
    *   O ID de um arquivo carregado que contém dados de validação.
    *   Se você fornecer este arquivo, os dados são usados para gerar métricas de validação periodicamente durante o fine-tuning. Essas métricas podem ser visualizadas no arquivo de resultados do fine-tuning. Os mesmos dados não devem estar presentes nos arquivos de treino e validação.
    *   Seu conjunto de dados deve ser formatado como um arquivo JSONL. Você deve carregar seu arquivo com o propósito `fine-tune`.
    *   Veja o [guia de fine-tuning](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset) para mais detalhes.

#### Retorna

Um objeto [fine-tuning.job](#the-fine-tuning-job-object).

#### Exemplos

##### Exemplo: Padrão

```bash
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

```json
# Resposta
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18", // Versão específica do modelo base
  "created_at": 1721764800,
  "fine_tuned_model": null, // Preenchido na conclusão
  "organization_id": "org-123",
  "result_files": [], // Preenchido na conclusão
  "status": "queued", // Status inicial
  "validation_file": null,
  "training_file": "file-abc123", // Corrigido para corresponder à requisição
  "method": { // Adicionado método padrão
    "type": "supervised",
    "supervised": {
      "hyperparameters": {
        "batch_size": "auto",
        "learning_rate_multiplier": "auto",
        "n_epochs": "auto"
      }
    }
  },
  "metadata": null
  // "hyperparameters": {} // Campo obsoleto não retornado
  // "seed": ... // Não incluído no exemplo
  // "integrations": [] // Não incluído no exemplo
}
```

> *(Nota: Exemplos para Epochs, Validation file, DPO, W&B Integration não foram fornecidos no texto original, mas seriam colocados aqui se estivessem)*

---

### Listar trabalhos de fine-tuning

**GET** `/v1/fine_tuning/jobs`

Lista os trabalhos de fine-tuning da sua organização.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de trabalhos a retornar (1-100).
*   `metadata`: `object` ou `null` - *Opcional* - Filtro de metadados opcional. Use a sintaxe `metadata[k]=v` ou defina `metadata=null`.

#### Retorna

Uma lista paginada de objetos [fine-tuning job](#the-fine-tuning-job-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": null,
      "training_file": "file-abc123",
      "metadata": {
        "key": "value"
      }
      // "method", "seed", "integrations" não incluídos no exemplo de resposta
    },
    { /* ... outro job ... */ }
  ],
  "has_more": true
}
```

---

### Listar eventos de fine-tuning

**GET** `/v1/fine_tuning/jobs/{fine_tuning_job_id}/events`

Obtém atualizações de status para um trabalho de fine-tuning.

#### Parâmetros de Caminho

*   `fine_tuning_job_id`: `string` - **Obrigatório** - ID do trabalho de fine-tuning.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de eventos a retornar (1-100).

#### Retorna

Uma lista de objetos [fine-tuning event](#the-fine-tuning-job-event-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "fine_tuning.job.event",
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
      "created_at": 1721764800, // Exemplo mostra mesmo timestamp, pode variar
      "level": "info",
      "message": "Fine tuning job successfully completed",
      "data": null,
      "type": "message"
    },
    {
      "object": "fine_tuning.job.event",
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
      "created_at": 1721764800, // Exemplo mostra mesmo timestamp, pode variar
      "level": "info",
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
      "data": null,
      "type": "message"
    }
    // ... outros eventos como 'validating files', 'running', etc.
  ],
  "has_more": true
}
```

---

### Listar checkpoints de fine-tuning

**GET** `/v1/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints`

Lista checkpoints para um trabalho de fine-tuning.

#### Parâmetros de Caminho

*   `fine_tuning_job_id`: `string` - **Obrigatório** - ID do trabalho de fine-tuning.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação (ID do último checkpoint).
*   `limit`: `integer` - *Opcional* - **Padrão:** `10` - Número de checkpoints a retornar.

#### Retorna

Uma lista de objetos [fine-tuning checkpoint](#the-fine-tuning-job-checkpoint-object) para um trabalho de fine-tuning.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "fine_tuning.job.checkpoint",
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
      "created_at": 1721764867,
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
      "metrics": {
        "full_valid_loss": 0.134,
        "full_valid_mean_token_accuracy": 0.874
        // Outras métricas podem estar presentes dependendo do job
      },
      "fine_tuning_job_id": "ftjob-abc123",
      "step_number": 2000
    },
    {
      "object": "fine_tuning.job.checkpoint",
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
      "created_at": 1721764800,
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000", // O ID interno '7q8mpxmy' difere do outro checkpoint
      "metrics": {
        "full_valid_loss": 0.167,
        "full_valid_mean_token_accuracy": 0.781
      },
      "fine_tuning_job_id": "ftjob-abc123",
      "step_number": 1000
    }
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

---

### Listar permissões de checkpoint

**GET** `/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions`

> **NOTA:** Este endpoint requer uma chave de API de administrador.

Proprietários da organização podem usar este endpoint para visualizar todas as permissões para um checkpoint de modelo ajustado.

#### Parâmetros de Caminho

*   `fine_tuned_model_checkpoint`: `string` - **Obrigatório** - O ID do checkpoint do modelo ajustado para obter permissões. (Ex: `ft:gpt-4o-mini:org:weather:B7R9VjQd:ckpt-step-2000`)

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação (ID da última permissão).
*   `limit`: `integer` - *Opcional* - **Padrão:** `10` - Número de permissões a retornar.
*   `order`: `string` - *Opcional* - **Padrão:** `descending` - Ordem de recuperação (`asc` ou `desc`).
*   `project_id`: `string` - *Opcional* - O ID do projeto para obter permissões.

#### Retorna

Uma lista de objetos [checkpoint permission](#the-fine-tuned-model-checkpoint-permission-object) para um checkpoint de modelo ajustado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd:ckpt-step-1000/permissions \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB", // ID da permissão
      "created_at": 1721764867,
      "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH" // Projeto com permissão
    },
    {
      "object": "checkpoint.permission",
      "id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
      "created_at": 1721764800,
      "project_id": "proj_iqGMw1llN8IrBb6SvvY5A1oF"
    }
  ],
  "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": false
}
```

---

### Criar permissões de checkpoint

**POST** `/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions`

> **NOTA:** Chamar este endpoint requer uma chave de API de administrador.

Isso permite que proprietários da organização compartilhem modelos ajustados com outros projetos em sua organização.

#### Parâmetros de Caminho

*   `fine_tuned_model_checkpoint`: `string` - **Obrigatório** - O ID do checkpoint do modelo ajustado.

#### Corpo da Requisição

*   `project_ids`: `array` - **Obrigatório**
    *   Os identificadores de projeto para conceder acesso.

#### Retorna

Uma lista de objetos [checkpoint permission](#the-fine-tuned-model-checkpoint-permission-object) para um checkpoint de modelo ajustado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd:ckpt-step-1000/permissions \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{"project_ids": ["proj_abGMw1llN8IrBb6SvvY5A1iH"]}'
```

#### Resposta

```json
{
  "object": "list", // O objeto de nível superior deveria ser list
  "data": [
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "created_at": 1721764867,
      "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
    }
    // Pode retornar múltiplas permissões se múltiplas foram criadas
  ],
  "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
  "has_more": false
}
```

---

### Excluir permissão de checkpoint

**DELETE** `/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions/{permission_id}`

> **NOTA:** Este endpoint requer uma chave de API de administrador.

Proprietários da organização podem usar este endpoint para excluir uma permissão para um checkpoint de modelo ajustado.

#### Parâmetros de Caminho

*   `fine_tuned_model_checkpoint`: `string` - **Obrigatório** - O ID do checkpoint do modelo ajustado.
*   `permission_id`: `string` - **Obrigatório** - O ID da permissão do checkpoint a ser excluída.

#### Retorna

O status de exclusão do objeto de permissão do checkpoint do modelo ajustado.

#### Exemplo de Requisição

```bash
curl -X DELETE https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd:ckpt-step-1000/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
```

#### Resposta

```json
{
  "object": "checkpoint.permission.deleted", // Corrigido de checkpoint.permission
  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
  "deleted": true
}
```

---

### Recuperar trabalho de fine-tuning

**GET** `/v1/fine_tuning/jobs/{fine_tuning_job_id}`

Obtém informações sobre um trabalho de fine-tuning.

[Saiba mais sobre fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)

#### Parâmetros de Caminho

*   `fine_tuning_job_id`: `string` - **Obrigatório** - O ID do trabalho de fine-tuning.

#### Retorna

O objeto [fine-tuning](#the-fine-tuning-job-object) com o ID fornecido.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123", // O ID no exemplo é diferente do path
  "model": "davinci-002", // Modelo base usado
  "created_at": 1692661014,
  "finished_at": 1692661190, // Preenchido quando concluído
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy", // Nome do modelo ajustado
  "organization_id": "org-123",
  "result_files": [
      "file-abc123" // Arquivo com resultados/métricas
  ],
  "status": "succeeded", // Status final
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": { // Obsoleto, use 'method'
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768, // Número de tokens processados
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0, // Irrelevante após conclusão
  "method": { // Método e hiperparâmetros usados
    "type": "supervised",
    "supervised": {
      "hyperparameters": {
        "n_epochs": 4,
        "batch_size": 1,
        "learning_rate_multiplier": 1.0
      }
    }
  },
  "error": null // Se status fosse 'failed', conteria detalhes do erro
}
```

---

### Cancelar fine-tuning

**POST** `/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel`

Cancela imediatamente um trabalho de fine-tuning.

#### Parâmetros de Caminho

*   `fine_tuning_job_id`: `string` - **Obrigatório** - O ID do trabalho de fine-tuning a ser cancelado.

#### Retorna

O objeto [fine-tuning](#the-fine-tuning-job-object) cancelado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "cancelled", // Status atualizado
  "validation_file": "file-abc123", // Exemplo mostra arquivo de validação
  "training_file": "file-abc123",
  // "method", "hyperparameters", etc., podem estar presentes dependendo do estado anterior
}
```

---

### Formatos de Treinamento

#### Formato de treinamento para modelos de chat usando o método `supervised`

O exemplo de treinamento por linha de um arquivo de entrada de fine-tuning para modelos de chat usando o método `supervised`.

*   `functions`: (**Deprecated**) `array` - Uma lista de funções.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `messages`: `array` - Lista de mensagens (ex: role `user`, `assistant`).
    *   <details><summary>Mostrar tipos possíveis</summary> (Pode incluir `content` ou `tool_calls`)</details>
*   `parallel_tool_calls`: `boolean` - Se habilita chamadas de ferramenta paralelas.
*   `tools`: `array` - Uma lista de ferramentas.
    *   <details><summary>Mostrar propriedades</summary></details>

##### Objeto de Treinamento (Chat Supervised) Exemplo

```json
{
  "messages": [
    { "role": "user", "content": "What is the weather in San Francisco?" },
    {
      "role": "assistant",
      "tool_calls": [
        {
          "id": "call_id",
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
          }
        }
      ]
    }
  ],
  "parallel_tool_calls": false,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
                "type": "string",
                "description": "The city and country, eg. San Francisco, USA"
            },
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
          },
          "required": ["location", "format"]
        }
      }
    }
  ]
}
```

#### Formato de treinamento para modelos de chat usando o método `preference` (DPO)

O exemplo de treinamento por linha de um arquivo de entrada de fine-tuning para modelos de chat usando o método `dpo`.

*   `input`: `object` - A entrada da conversa.
    *   <details><summary>Mostrar propriedades</summary> (Inclui `messages`)</details>
*   `non_preferred_completion`: `array` - A mensagem de conclusão não preferida.
    *   <details><summary>Mostrar tipos possíveis</summary> (Lista de mensagens, geralmente uma mensagem de `assistant`)</details>
*   `preferred_completion`: `array` - A mensagem de conclusão preferida.
    *   <details><summary>Mostrar tipos possíveis</summary> (Lista de mensagens, geralmente uma mensagem de `assistant`)</details>

##### Objeto de Treinamento (Chat Preference/DPO) Exemplo

```json
{
  "input": {
    "messages": [
      { "role": "user", "content": "What is the weather in San Francisco?" }
    ]
  },
  "preferred_completion": [
    {
      "role": "assistant",
      "content": "The weather in San Francisco is 70 degrees Fahrenheit."
    }
  ],
  "non_preferred_completion": [
    {
      "role": "assistant",
      "content": "The weather in San Francisco is 21 degrees Celsius."
    }
  ]
}
```

#### Formato de treinamento para modelos de completions

O exemplo de treinamento por linha de um arquivo de entrada de fine-tuning para modelos de completions.

*   `completion`: `string` - A conclusão desejada para este exemplo.
*   `prompt`: `string` - O prompt de entrada para este exemplo.

##### Objeto de Treinamento (Completions) Exemplo

```json
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

---

### O objeto Fine-tuning Job

O objeto `fine_tuning.job` representa um trabalho de fine-tuning que foi criado através da API.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `error`: `object` ou `null` - Detalhes sobre a falha, se houver.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `code`, `message`, `param`)</details>
*   `estimated_finish`: `integer` ou `null` - Timestamp Unix estimado de conclusão (null se não estiver em execução).
*   `fine_tuned_model`: `string` ou `null` - Nome do modelo ajustado (null se ainda em execução).
*   `finished_at`: `integer` ou `null` - Timestamp Unix de conclusão (null se ainda em execução).
*   `hyperparameters`: `object` - (**Deprecated**) Hiperparâmetros usados (apenas para `supervised`).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `id`: `string` - Identificador do objeto.
*   `integrations`: `array` ou `null` - Lista de integrações habilitadas.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `metadata`: `map` - Metadados.
*   `method`: `object` - Método usado para fine-tuning.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `model`: `string` - Modelo base sendo ajustado.
*   `object`: `string` - Tipo do objeto (`fine_tuning.job`).
*   `organization_id`: `string` - Organização proprietária.
*   `result_files`: `array` - ID(s) do(s) arquivo(s) de resultados compilados.
*   `seed`: `integer` - Semente usada.
*   `status`: `string` - Status atual (`validating_files`, `queued`, `running`, `succeeded`, `failed`, `cancelled`).
*   `trained_tokens`: `integer` ou `null` - Número total de tokens faturáveis processados (null se ainda em execução).
*   `training_file`: `string` - ID do arquivo de treinamento.
*   `validation_file`: `string` ou `null` - ID do arquivo de validação.

#### Objeto Fine-tuning Job Exemplo

```json
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [
      "file-abc123"
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": { // Campo obsoleto
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0,
  "method": { // Campo correto
    "type": "supervised",
    "supervised": {
      "hyperparameters": {
        "n_epochs": 4,
        "batch_size": 1,
        "learning_rate_multiplier": 1.0
      }
    }
  },
  "metadata": {
    "key": "value"
  }
}
```

---

### O objeto Fine-tuning Job Event

Objeto de evento do trabalho de fine-tuning.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `data`: `object` - Dados associados ao evento (geralmente vazio).
*   `id`: `string` - Identificador do objeto.
*   `level`: `string` - Nível de log do evento (`info`, `warn`, `error`).
*   `message`: `string` - Mensagem do evento.
*   `object`: `string` - Tipo do objeto (`fine_tuning.job.event`).
*   `type`: `string` - Tipo de evento (`message`, `metrics`).

#### Objeto Fine-tuning Job Event Exemplo

```json
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123",
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job",
  "data": {},
  "type": "message"
}
```

---

### O objeto Fine-tuning Job Checkpoint

O objeto `fine_tuning.job.checkpoint` representa um checkpoint de modelo para um trabalho de fine-tuning que está pronto para uso.

*   `created_at`: `integer` - Timestamp Unix de criação do checkpoint.
*   `fine_tuned_model_checkpoint`: `string` - Nome do modelo do checkpoint ajustado criado.
*   `fine_tuning_job_id`: `string` - ID do trabalho de fine-tuning do qual este checkpoint foi criado.
*   `id`: `string` - Identificador do checkpoint.
*   `metrics`: `object` - Métricas no número do passo durante o trabalho de fine-tuning.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `step`, `train_loss`, `train_mean_token_accuracy`, `valid_loss`, `valid_mean_token_accuracy`, `full_valid_loss`, `full_valid_mean_token_accuracy`)</details>
*   `object`: `string` - Tipo do objeto (`fine_tuning.job.checkpoint`).
*   `step_number`: `integer` - Número do passo em que o checkpoint foi criado.

#### Objeto Fine-tuning Job Checkpoint Exemplo

```json
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

---

### O objeto Fine-tuned Model Checkpoint Permission

O objeto `checkpoint.permission` representa uma permissão para um checkpoint de modelo ajustado.

*   `created_at`: `integer` - Timestamp Unix de criação da permissão.
*   `id`: `string` - Identificador da permissão.
*   `object`: `string` - Tipo do objeto (`checkpoint.permission`).
*   `project_id`: `string` - Identificador do projeto para o qual a permissão é concedida.

#### Objeto Fine-tuned Model Checkpoint Permission Exemplo

```json
{
  "object": "checkpoint.permission",
  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
  "created_at": 1712211699,
  "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
}
```

---

## Batch

Crie grandes lotes de requisições de API para processamento assíncrono. A API Batch retorna conclusões em 24 horas com um desconto de 50%.

**Guia relacionado:** [Batch](https://platform.openai.com/docs/guides/batch)

### Criar batch

**POST** `/v1/batches`

Cria e executa um batch a partir de um arquivo carregado de requisições.

#### Corpo da Requisição

*   `completion_window`: `string` - **Obrigatório**
    *   O período de tempo dentro do qual o batch deve ser processado. Atualmente, apenas `24h` é suportado.
*   `endpoint`: `string` - **Obrigatório**
    *   O endpoint a ser usado para todas as requisições no batch. Atualmente `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings` e `/v1/completions` são suportados. *Nota: batches `/v1/embeddings` também são restritos a um máximo de 50.000 entradas de embedding em todas as requisições no batch.*
*   `input_file_id`: `string` - **Obrigatório**
    *   O ID de um arquivo carregado que contém requisições para o novo batch.
    *   Veja [upload file](#upload-file). Seu arquivo de entrada deve ser formatado como um arquivo JSONL e carregado com o propósito `batch`. O arquivo pode conter até 50.000 requisições e ter até 200 MB de tamanho.
*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição de outros endpoints)

#### Retorna

O objeto [Batch](#the-batch-object) criado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h",
    "metadata": {
      "customer_id": "user_123456789",
      "batch_description": "Nightly eval job"
    }
  }'
```

#### Resposta

```json
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null, // Preenchido se houver erros de validação
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating", // Status inicial
  "output_file_id": null, // Preenchido na conclusão
  "error_file_id": null, // Preenchido na conclusão se houver erros
  "created_at": 1711471533,
  "in_progress_at": null, // Preenchido quando inicia
  "expires_at": null, // Preenchido quando criado
  "finalizing_at": null, // Preenchido quando começa a finalizar
  "completed_at": null, // Preenchido na conclusão
  "failed_at": null, // Preenchido se falhar
  "expired_at": null, // Preenchido se expirar
  "cancelling_at": null, // Preenchido se cancelando
  "cancelled_at": null, // Preenchido se cancelado
  "request_counts": { // Inicialmente 0
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job"
  }
}
```

---

### Recuperar batch

**GET** `/v1/batches/{batch_id}`

Recupera um batch.

#### Parâmetros de Caminho

*   `batch_id`: `string` - **Obrigatório** - ID do batch a ser recuperado.

#### Retorna

O objeto [Batch](#the-batch-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions", // Endpoint usado no batch
  "errors": null, // Erros de validação
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed", // Status atual
  "output_file_id": "file-cvaTdG", // Arquivo com saídas bem-sucedidas
  "error_file_id": "file-HOWS94", // Arquivo com saídas de erro
  "created_at": 1711471533,
  "in_progress_at": 1711471538, // Quando começou a processar
  "expires_at": 1711557933, // Quando expirará
  "finalizing_at": 1711493133, // Quando começou a finalizar
  "completed_at": 1711493163, // Quando foi concluído
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": { // Contagens finais
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job"
  }
}
```

---

### Cancelar batch

**POST** `/v1/batches/{batch_id}/cancel`

Cancela um batch em andamento. O batch ficará no status `cancelling` por até 10 minutos, antes de mudar para `cancelled`, onde terá resultados parciais (se houver) disponíveis no arquivo de saída.

#### Parâmetros de Caminho

*   `batch_id`: `string` - **Obrigatório** - ID do batch a ser cancelado.

#### Retorna

O objeto [Batch](#the-batch-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

#### Resposta

```json
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling", // Status alterado
  "output_file_id": null, // Pode ser preenchido se houver resultados parciais
  "error_file_id": null, // Pode ser preenchido se houver erros parciais
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133, // Timestamp de início do cancelamento
  "cancelled_at": null, // Preenchido quando o cancelamento é concluído
  "request_counts": { // Contagens no momento do cancelamento
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job"
  }
}
```

---

### Listar batch

**GET** `/v1/batches`

Lista os batches da sua organização.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de batches a retornar (1-100).

#### Retorna

Uma lista paginada de objetos [Batch](#the-batch-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/chat/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "completed",
      "output_file_id": "file-cvaTdG",
      "error_file_id": "file-HOWS94",
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": 1711493133,
      "completed_at": 1711493163,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 95,
        "failed": 5
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly job"
      }
    },
    { /* ... outro batch ... */ }
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

---

### O objeto Batch

*   `cancelled_at`: `integer` - Timestamp Unix de cancelamento.
*   `cancelling_at`: `integer` - Timestamp Unix de início do cancelamento.
*   `completed_at`: `integer` - Timestamp Unix de conclusão.
*   `completion_window`: `string` - Janela de tempo para processamento (`24h`).
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `endpoint`: `string` - Endpoint da API OpenAI usado.
*   `error_file_id`: `string` - ID do arquivo com saídas de erro.
*   `errors`: `object` - Erros de validação do batch.
    *   <details><summary>Mostrar propriedades</summary> (Pode incluir `code`, `message`)</details>
*   `expired_at`: `integer` - Timestamp Unix de expiração.
*   `expires_at`: `integer` - Timestamp Unix de quando expirará.
*   `failed_at`: `integer` - Timestamp Unix de falha.
*   `finalizing_at`: `integer` - Timestamp Unix de início da finalização.
*   `id`: `string` - Identificador do batch.
*   `in_progress_at`: `integer` - Timestamp Unix de início do processamento.
*   `input_file_id`: `string` - ID do arquivo de entrada.
*   `metadata`: `map` - Metadados.
*   `object`: `string` - Tipo do objeto (`batch`).
*   `output_file_id`: `string` - ID do arquivo com saídas bem-sucedidas.
*   `request_counts`: `object` - Contagem de requisições por status.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `total`, `completed`, `failed`)</details>
*   `status`: `string` - Status atual (`validating`, `failed`, `in_progress`, `finalizing`, `completed`, `expired`, `cancelling`, `cancelled`).

#### Objeto Batch Exemplo

```json
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job"
  }
}
```

---

### O objeto Request Input (Formato do arquivo de entrada)

O objeto por linha do arquivo de entrada do batch (JSONL).

*   `custom_id`: `string` - ID por requisição fornecido pelo desenvolvedor (único no batch).
*   `method`: `string` - Método HTTP (atualmente apenas `POST`).
*   `url`: `string` - URL relativa da API OpenAI (ex: `/v1/chat/completions`).
*   `body`: `object` - O corpo da requisição para o endpoint especificado na `url`.

#### Objeto Request Input Exemplo (uma linha do JSONL)

```json
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

---

### O objeto Request Output (Formato dos arquivos de saída/erro)

O objeto por linha dos arquivos de saída e erro do batch (JSONL).

*   `custom_id`: `string` - ID por requisição fornecido pelo desenvolvedor (do arquivo de entrada).
*   `error`: `object` ou `null` - Para requisições que falharam com um erro não HTTP.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades como `code`, `message`)</details>
*   `id`: `string` - ID interno da requisição do batch.
*   `response`: `object` ou `null` - A resposta da API para a requisição.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `status_code`, `request_id`, `body` - onde `body` é a resposta usual do endpoint chamado)</details>

#### Objeto Request Output Exemplo (uma linha do JSONL)

```json
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

---

## Arquivos (Files)

Arquivos são usados para carregar documentos que podem ser usados com recursos como Assistants, Fine-tuning e Batch API.

### Carregar arquivo (Upload file)

**POST** `/v1/files`

Carrega um arquivo que pode ser usado em vários endpoints. Arquivos individuais podem ter até 512 MB, e o tamanho de todos os arquivos carregados por uma organização pode ser de até 100 GB.

*   A API Assistants suporta arquivos de até 2 milhões de tokens e [tipos de arquivo específicos](https://platform.openai.com/docs/assistants/tools/file-search/supported-files).
*   A API Fine-tuning suporta apenas arquivos `.jsonl`. A entrada também tem [formatos necessários específicos](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset).
*   A API Batch suporta apenas arquivos `.jsonl` de até 200 MB. A entrada também tem um [formato necessário específico](#the-request-input-object).

Entre em contato conosco se precisar aumentar esses limites de armazenamento.

#### Corpo da Requisição

*   `file`: `file` - **Obrigatório** - O objeto File (não o nome do arquivo) a ser carregado.
*   `purpose`: `string` - **Obrigatório** - O propósito pretendido do arquivo carregado. Um de:
    *   `assistants`: Usado na API Assistants
    *   `batch`: Usado na API Batch
    *   `fine-tune`: Usado para fine-tuning
    *   `vision`: Imagens usadas para fine-tuning de visão
    *   `user_data`: Tipo de arquivo flexível para qualquer propósito
    *   `evals`: Usado para conjuntos de dados de eval

#### Retorna

O objeto [File](#the-file-object) carregado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune"
  // "status" e "status_details" são obsoletos
}
```

---

### Listar arquivos

**GET** `/v1/files`

Retorna uma lista de arquivos.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação (ID do arquivo).
*   `limit`: `integer` - *Opcional* - **Padrão:** `10000` - Número de arquivos a retornar (1-10000).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).
*   `purpose`: `string` - *Opcional* - Retornar apenas arquivos com o propósito fornecido.

#### Retorna

Uma lista de objetos [File](#the-file-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "data": [
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 175,
      "created_at": 1613677385,
      "filename": "salesOverview.pdf",
      "purpose": "assistants"
    },
    {
      "id": "file-def456", // ID diferente no exemplo original
      "object": "file",
      "bytes": 140,
      "created_at": 1613779121,
      "filename": "puppy.jsonl",
      "purpose": "fine-tune"
    }
  ],
  "object": "list"
}
```

---

### Recuperar arquivo

**GET** `/v1/files/{file_id}`

Retorna informações sobre um arquivo específico.

#### Parâmetros de Caminho

*   `file_id`: `string` - **Obrigatório** - O ID do arquivo.

#### Retorna

O objeto [File](#the-file-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune"
}
```

---

### Excluir arquivo

**DELETE** `/v1/files/{file_id}`

Exclui um arquivo.

#### Parâmetros de Caminho

*   `file_id`: `string` - **Obrigatório** - O ID do arquivo.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "file.deleted", // Corrigido de "file"
  "deleted": true
}
```

---

### Recuperar conteúdo do arquivo

**GET** `/v1/files/{file_id}/content`

Retorna o conteúdo do arquivo especificado.

#### Parâmetros de Caminho

*   `file_id`: `string` - **Obrigatório** - O ID do arquivo.

#### Retorna

O conteúdo do arquivo (bytes brutos).

#### Exemplo de Requisição

```bash
# Salva o conteúdo em um arquivo local
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

*(A resposta são os bytes brutos do arquivo)*

---

### O objeto File

O objeto `File` representa um documento que foi carregado para a OpenAI.

*   `bytes`: `integer` - O tamanho do arquivo em bytes.
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `expires_at`: `integer` - Timestamp Unix de expiração (pode não estar sempre presente).
*   `filename`: `string` - O nome do arquivo.
*   `id`: `string` - O identificador do arquivo.
*   `object`: `string` - Tipo do objeto (`file`).
*   `purpose`: `string` - O propósito pretendido (`assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`, `vision`, `user_data`, `evals`).
*   `status`: (**Deprecated**) `string` - Status (`uploaded`, `processed`, `error`).
*   `status_details`: (**Deprecated**) `string` - Detalhes do status.

#### Objeto File Exemplo

```json
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "expires_at": 1680202602, // Exemplo com expires_at
  "filename": "salesOverview.pdf",
  "purpose": "assistants"
}
```

---

## Uploads

Permite carregar arquivos grandes em várias partes.

### Criar upload

**POST** `/v1/uploads`

Cria um objeto `Upload` intermediário ao qual você pode adicionar Partes. Atualmente, um Upload pode aceitar no máximo 8 GB no total e expira após uma hora da criação.

Após concluir o Upload, criaremos um objeto `File` que contém todas as partes carregadas. Este `File` é utilizável no resto da nossa plataforma como um objeto `File` regular.

Para certos valores de `purpose`, o `mime_type` correto deve ser especificado. Consulte a documentação para os [tipos MIME suportados](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types) para seu caso de uso (links específicos para Assistants e Vision fornecidos na documentação original).

Para orientação sobre as extensões de nome de arquivo adequadas para cada propósito, siga a documentação sobre [criação de um Arquivo](https://platform.openai.com/docs/api-reference/files/create).

#### Corpo da Requisição

*   `bytes`: `integer` - **Obrigatório** - O número de bytes no arquivo que você está carregando.
*   `filename`: `string` - **Obrigatório** - O nome do arquivo a ser carregado.
*   `mime_type`: `string` - **Obrigatório** - O tipo MIME do arquivo.
*   `purpose`: `string` - **Obrigatório** - O propósito pretendido do arquivo carregado. Veja [propósitos de Arquivo](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).

#### Retorna

O objeto [Upload](#the-upload-object) com status `pending`.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "application/jsonl" # Corrigido de text/jsonl para application/jsonl
  }'
```

#### Resposta

```json
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719188511 // Corrigido para 1 hora após created_at
  // "file" não está presente ainda
}
```

---

### Adicionar parte do upload (Add upload part)

**POST** `/v1/uploads/{upload_id}/parts`

Adiciona uma Parte a um objeto Upload. Uma Parte representa um pedaço de bytes do arquivo que você está tentando carregar.

Cada Parte pode ter no máximo 64 MB, e você pode adicionar Partes até atingir o máximo de 8 GB do Upload.

É possível adicionar várias Partes em paralelo. Você pode decidir a ordem pretendida das Partes ao concluir o Upload.

#### Parâmetros de Caminho

*   `upload_id`: `string` - **Obrigatório** - O ID do Upload.

#### Corpo da Requisição

*   `data`: `file` - **Obrigatório** - O pedaço de bytes para esta Parte.

#### Retorna

O objeto [upload Part](#the-upload-part-object).

#### Exemplo de Requisição

```bash
# Nota: O exemplo usa -F, indicando multipart/form-data, não JSON
curl https://api.openai.com/v1/uploads/upload_abc123/parts \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F data=@chunk1.bin # Envia o conteúdo do arquivo chunk1.bin
```

#### Resposta

```json
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

---

### Completar upload

**POST** `/v1/uploads/{upload_id}/complete`

Conclui o Upload.

Dentro do objeto Upload retornado, há um objeto File aninhado que está pronto para uso no resto da plataforma.

Você pode especificar a ordem das Partes passando uma lista ordenada dos IDs das Partes.

O número de bytes carregados após a conclusão deve corresponder ao número de bytes especificado inicialmente ao criar o objeto Upload. Nenhuma Parte pode ser adicionada após a conclusão de um Upload.

#### Parâmetros de Caminho

*   `upload_id`: `string` - **Obrigatório** - O ID do Upload.

#### Corpo da Requisição

*   `part_ids`: `array` - **Obrigatório** - A lista ordenada dos IDs das Partes.
*   `md5`: `string` - *Opcional* - O checksum md5 opcional para o conteúdo do arquivo para verificar se os bytes carregados correspondem ao esperado.

#### Retorna

O objeto [Upload](#the-upload-object) com status `completed` e uma propriedade `file` adicional contendo o objeto File utilizável criado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/uploads/upload_abc123/complete \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
    // "md5": "..." // Opcional
  }'
```

#### Resposta

```json
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed", // Status atualizado
  "expires_at": 1719188511,
  "file": { // Objeto File criado
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911, // Timestamp da criação do File
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune"
  }
}
```

---

### Cancelar upload

**POST** `/v1/uploads/{upload_id}/cancel`

Cancela o Upload. Nenhuma Parte pode ser adicionada após o cancelamento de um Upload.

#### Parâmetros de Caminho

*   `upload_id`: `string` - **Obrigatório** - O ID do Upload.

#### Retorna

O objeto [Upload](#the-upload-object) com status `cancelled`.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/uploads/upload_abc123/cancel \
 -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled", // Status atualizado
  "expires_at": 1719188511,
  "file": null // Upload cancelado não cria um File
}
```

---

### O objeto Upload

O objeto `Upload` pode aceitar pedaços de bytes na forma de Partes.

*   `bytes`: `integer` - O número pretendido de bytes a serem carregados.
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `expires_at`: `integer` - Timestamp Unix de expiração.
*   `file`: `object` ou `null` - O objeto File pronto após a conclusão do Upload.
*   `filename`: `string` - Nome do arquivo a ser carregado.
*   `id`: `string` - Identificador único do Upload.
*   `object`: `string` - Tipo do objeto (`upload`).
*   `purpose`: `string` - Propósito pretendido do arquivo.
*   `status`: `string` - Status do Upload (`pending`, `completed`, `cancelled`, `expired`).

#### Objeto Upload Exemplo (Concluído)

```json
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719188511,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune"
  }
}
```

---

### O objeto Upload Part

A `Part` de upload representa um pedaço de bytes que podemos adicionar a um objeto Upload.

*   `created_at`: `integer` - Timestamp Unix de criação da Parte.
*   `id`: `string` - Identificador único da Parte.
*   `object`: `string` - Tipo do objeto (`upload.part`).
*   `upload_id`: `string` - ID do objeto Upload ao qual esta Parte foi adicionada.

#### Objeto Upload Part Exemplo

```json
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

---

## Imagens

Dado um prompt e/ou uma imagem de entrada, o modelo gerará uma nova imagem.

**Guia relacionado:** [Image generation](https://platform.openai.com/docs/guides/images)

### Criar imagem

**POST** `/v1/images/generations`

Cria uma imagem dado um prompt.

#### Corpo da Requisição

*   `prompt`: `string` - **Obrigatório**
    *   Uma descrição textual da(s) imagem(ns) desejada(s). O comprimento máximo é 1000 caracteres para `dall-e-2` e 4000 caracteres para `dall-e-3`.
*   `model`: `string` - *Opcional* - **Padrão:** `dall-e-2`
    *   O modelo a ser usado para geração de imagem (`dall-e-2` ou `dall-e-3`).
*   `n`: `integer` ou `null` - *Opcional* - **Padrão:** `1`
    *   O número de imagens a serem geradas. Deve estar entre 1 e 10. Para `dall-e-3`, apenas `n=1` é suportado.
*   `quality`: `string` - *Opcional* - **Padrão:** `standard`
    *   A qualidade da imagem que será gerada. `hd` cria imagens com detalhes mais finos e maior consistência. Apenas suportado para `dall-e-3`.
*   `response_format`: `string` ou `null` - *Opcional* - **Padrão:** `url`
    *   O formato em que as imagens geradas são retornadas. Deve ser `url` ou `b64_json`. URLs são válidas apenas por 60 minutos.
*   `size`: `string` ou `null` - *Opcional* - **Padrão:** `1024x1024`
    *   O tamanho das imagens geradas. Deve ser `256x256`, `512x512` ou `1024x1024` para `dall-e-2`. Deve ser `1024x1024`, `1792x1024` ou `1024x1792` para modelos `dall-e-3`.
*   `style`: `string` ou `null` - *Opcional* - **Padrão:** `vivid`
    *   O estilo das imagens geradas. Deve ser `vivid` ou `natural`. Apenas suportado para `dall-e-3`.
*   `user`: `string` - *Opcional*
    *   Um identificador único representando seu usuário final. [Saiba mais](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

#### Retorna

Retorna uma lista de objetos [image](#the-image-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

#### Resposta

```json
{
  "created": 1741570800, // Timestamp de exemplo
  "data": [
    {
      "url": "https://...", // URL da imagem gerada
      "revised_prompt": "A cute baby sea otter lounging on its back in clear blue water under a sunny sky." // Exemplo de prompt revisado pelo DALL-E 3
    }
    // Se n > 1 para DALL-E 2, haveria mais objetos aqui
  ]
}
```

---

### Criar edição de imagem

**POST** `/v1/images/edits`

Cria uma imagem editada ou estendida dada uma imagem original e um prompt.

#### Corpo da Requisição (multipart/form-data)

*   `image`: `file` - **Obrigatório**
    *   A imagem a ser editada. Deve ser um arquivo PNG válido, menor que 4MB e quadrado. Se `mask` não for fornecida, a imagem deve ter transparência, que será usada como máscara.
*   `prompt`: `string` - **Obrigatório**
    *   Uma descrição textual da(s) imagem(ns) desejada(s). Máximo de 1000 caracteres.
*   `mask`: `file` - *Opcional*
    *   Uma imagem adicional cujas áreas totalmente transparentes (alfa zero) indicam onde `image` deve ser editada. Deve ser um arquivo PNG válido, menor que 4MB e ter as mesmas dimensões que `image`.
*   `model`: `string` ou `"dall-e-2"` - *Opcional* - **Padrão:** `dall-e-2`
    *   O modelo a ser usado. Apenas `dall-e-2` é suportado no momento.
*   `n`: `integer` ou `null` - *Opcional* - **Padrão:** `1`
    *   Número de imagens a gerar (1-10).
*   `response_format`: `string` ou `null` - *Opcional* - **Padrão:** `url`
    *   Formato de retorno (`url` ou `b64_json`).
*   `size`: `string` ou `null` - *Opcional* - **Padrão:** `1024x1024`
    *   Tamanho das imagens (`256x256`, `512x512`, `1024x1024`).
*   `user`: `string` - *Opcional* - Identificador do usuário final.

#### Retorna

Retorna uma lista de objetos [image](#the-image-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

#### Resposta

```json
{
  "created": 1741570900, // Timestamp de exemplo
  "data": [
    {
      "url": "https://..."
      // "b64_json": "..." // Se response_format for b64_json
      // "revised_prompt": "..." // Menos comum para DALL-E 2
    },
    {
      "url": "https://..."
    }
  ]
}
```

---

### Criar variação de imagem

**POST** `/v1/images/variations`

Cria uma variação de uma imagem fornecida.

#### Corpo da Requisição (multipart/form-data)

*   `image`: `file` - **Obrigatório**
    *   A imagem a ser usada como base. Deve ser um arquivo PNG válido, menor que 4MB e quadrado.
*   `model`: `string` ou `"dall-e-2"` - *Opcional* - **Padrão:** `dall-e-2`
    *   O modelo a ser usado. Apenas `dall-e-2` é suportado no momento.
*   `n`: `integer` ou `null` - *Opcional* - **Padrão:** `1`
    *   Número de imagens a gerar (1-10). *Nota: O texto diz que para DALL-E 3 n=1 é suportado, mas este endpoint só suporta DALL-E 2.*
*   `response_format`: `string` ou `null` - *Opcional* - **Padrão:** `url`
    *   Formato de retorno (`url` ou `b64_json`).
*   `size`: `string` ou `null` - *Opcional* - **Padrão:** `1024x1024`
    *   Tamanho das imagens (`256x256`, `512x512`, `1024x1024`).
*   `user`: `string` - *Opcional* - Identificador do usuário final.

#### Retorna

Retorna uma lista de objetos [image](#the-image-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

#### Resposta

```json
{
  "created": 1741571000, // Timestamp de exemplo
  "data": [
    {
      "url": "https://..."
    },
    {
      "url": "https://..."
    }
  ]
}
```

---

### O objeto Image

Representa a URL ou o conteúdo de uma imagem gerada pela API OpenAI.

*   `b64_json`: `string`
    *   O JSON codificado em base64 da imagem gerada, se `response_format` for `b64_json`.
*   `revised_prompt`: `string`
    *   O prompt que foi usado para gerar a imagem, se houve alguma revisão no prompt (principalmente para DALL-E 3).
*   `url`: `string`
    *   A URL da imagem gerada, se `response_format` for `url` (padrão).

#### Objeto Image Exemplo

```json
{
  "url": "https://oaidalleapiprodscus.blob.core.windows.net/private/...",
  "revised_prompt": "A close-up, high-detail photograph capturing a charming baby sea otter floating on its back in serene, clear blue water. The otter looks relaxed under the gentle sunlight of a bright day. The style is photorealistic."
  // "b64_json" seria preenchido em vez de "url" se solicitado
}
```

---

## Modelos

Liste e descreva os vários modelos disponíveis na API. Você pode consultar a [documentação de Modelos](https://platform.openai.com/docs/models) para entender quais modelos estão disponíveis e as diferenças entre eles.

### Listar modelos

**GET** `/v1/models`

Lista os modelos atualmente disponíveis e fornece informações básicas sobre cada um, como o proprietário e a disponibilidade.

#### Retorna

Uma lista de objetos [model](#the-model-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-4o-mini-2024-07-18", // Exemplo de ID de modelo
      "object": "model",
      "created": 1721228400, // Timestamp de exemplo
      "owned_by": "openai"
    },
    {
      "id": "dall-e-3",
      "object": "model",
      "created": 1700000000, // Timestamp de exemplo
      "owned_by": "openai"
    },
    {
      "id": "ft:gpt-4o-mini:my-org:custom-model:abc123def", // Exemplo de modelo ajustado
      "object": "model",
      "created": 1740000000, // Timestamp de exemplo
      "owned_by": "org-xxxxxxxxxxx" // ID da sua organização
    }
    // ... outros modelos
  ]
  // "has_more" não está presente na resposta de list models
}
```

---

### Recuperar modelo

**GET** `/v1/models/{model}`

Recupera uma instância de modelo, fornecendo informações básicas sobre o modelo, como o proprietário e as permissões.

#### Parâmetros de Caminho

*   `model`: `string` - **Obrigatório** - O ID do modelo (ex: `gpt-4.1`, `gpt-4o-mini`, `ft:....`).

#### Retorna

O objeto [model](#the-model-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/models/gpt-4.1 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "gpt-4.1", // Corresponde ao path param
  "object": "model",
  "created": 1686935002, // Timestamp de criação do modelo
  "owned_by": "openai" // Proprietário do modelo
}
```

---

### Excluir um modelo ajustado (fine-tuned)

**DELETE** `/v1/models/{model}`

Exclui um modelo ajustado. Você deve ter a função de `Owner` (Proprietário) em sua organização para excluir um modelo.

#### Parâmetros de Caminho

*   `model`: `string` - **Obrigatório** - O modelo a ser excluído (deve ser um ID de modelo ajustado, ex: `ft:...`).

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### Resposta

```json
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model.deleted", // Corrigido de "model"
  "deleted": true
}
```

---

### O objeto Model

Descreve uma oferta de modelo OpenAI que pode ser usada com a API.

*   `created`: `integer` - Timestamp Unix de criação do modelo.
*   `id`: `string` - O identificador do modelo.
*   `object`: `string` - Tipo do objeto (`model`).
*   `owned_by`: `string` - A organização que possui o modelo (`openai` ou ID da sua organização para modelos ajustados).

#### Objeto Model Exemplo

```json
{
  "id": "gpt-4.1",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

---

## Moderações

Dadas entradas de texto e/ou imagem, classifica se essas entradas são potencialmente prejudiciais em várias categorias.

**Guia relacionado:** [Moderations](https://platform.openai.com/docs/guides/moderation)

### Criar moderação

**POST** `/v1/moderations`

Classifica se entradas de texto e/ou imagem são potencialmente prejudiciais. [Saiba mais no guia de moderação](https://platform.openai.com/docs/guides/moderation).

#### Corpo da Requisição

*   `input`: `string` ou `array` - **Obrigatório**
    *   Entrada(s) para classificar. Pode ser uma única string, um array de strings ou um array de objetos de entrada multimodal semelhantes a outros modelos.
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `string`, `array<string>`, `array<object>` com `type: 'text'` ou `type: 'image_url'`)</details>
*   `model`: `string` - *Opcional* - **Padrão:** `omni-moderation-latest`
    *   O modelo de moderação de conteúdo que você gostaria de usar. [Saiba mais sobre modelos disponíveis](https://platform.openai.com/docs/guides/moderation/quickstart#available-models).

#### Retorna

Um objeto [moderation](#the-moderation-object).

#### Exemplos

##### Exemplo: String única

```bash
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

```json
# Resposta
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007", // Modelo usado na classificação
  "results": [ // Array com um resultado por entrada
    {
      "flagged": true, // Se alguma categoria excedeu o limiar
      "categories": { // Classificação booleana por categoria
        "sexual": false,
        "hate": false,
        "harassment": true,
        "self-harm": false,
        "sexual/minors": false,
        "hate/threatening": false,
        "violence/graphic": false,
        "self-harm/intent": false,
        "self-harm/instructions": false,
        "harassment/threatening": true,
        "violence": true
      },
      "category_scores": { // Pontuações brutas por categoria
        "sexual": 0.000011726012417057063,
        "hate": 0.22706663608551025,
        "harassment": 0.5215635299682617,
        // ... outras pontuações
        "harassment/threatening": 0.5694745779037476,
        "violence": 0.9971134662628174
      }
      // "category_applied_input_types" não está presente no exemplo original para este modelo
    }
  ]
}
```

##### Exemplo: Imagem e Texto

> *(Nota: Exemplo para Image and text não foi fornecido no texto original, mas seria colocado aqui se estivesse. A resposta incluiria `category_applied_input_types`)*

---

### O objeto Moderation

Representa se uma determinada entrada de texto/imagem é potencialmente prejudicial.

*   `id`: `string` - Identificador único da requisição de moderação.
*   `model`: `string` - Modelo usado para gerar os resultados.
*   `results`: `array` - Uma lista de objetos de moderação (um por entrada na requisição).
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `flagged` (boolean), `categories` (objeto boolean), `category_scores` (objeto float), `category_applied_input_types` (objeto array<string>, apenas para modelos omni))</details>

#### Objeto Moderation Exemplo (com omni-moderation)

```json
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [
    {
      "flagged": true,
      "categories": { // Categorias podem variar entre modelos
        "harassment": true,
        "harassment/threatening": true,
        "sexual": false,
        "hate": false,
        "hate/threatening": false,
        "illicit": false,
        "illicit/violent": false,
        "self-harm/intent": false,
        "self-harm/instructions": false,
        "self-harm": false,
        "sexual/minors": false,
        "violence": true,
        "violence/graphic": true
      },
      "category_scores": {
        "harassment": 0.8189693396524255,
        // ... outras pontuações
        "violence": 0.9999992735124786,
        "violence/graphic": 0.843064871157054
      },
      "category_applied_input_types": { // Indica se a categoria foi aplicada a 'text' ou 'image'
        "harassment": [
          "text"
        ],
        "harassment/threatening": [
          "text"
        ],
        "sexual": [
          "text",
          "image"
        ],
        // ... outros tipos aplicados
        "violence": [
          "text",
          "image"
        ],
        "violence/graphic": [
          "text",
          "image"
        ]
      }
    }
  ]
}
```

---

## Vector Stores

Vector stores potencializam a busca semântica para a API de Recuperação (Retrieval) e a ferramenta `file_search` nas APIs Responses e Assistants.

**Guia relacionado:** [File Search](https://platform.openai.com/docs/assistants/tools/file-search)

### Criar vector store

**POST** `/v1/vector_stores`

Cria um vector store.

#### Corpo da Requisição

*   `chunking_strategy`: `object` - *Opcional*
    *   A estratégia de chunking usada para dividir o(s) arquivo(s). Se não definido, usará a estratégia `auto`. Aplicável apenas se `file_ids` não estiver vazio.
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `type: "auto"`, `type: "static"` com `static: {max_chunk_size_tokens, chunk_overlap_tokens}`)</details>
*   `expires_after`: `object` - *Opcional*
    *   A política de expiração para um vector store.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `anchor` (`last_active_at`), `days`)</details>
*   `file_ids`: `array` - *Opcional*
    *   Uma lista de IDs de Arquivo que o vector store deve usar. Útil para ferramentas como `file_search`.
*   `metadata`: `map` - *Opcional*
    *   Conjunto de 16 pares chave-valor. (Mesma descrição de outros endpoints)
*   `name`: `string` - *Opcional*
    *   O nome do vector store.

#### Retorna

Um objeto [vector store](#the-vector-store-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "name": "Support FAQ",
    "file_ids": ["file-1", "file-2"],
    "expires_after": {
      "anchor": "last_active_at",
      "days": 7
    }
  }'
```

#### Resposta

```json
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "usage_bytes": 0, // Inicialmente 0, atualizado após processamento dos arquivos
  "file_counts": { // Contagem inicial reflete arquivos sendo adicionados
    "in_progress": 2,
    "completed": 0,
    "failed": 0,
    "cancelled": 0,
    "total": 2
  },
  "status": "in_progress", // Muda para 'completed' após processamento
  "expires_after": {
    "anchor": "last_active_at",
    "days": 7
  },
  "expires_at": null, // Calculado com base em last_active_at
  "last_active_at": null, // Atualizado com o uso
  "metadata": {}
}
```

---

### Listar vector stores

**GET** `/v1/vector_stores`

Retorna uma lista de vector stores.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de stores a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [vector store](#the-vector-store-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "usage_bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      },
      "status": "completed",
      // "expires_after", "expires_at", "last_active_at", "metadata" não incluídos neste exemplo de listagem
    },
    {
      "id": "vs_abc456",
      "object": "vector_store",
      "created_at": 1699061775, // Exemplo com timestamp diferente
      "name": "Support FAQ v2",
      "usage_bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      },
      "status": "completed",
    }
  ],
  "first_id": "vs_abc123", // ID do primeiro na página
  "last_id": "vs_abc456", // ID do último na página
  "has_more": false
}
```

---

### Recuperar vector store

**GET** `/v1/vector_stores/{vector_store_id}`

Recupera um vector store.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store.

#### Retorna

O objeto [vector store](#the-vector-store-object) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ", // Nome e outros detalhes preenchidos
  "usage_bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  },
  "status": "completed",
  "expires_after": { // Exemplo com expires_after
    "anchor": "last_active_at",
    "days": 7
  },
  "expires_at": 1699661776, // Exemplo com expires_at calculado
  "last_active_at": 1699061776, // Exemplo com last_active_at
  "metadata": {}
}

```

---

### Modificar vector store

**POST** `/v1/vector_stores/{vector_store_id}`

Modifica um vector store.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store.

#### Corpo da Requisição

*   `expires_after`: `object` ou `null` - *Opcional* - A política de expiração.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `metadata`: `map` - *Opcional* - Metadados.
*   `name`: `string` ou `null` - *Opcional* - O nome do vector store.

#### Retorna

O objeto [vector store](#the-vector-store-object) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "name": "Updated Support FAQ",
    "metadata": {"version": "2.0"}
  }'
```

#### Resposta

```json
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Updated Support FAQ", // Nome atualizado
  "usage_bytes": 139920,
  "file_counts": { /* ... */ },
  "status": "completed",
  "expires_after": { /* ... */ },
  "expires_at": 1699661776,
  "last_active_at": 1699061776,
  "metadata": {"version": "2.0"} // Metadata atualizada
}
```

---

### Excluir vector store

**DELETE** `/v1/vector_stores/{vector_store_id}`

Exclui um vector store.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

#### Resposta

```json
{
  "id": "vs_abc123",
  "object": "vector_store.deleted",
  "deleted": true
}
```

---

### Pesquisar vector store

**POST** `/v1/vector_stores/{vector_store_id}/search`

Pesquisa um vector store por chunks relevantes com base em uma consulta e filtro de atributos de arquivo.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store a ser pesquisado.

#### Corpo da Requisição

*   `query`: `string` ou `array` - **Obrigatório** - Uma string de consulta para a busca.
*   `filters`: `object` - *Opcional* - Um filtro para aplicar com base nos atributos do arquivo.
    *   <details><summary>Mostrar tipos possíveis</summary> (Permite filtrar por `file_ids`, `attributes`, etc.)</details>
*   `max_num_results`: `integer` - *Opcional* - **Padrão:** `10` - O número máximo de resultados a retornar (1-50).
*   `ranking_options`: `object` - *Opcional* - Opções de classificação para a busca.
    *   <details><summary>Mostrar propriedades</summary> (Ex: `rerank_method: "standard"`)</details>
*   `rewrite_query`: `boolean` - *Opcional* - **Padrão:** `false` - Se reescreve a consulta em linguagem natural para busca vetorial.

#### Retorna

Uma página de resultados de busca do vector store.

#### Exemplo de Requisição

```bash
curl -X POST \
https://api.openai.com/v1/vector_stores/vs_abc123/search \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-H "Content-Type: application/json" \
-H "OpenAI-Beta: assistants=v2" \
-d '{
      "query": "What is the return policy?",
      "filters": {
        "file_ids": ["file_123"]
      },
      "max_num_results": 2
    }'
```

#### Resposta

```json
{
  "object": "vector_store.search_results.page",
  "search_query": "What is the return policy?", // Query original ou reescrita
  "data": [ // Lista de chunks relevantes
    {
      "file_id": "file_123",
      "filename": "document.pdf", // Nome do arquivo de origem
      "score": 0.95, // Pontuação de relevância
      "attributes": { // Atributos do arquivo, se houver
        "author": "John Doe",
        "date": "2023-01-01"
      },
      "content": [ // Conteúdo do chunk
        {
          "type": "text",
          "text": "Relevant chunk about return policy..."
        }
      ]
    },
    {
      "file_id": "file_456", // Exemplo de outro arquivo se o filtro não fosse aplicado
      "filename": "notes.txt",
      "score": 0.89,
      "attributes": {
        "author": "Jane Smith",
        "date": "2023-01-02"
      },
      "content": [
        {
          "type": "text",
          "text": "Sample text content from the vector store."
        }
      ]
    }
  ],
  "has_more": false, // Se há mais resultados
  "next_page": null // Cursor para a próxima página, se has_more for true
}
```

---

### O objeto Vector Store

Um vector store é uma coleção de arquivos processados que podem ser usados pela ferramenta `file_search`.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `expires_after`: `object` - Política de expiração.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `expires_at`: `integer` ou `null` - Timestamp Unix de expiração.
*   `file_counts`: `object` - Contagem de arquivos por status.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `in_progress`, `completed`, `failed`, `cancelled`, `total`)</details>
*   `id`: `string` - Identificador do vector store.
*   `last_active_at`: `integer` ou `null` - Timestamp Unix da última atividade.
*   `metadata`: `map` - Metadados.
*   `name`: `string` - Nome do vector store.
*   `object`: `string` - Tipo do objeto (`vector_store`).
*   `status`: `string` - Status (`expired`, `in_progress`, `completed`).
*   `usage_bytes`: `integer` - Número total de bytes usados pelos arquivos.

#### Objeto Vector Store Exemplo

```json
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "expires_after": null, // Exemplo sem expiração
  "expires_at": null,
  "metadata": {}
}
```

---

## Vector Store Files

Vector store files representam arquivos dentro de um vector store.

**Guia relacionado:** [File Search](https://platform.openai.com/docs/assistants/tools/file-search)

### Criar vector store file

**POST** `/v1/vector_stores/{vector_store_id}/files`

Cria um vector store file anexando um File a um vector store.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store.

#### Corpo da Requisição

*   `file_id`: `string` - **Obrigatório** - Um ID de Arquivo que o vector store deve usar.
*   `attributes`: `map` - *Opcional* - Conjunto de 16 pares chave-valor (string, boolean, number).
*   `chunking_strategy`: `object` - *Opcional* - Estratégia de chunking para este arquivo (sobrescreve a do store).
    *   <details><summary>Mostrar tipos possíveis</summary></details>

#### Retorna

Um objeto [vector store file](#the-vector-store-file-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123",
      "attributes": {"source": "manual_upload"}
    }'
```

#### Resposta

```json
{
  "id": "file-abc123", // ID do arquivo original
  "object": "vector_store.file",
  "usage_bytes": 0, // Atualizado após processamento
  "created_at": 1699061776, // Timestamp de associação
  "vector_store_id": "vs_abcd", // ID do vector store
  "status": "in_progress", // Muda para completed/failed/cancelled
  "last_error": null,
  "attributes": {"source": "manual_upload"}, // Atributos definidos
  "chunking_strategy": null // Usará a do store ou 'auto' se não definida
}
```

---

### Listar vector store files

**GET** `/v1/vector_stores/{vector_store_id}/files`

Retorna uma lista de vector store files.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `filter`: `string` - *Opcional* - Filtrar por status (`in_progress`, `completed`, `failed`, `cancelled`).
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de arquivos a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [vector store file](#the-vector-store-file-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234, // Exemplo com bytes
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null
      // attributes e chunking_strategy podem estar presentes
    },
    {
      "id": "file-abc456",
      "object": "vector_store.file",
      "usage_bytes": 5678,
      "created_at": 1699061775,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

---

### Recuperar vector store file

**GET** `/v1/vector_stores/{vector_store_id}/files/{file_id}`

Recupera um vector store file.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `file_id`: `string` - **Obrigatório** - ID do arquivo sendo recuperado.

#### Retorna

O objeto [vector store file](#the-vector-store-file-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd", // Corresponde ao path
  "status": "completed",
  "last_error": null,
  "attributes": {"source": "manual_upload"},
  "chunking_strategy": { // Exemplo com chunking strategy
     "type": "static",
     "static": {
        "max_chunk_size_tokens": 800,
        "chunk_overlap_tokens": 400
      }
   }
}
```

---

### Recuperar conteúdo do vector store file

**GET** `/v1/vector_stores/{vector_store_id}/files/{file_id}/content`

Recupera o conteúdo parseado de um vector store file.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - O ID do vector store.
*   `file_id`: `string` - **Obrigatório** - O ID do arquivo dentro do vector store.

#### Retorna

O conteúdo parseado do vector store file especificado.

#### Exemplo de Requisição

```bash
curl \
https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "file_id": "file-abc123",
  "filename": "example.txt", // Nome original do arquivo
  "attributes": {"key": "value"}, // Atributos associados
  "content": [ // Conteúdo parseado (pode variar com o tipo de arquivo)
    {"type": "text", "text": "Primeiro chunk de texto..."},
    {"type": "text", "text": "Segundo chunk de texto..."}
    // ... mais chunks
  ]
}
```

---

### Atualizar atributos do vector store file

**POST** `/v1/vector_stores/{vector_store_id}/files/{file_id}`

Atualiza atributos em um vector store file.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `file_id`: `string` - **Obrigatório** - ID do arquivo a atualizar.

#### Corpo da Requisição

*   `attributes`: `map` - **Obrigatório** - Conjunto de 16 pares chave-valor.

#### Retorna

O objeto [vector store file](#the-vector-store-file-object) atualizado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{"attributes": {"key1": "value1", "key2": 2, "old_key": null}}' # Para remover uma chave, use null
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd", // Corresponde ao path
  "status": "completed",
  "last_error": null,
  "chunking_strategy": { /* ... */ },
  "attributes": {"key1": "value1", "key2": 2} // Atributos atualizados
}
```

---

### Excluir vector store file

**DELETE** `/v1/vector_stores/{vector_store_id}/files/{file_id}`

Exclui um vector store file. Isso remove o arquivo do vector store, mas o arquivo em si (na API `/v1/files`) não será excluído. Para excluir o arquivo, use o endpoint [delete file](#delete-file).

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `file_id`: `string` - **Obrigatório** - ID do arquivo a ser excluído do store.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

#### Resposta

```json
{
  "id": "file-abc123",
  "object": "vector_store.file.deleted",
  "deleted": true
}
```

---

### O objeto Vector Store File (Beta)

Uma lista de arquivos anexados a um vector store.

*   `attributes`: `map` - Metadados específicos do arquivo no contexto do vector store.
*   `chunking_strategy`: `object` - Estratégia de chunking usada.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `created_at`: `integer` - Timestamp Unix de criação da associação.
*   `id`: `string` - Identificador do arquivo (o mesmo de `/v1/files`).
*   `last_error`: `object` ou `null` - Último erro associado a este arquivo no store.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `code`, `message`)</details>
*   `object`: `string` - Tipo do objeto (`vector_store.file`).
*   `status`: `string` - Status do processamento do arquivo no store (`in_progress`, `completed`, `cancelled`, `failed`).
*   `usage_bytes`: `integer` - Uso total do vector store em bytes para este arquivo.
*   `vector_store_id`: `string` - ID do vector store ao qual o arquivo está anexado.

#### Objeto Vector Store File Exemplo

```json
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  },
  "attributes": {"source": "manual_upload"}
}
```

---

## Vector Store File Batches

Vector store file batches representam operações para adicionar múltiplos arquivos a um vector store.

**Guia relacionado:** [File Search](https://platform.openai.com/docs/assistants/tools/file-search)

### Criar vector store file batch

**POST** `/v1/vector_stores/{vector_store_id}/file_batches`

Cria um vector store file batch.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.

#### Corpo da Requisição

*   `file_ids`: `array` - **Obrigatório** - Uma lista de IDs de Arquivo que o vector store deve usar.
*   `attributes`: `map` - *Opcional* - Atributos a serem aplicados a todos os arquivos neste batch.
*   `chunking_strategy`: `object` - *Opcional* - Estratégia de chunking para os arquivos neste batch.
    *   <details><summary>Mostrar tipos possíveis</summary></details>

#### Retorna

Um objeto [vector store file batch](#the-vector-store-files-batch-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
      // "chunking_strategy": {...} // Opcional
      // "attributes": {...} // Opcional
    }'
```

#### Resposta

```json
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress", // Status inicial
  "file_counts": { // Contagem inicial
    "in_progress": 2,
    "completed": 0,
    "failed": 0,
    "cancelled": 0,
    "total": 2
  }
}
```

---

### Recuperar vector store file batch

**GET** `/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}`

Recupera um vector store file batch.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `batch_id`: `string` - **Obrigatório** - ID do file batch.

#### Retorna

O objeto [vector store file batch](#the-vector-store-files-batch-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch", // Corrigido de files_batches
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "completed", // Exemplo com status finalizado
  "file_counts": { // Contagem final
    "in_progress": 0,
    "completed": 2,
    "failed": 0,
    "cancelled": 0,
    "total": 2
  }
}
```

---

### Cancelar vector store file batch

**POST** `/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel`

Cancela um vector store file batch. Tenta cancelar o processamento dos arquivos neste batch o mais rápido possível.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `batch_id`: `string` - **Obrigatório** - ID do file batch a cancelar.

#### Retorna

O objeto [vector store file batch](#the-vector-store-files-batch-object) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/vector_stores/vs_abc123/file_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch", // Corrigido de files_batches
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling", // Status alterado
  "file_counts": { // Contagens no momento do cancelamento
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0, // Será atualizado quando o cancelamento for concluído
    "total": 15
  }
}
```

---

### Listar vector store files em um batch

**GET** `/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/files`

Retorna uma lista de vector store files em um batch.

#### Parâmetros de Caminho

*   `vector_store_id`: `string` - **Obrigatório** - ID do vector store.
*   `batch_id`: `string` - **Obrigatório** - ID do file batch.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `filter`: `string` - *Opcional* - Filtrar por status (`in_progress`, `completed`, `failed`, `cancelled`).
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de arquivos a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [vector store file](#the-vector-store-file-object).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234,
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null
      // ... outros detalhes do arquivo
    },
    {
      "id": "file-abc456",
      "object": "vector_store.file",
      "usage_bytes": 5678,
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null
      // ... outros detalhes do arquivo
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

---

### O objeto Vector Store Files Batch (Beta)

Um batch de arquivos anexados a um vector store.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `file_counts`: `object` - Contagem de arquivos por status neste batch.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `in_progress`, `completed`, `failed`, `cancelled`, `total`)</details>
*   `id`: `string` - Identificador do batch.
*   `object`: `string` - Tipo do objeto (`vector_store.file_batch`). *O exemplo mostra `vector_store.files_batch` - verificar qual está correto.*
*   `status`: `string` - Status do batch (`in_progress`, `completed`, `cancelled`, `failed`).
*   `vector_store_id`: `string` - ID do vector store ao qual o batch pertence.

#### Objeto Vector Store Files Batch Exemplo

```json
{
  "id": "vsfb_123",
  "object": "vector_store.file_batch", // Usando o da definição
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

---

## Assistants (Beta)

Construa assistentes que podem chamar modelos e usar ferramentas para realizar tarefas.

**Get started with the Assistants API**

### Criar assistente (Beta)

**POST** `/v1/assistants`

Cria um assistente com um modelo e instruções.

#### Corpo da Requisição

*   `model`: `string` - **Obrigatório** - ID do modelo a ser usado (ex: `gpt-4o`).
*   `description`: `string` ou `null` - *Opcional* - Descrição do assistente (máx 512 chars).
*   `instructions`: `string` ou `null` - *Opcional* - Instruções de sistema (máx 256k chars).
*   `metadata`: `map` - *Opcional* - Metadados (16 pares chave-valor).
*   `name`: `string` ou `null` - *Opcional* - Nome do assistente (máx 256 chars).
*   `reasoning_effort`: `string` ou `null` - *Opcional* - **Padrão:** `medium` - (*Apenas modelos da série o*) Restringe esforço de raciocínio (`low`, `medium`, `high`).
*   `response_format`: `"auto"` ou `object` - *Opcional* - Especifica o formato de saída (`json_schema`, `json_object`).
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `temperature`: `number` ou `null` - *Opcional* - **Padrão:** `1` - Temperatura de amostragem (0-2).
*   `tool_resources`: `object` ou `null` - *Opcional* - Recursos usados pelas ferramentas (ex: `file_search` precisa de `vector_store_ids`, `code_interpreter` precisa de `file_ids`).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `tools`: `array` - *Opcional* - **Padrão:** `[]` - Lista de ferramentas habilitadas (`code_interpreter`, `file_search`, `function`). Máximo de 128.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `top_p`: `number` ou `null` - *Opcional* - **Padrão:** `1` - Amostragem Nucleus.

#### Retorna

Um objeto [assistant](#the-assistant-object-beta).

#### Exemplos

##### Exemplo: Code Interpreter

```bash
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
    // "tool_resources": {"code_interpreter": {"file_ids": ["file-xyz"]}} // Se precisar de arquivos
  }'
```

```json
# Resposta
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "tool_resources": {}, // Vazio se não especificado na requisição
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

##### Exemplo: File Search

> *(Nota: Exemplo para Files (File Search) não foi fornecido no texto original, mas seria similar, especificando `tools: [{"type": "file_search"}]` e opcionalmente `tool_resources: {"file_search": {"vector_store_ids": ["vs_123"]}}`)*

---

### Listar assistentes (Beta)

**GET** `/v1/assistants`

Retorna uma lista de assistentes.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de assistentes a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [assistant](#the-assistant-object-beta).

#### Exemplo de Requisição

```bash
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698982736,
      "name": "Coding Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a helpful assistant designed to make me better at coding!",
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    },
    {
      "id": "asst_abc456",
      // ... outro assistente ...
    },
    {
      "id": "asst_abc789",
      // ... outro assistente ...
    }
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

---

### Recuperar assistente (Beta)

**GET** `/v1/assistants/{assistant_id}`

Recupera um assistente.

#### Parâmetros de Caminho

*   `assistant_id`: `string` - **Obrigatório** - ID do assistente.

#### Retorna

O objeto [assistant](#the-assistant-object-beta) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [
    {
      "type": "file_search"
    }
  ],
  "tool_resources": { // Adicionado para clareza, pode estar vazio se não configurado
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

---

### Modificar assistente (Beta)

**POST** `/v1/assistants/{assistant_id}`

Modifica um assistente.

#### Parâmetros de Caminho

*   `assistant_id`: `string` - **Obrigatório** - ID do assistente a modificar.

#### Corpo da Requisição

*   `description`: `string` ou `null` - *Opcional*
*   `instructions`: `string` ou `null` - *Opcional*
*   `metadata`: `map` - *Opcional*
*   `model`: `string` - *Opcional*
*   `name`: `string` ou `null` - *Opcional*
*   `reasoning_effort`: `string` ou `null` - *Opcional*
*   `response_format`: `"auto"` ou `object` - *Opcional*
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `temperature`: `number` ou `null` - *Opcional*
*   `tool_resources`: `object` ou `null` - *Opcional*
    *   <details><summary>Mostrar propriedades</summary></details>
*   `tools`: `array` - *Opcional*
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `top_p`: `number` ou `null` - *Opcional*

*(As descrições dos campos são as mesmas de Criar assistente)*

#### Retorna

O objeto [assistant](#the-assistant-object-beta) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always respond with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o",
      "tool_resources": {"file_search": {"vector_store_ids": ["vs_xyz789"]}}
    }'
```

#### Resposta

```json
{
  "id": "asst_abc123", // ID permanece o mesmo
  "object": "assistant",
  "created_at": 1699009709, // Timestamp de criação original
  "name": "HR Helper", // Nome não modificado no exemplo
  "description": null,
  "model": "gpt-4o", // Modelo atualizado (ou reafirmado)
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.", // Instruções atualizadas
  "tools": [ // Ferramentas atualizadas
    {
      "type": "file_search"
    }
  ],
  "tool_resources": { // Recursos de ferramenta atualizados
    "file_search": {
      "vector_store_ids": ["vs_xyz789"]
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

---

### Excluir assistente (Beta)

**DELETE** `/v1/assistants/{assistant_id}`

Exclui um assistente.

#### Parâmetros de Caminho

*   `assistant_id`: `string` - **Obrigatório** - ID do assistente a excluir.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

#### Resposta

```json
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

---

### O objeto Assistant (Beta)

Representa um assistente que pode chamar o modelo e usar ferramentas.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `description`: `string` ou `null` - Descrição (máx 512 chars).
*   `id`: `string` - Identificador.
*   `instructions`: `string` ou `null` - Instruções de sistema (máx 256k chars).
*   `metadata`: `map` - Metadados.
*   `model`: `string` - ID do modelo usado.
*   `name`: `string` ou `null` - Nome (máx 256 chars).
*   `object`: `string` - Tipo do objeto (`assistant`).
*   `response_format`: `"auto"` ou `object` - Formato de saída especificado.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `temperature`: `number` ou `null` - Temperatura de amostragem.
*   `tool_resources`: `object` ou `null` - Recursos usados pelas ferramentas.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `tools`: `array` - Lista de ferramentas habilitadas.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `top_p`: `number` ou `null` - Amostragem Nucleus.

#### Objeto Assistant Exemplo

```json
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "tool_resources": {},
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

---

## Threads (Beta)

Crie threads com as quais os assistentes podem interagir.

**Guia relacionado:** [Assistants](https://platform.openai.com/docs/assistants/overview) (Especificamente sobre Threads)

### Criar thread (Beta)

**POST** `/v1/threads`

Cria uma thread.

#### Corpo da Requisição

*   `messages`: `array` - *Opcional*
    *   Uma lista de mensagens para iniciar a thread.
    *   <details><summary>Mostrar propriedades</summary> (Cada item é um objeto de mensagem com `role`, `content`, `attachments`, `metadata`)</details>
*   `metadata`: `map` - *Opcional* - Metadados para a thread.
*   `tool_resources`: `object` ou `null` - *Opcional*
    *   Recursos disponibilizados para as ferramentas nesta thread.
    *   <details><summary>Mostrar propriedades</summary></details>

#### Retorna

Um objeto [thread](#the-thread-object-beta).

#### Exemplos

##### Exemplo: Vazia

```bash
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '' # Corpo vazio para criar thread vazia
```

```json
# Resposta
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {} // Vazio por padrão
}
```

##### Exemplo: Com Mensagens

> *(Nota: Exemplo para Messages não foi fornecido no texto original, mas seria com um corpo como `{"messages": [{"role": "user", "content": "Hello!"}]}`)*

---

### Recuperar thread (Beta)

**GET** `/v1/threads/{thread_id}`

Recupera uma thread.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.

#### Retorna

O objeto [thread](#the-thread-object-beta) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": { // Exemplo com recursos de ferramenta definidos
    "code_interpreter": {
      "file_ids": ["file-1", "file-2"]
    },
    "file_search": {
       "vector_store_ids": ["vs-1"]
    }
  }
}
```

---

### Modificar thread (Beta)

**POST** `/v1/threads/{thread_id}`

Modifica uma thread. (Atualmente, apenas metadados e recursos de ferramenta podem ser modificados).

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.

#### Corpo da Requisição

*   `metadata`: `map` - *Opcional* - Metadados.
*   `tool_resources`: `object` ou `null` - *Opcional* - Recursos de ferramenta.
    *   <details><summary>Mostrar propriedades</summary></details>

#### Retorna

O objeto [thread](#the-thread-object-beta) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      },
      "tool_resources": {
        "code_interpreter": {
           "file_ids": ["file-new"] // Sobrescreve file_ids existentes
         }
       }
    }'
```

#### Resposta

```json
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": { // Metadados atualizados
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": { // Recursos atualizados
    "code_interpreter": {
       "file_ids": ["file-new"]
    },
    "file_search": { // Recursos não modificados permanecem
       "vector_store_ids": ["vs-1"]
    }
  }
}
```

---

### Excluir thread (Beta)

**DELETE** `/v1/threads/{thread_id}`

Exclui uma thread.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

#### Resposta

```json
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

---

### O objeto Thread (Beta)

Representa uma thread que contém mensagens.

*   `created_at`: `integer` - Timestamp Unix de criação.
*   `id`: `string` - Identificador.
*   `metadata`: `map` - Metadados.
*   `object`: `string` - Tipo do objeto (`thread`).
*   `tool_resources`: `object` ou `null` - Recursos disponibilizados para as ferramentas nesta thread.
    *   <details><summary>Mostrar propriedades</summary></details>

#### Objeto Thread Exemplo

```json
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {},
  "tool_resources": {
     "file_search": {
         "vector_store_ids": ["vs_xyz"]
     }
  }
}
```

---

## Mensagens (Messages) (Beta)

Crie mensagens dentro de threads.

**Guia relacionado:** [Assistants](https://platform.openai.com/docs/assistants/overview) (Especificamente sobre Mensagens)

### Criar mensagem (Beta)

**POST** `/v1/threads/{thread_id}/messages`

Cria uma mensagem.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread para criar a mensagem.

#### Corpo da Requisição

*   `content`: `string` ou `array` - **Obrigatório** - Conteúdo da mensagem (texto ou multimodal).
    *   <details><summary>Mostrar tipos possíveis</summary> (Ex: `string`, `array<object>` com `type: 'text', text: '...'` ou `type: 'image_url', image_url: {...}`)</details>
*   `role`: `string` - **Obrigatório** - Papel da entidade criando a mensagem (`user` ou `assistant`). Use `user` na maioria dos casos.
*   `attachments`: `array` ou `null` - *Opcional* - Lista de arquivos anexados e as ferramentas às quais devem ser adicionados.
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `file_id` e `tools` (array de objetos com `type`))</details>
*   `metadata`: `map` - *Opcional* - Metadados da mensagem.

#### Retorna

Um objeto [message](#the-message-object-beta).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms.",
      "attachments": [
         { "file_id": "file-123", "tools": [{"type": "code_interpreter"}] }
      ]
    }'
```

#### Resposta

```json
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null, // Null para mensagens criadas manualmente
  "thread_id": "thread_abc123",
  "run_id": null, // Null para mensagens criadas manualmente
  "role": "user",
  "content": [ // Conteúdo sempre é um array
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": [] // Preenchido pelo assistente se usar file_search/citation
      }
    }
    // Se fosse imagem: { "type": "image_url", "image_url": {"url": "...", "detail": "auto"}}
  ],
  "attachments": [ // Anexos especificados na requisição
     { "file_id": "file-123", "tools": [{"type": "code_interpreter"}] }
  ],
  "metadata": {},
  "status": "completed", // Status inicial para mensagens criadas manualmente
  "completed_at": 1713226573, // Timestamp de conclusão
  "incomplete_at": null,
  "incomplete_details": null
}
```

---

### Listar mensagens (Beta)

**GET** `/v1/threads/{thread_id}/messages`

Retorna uma lista de mensagens para uma determinada thread.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de mensagens a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).
*   `run_id`: `string` - *Opcional* - Filtrar mensagens pelo ID da run que as gerou.

#### Retorna

Uma lista de objetos [message](#the-message-object-beta).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    { // Mensagem mais recente (order=desc padrão)
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699016383,
      "assistant_id": "asst_xyz", // ID do assistente se role = assistant
      "thread_id": "thread_abc123",
      "run_id": "run_xyz", // ID da run que gerou esta mensagem
      "role": "assistant", // Exemplo de mensagem do assistente
      "content": [
        {
          "type": "text",
          "text": {
            "value": "AI stands for Artificial Intelligence...",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
      // status, completed_at etc. também presentes
    },
    { // Mensagem anterior
      "id": "msg_abc456",
      "object": "thread.message",
      "created_at": 1699016380, // Timestamp anterior
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hello, what is AI?",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

---

### Recuperar mensagem (Beta)

**GET** `/v1/threads/{thread_id}/messages/{message_id}`

Recupera uma mensagem.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `message_id`: `string` - **Obrigatório** - ID da mensagem.

#### Retorna

O objeto [message](#the-message-object-beta) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null, // Se for mensagem de usuário
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "attachments": [],
  "metadata": {},
  "status": "completed",
  "completed_at": 1699017614,
  "incomplete_at": null,
  "incomplete_details": null
}
```

---

### Modificar mensagem (Beta)

**POST** `/v1/threads/{thread_id}/messages/{message_id}`

Modifica uma mensagem. (Atualmente, apenas metadados podem ser modificados).

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `message_id`: `string` - **Obrigatório** - ID da mensagem.

#### Corpo da Requisição

*   `metadata`: `map` - *Opcional* - Metadados.

#### Retorna

O objeto [message](#the-message-object-beta) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

#### Resposta

```json
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [ /* ... */ ],
  // "file_ids": [], // Campo obsoleto, use `attachments`
  "attachments": [],
  "metadata": { // Metadados atualizados
    "modified": "true",
    "user": "abc123"
  },
  "status": "completed",
  "completed_at": 1699017614,
  "incomplete_at": null,
  "incomplete_details": null
}
```

---

### Excluir mensagem (Beta)

**DELETE** `/v1/threads/{thread_id}/messages/{message_id}`

Exclui uma mensagem.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `message_id`: `string` - **Obrigatório** - ID da mensagem.

#### Retorna

Status da exclusão.

#### Exemplo de Requisição

```bash
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

---

### O objeto Message (Beta)

Representa uma mensagem dentro de uma thread.

*   `assistant_id`: `string` ou `null` - ID do assistente autor (se aplicável).
*   `attachments`: `array` ou `null` - Lista de arquivos anexados e suas ferramentas.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `completed_at`: `integer` ou `null` - Timestamp Unix de conclusão.
*   `content`: `array` - Conteúdo da mensagem (texto e/ou imagens).
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `id`: `string` - Identificador.
*   `incomplete_at`: `integer` ou `null` - Timestamp Unix de marcação como incompleta.
*   `incomplete_details`: `object` ou `null` - Detalhes sobre incompletude.
    *   <details><summary>Mostrar propriedades</summary> (Propriedade `reason`)</details>
*   `metadata`: `map` - Metadados.
*   `object`: `string` - Tipo do objeto (`thread.message`).
*   `role`: `string` - Entidade produtora (`user` ou `assistant`).
*   `run_id`: `string` ou `null` - ID da run associada à criação (null se manual).
*   `status`: `string` - Status (`in_progress`, `incomplete`, `completed`).
*   `thread_id`: `string` - ID da thread à qual pertence.

#### Objeto Message Exemplo (Mensagem de Assistente)

```json
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "run_id": "run_abc123",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "Hi! How can I help you today?",
        "annotations": []
      }
    }
  ],
  "attachments": [],
  "metadata": {},
  "status": "completed",
  "completed_at": 1698983503,
  "incomplete_at": null,
  "incomplete_details": null
}
```

---

## Runs (Execuções) (Beta)

Representa uma execução (run) em uma thread.

**Guia relacionado:** [Assistants](https://platform.openai.com/docs/assistants/overview) (Especificamente sobre Runs)

### Criar run (Beta)

**POST** `/v1/threads/{thread_id}/runs`

Cria uma run.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread a ser executada.

#### Parâmetros de Consulta

*   `include[]`: `array` - *Opcional* - Campos adicionais a incluir. Atualmente, apenas `step_details.tool_calls[*].file_search.results[*].content`. [Saiba mais](https://platform.openai.com/docs/assistants/tools/file-search/how-it-works).

#### Corpo da Requisição

*   `assistant_id`: `string` - **Obrigatório** - ID do assistente a ser usado.
*   `additional_instructions`: `string` ou `null` - *Opcional* - Anexa instruções adicionais.
*   `additional_messages`: `array` ou `null` - *Opcional* - Adiciona mensagens antes de criar a run.
    *   <details><summary>Mostrar propriedades</summary> (Cada item é um objeto de mensagem)</details>
*   `instructions`: `string` ou `null` - *Opcional* - Sobrescreve as instruções do assistente.
*   `max_completion_tokens`: `integer` ou `null` - *Opcional* - Máximo de tokens de conclusão.
*   `max_prompt_tokens`: `integer` ou `null` - *Opcional* - Máximo de tokens de prompt.
*   `metadata`: `map` - *Opcional* - Metadados.
*   `model`: `string` - *Opcional* - Sobrescreve o modelo do assistente.
*   `parallel_tool_calls`: `boolean` - *Opcional* - **Padrão:** `true` - Habilita chamadas de função paralelas.
*   `reasoning_effort`: `string` ou `null` - *Opcional* - **Padrão:** `medium` - (*Apenas modelos da série o*) Restringe esforço de raciocínio.
*   `response_format`: `"auto"` ou `object` - *Opcional* - Especifica o formato de saída.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `stream`: `boolean` ou `null` - *Opcional* - Se `true`, retorna um stream de eventos.
*   `temperature`: `number` ou `null` - *Opcional* - **Padrão:** `1` - Temperatura de amostragem.
*   `tool_choice`: `string` ou `object` - *Opcional* - Controla qual ferramenta é chamada (`none`, `auto`, `required`, ou ferramenta específica).
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `tools`: `array` ou `null` - *Opcional* - Sobrescreve as ferramentas do assistente.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `top_p`: `number` ou `null` - *Opcional* - **Padrão:** `1` - Amostragem Nucleus.
*   `truncation_strategy`: `object` ou `null` - *Opcional* - Controla o truncamento da thread.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `type` (`auto`, `last_messages`), `last_messages` (integer))</details>

#### Retorna

Um objeto [run](#the-run-object-beta).

#### Exemplos

##### Exemplo: Padrão

```bash
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123",
    "max_prompt_tokens": 1000, // Exemplo com limites de token
    "max_completion_tokens": 1000
  }'
```

```json
# Resposta
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued", // Status inicial
  "started_at": null, // Preenchido quando inicia
  "expires_at": 1699063890, // Exemplo: criado_at + 10 minutos
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null, // Preenchido se precisar de tool outputs
  "last_error": null,
  "model": "gpt-4o", // Modelo do assistente
  "instructions": "Instruções do assistente...", // Instruções do assistente
  "incomplete_details": null,
  "tools": [ // Ferramentas do assistente
    {
      "type": "code_interpreter"
    }
  ],
  "tool_resources": {}, // Recursos da thread/assistente
  "metadata": {},
  "usage": null, // Preenchido na conclusão
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000, // Limite definido na requisição
  "max_completion_tokens": 1000, // Limite definido na requisição
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

> *(Nota: Exemplos para Streaming, Streaming with Functions não foram fornecidos no texto original, mas seriam colocados aqui se estivessem. Envolveria `stream: true` na requisição e uma resposta SSE.)*

---

### Criar thread e run (Beta)

**POST** `/v1/threads/runs`

Cria uma thread e a executa em uma única requisição.

#### Corpo da Requisição

*   `assistant_id`: `string` - **Obrigatório** - ID do assistente.
*   `instructions`: `string` ou `null` - *Opcional* - Sobrescreve instruções do assistente.
*   `max_completion_tokens`: `integer` ou `null` - *Opcional*
*   `max_prompt_tokens`: `integer` ou `null` - *Opcional*
*   `metadata`: `map` - *Opcional* - Metadados para a **run**.
*   `model`: `string` - *Opcional* - Sobrescreve modelo do assistente.
*   `parallel_tool_calls`: `boolean` - *Opcional* - **Padrão:** `true`
*   `response_format`: `"auto"` ou `object` - *Opcional*
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `stream`: `boolean` ou `null` - *Opcional* - Habilita streaming.
*   `temperature`: `number` ou `null` - *Opcional* - **Padrão:** `1`
*   `thread`: `object` - *Opcional* - Opções para criar a nova thread. Se omitido, cria thread vazia.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `messages`, `metadata`, `tool_resources` para a **thread**)</details>
*   `tool_choice`: `string` ou `object` - *Opcional*
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `tool_resources`: `object` ou `null` - *Opcional* - Recursos para as ferramentas **nesta run** (sobrescreve os da thread).
    *   <details><summary>Mostrar propriedades</summary></details>
*   `tools`: `array` ou `null` - *Opcional* - Sobrescreve ferramentas do assistente.
*   `top_p`: `number` ou `null` - *Opcional* - **Padrão:** `1`
*   `truncation_strategy`: `object` ou `null` - *Opcional* - Estratégia de truncamento.
    *   <details><summary>Mostrar propriedades</summary></details>

*(Descrições dos campos são as mesmas de Criar run)*

#### Retorna

Um objeto [run](#the-run-object-beta).

#### Exemplos

##### Exemplo: Padrão

```bash
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    }'
```

```json
# Resposta
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123", // ID da thread recém-criada
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.", // Instruções do assistente usado
  "tools": [], // Ferramentas do assistente
  "tool_resources": {}, // Recursos da thread/assistente
  "metadata": {}, // Metadata da run (vazio no exemplo)
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

> *(Nota: Exemplos para Streaming, Streaming with Functions não foram fornecidos no texto original.)*

---

### Listar runs (Beta)

**GET** `/v1/threads/{thread_id}/runs`

Retorna uma lista de runs pertencentes a uma thread.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de runs a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [run](#the-run-object-beta).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    { // Run mais recente
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null, // Nulo para runs concluídas
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null, // Pode ser as instruções da run ou do assistente
      "incomplete_details": null,
      "tools": [ /* ... */ ],
      "tool_resources": { /* ... */ },
      "metadata": {},
      "usage": { // Preenchido para runs concluídas
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      // ... outros parâmetros
    },
    { // Run anterior
      "id": "run_abc456",
      // ... detalhes da run anterior ...
    }
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

---

### Recuperar run (Beta)

**GET** `/v1/threads/{thread_id}/runs/{run_id}`

Recupera uma run.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run.

#### Retorna

O objeto [run](#the-run-object-beta) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "tool_resources": { /* ... */ },
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  // ... outros parâmetros
}
```

---

### Modificar run (Beta)

**POST** `/v1/threads/{thread_id}/runs/{run_id}`

Modifica uma run. (Atualmente, apenas metadados podem ser modificados).

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run.

#### Corpo da Requisição

*   `metadata`: `map` - *Opcional* - Metadados.

#### Retorna

O objeto [run](#the-run-object-beta) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

#### Resposta

```json
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  // ... outros campos ...
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ]
    }
  },
  "metadata": { // Metadados atualizados
    "user_id": "user_abc123"
  },
  "usage": { /* ... */ },
  // ... outros parâmetros
}
```

---

### Enviar saídas de ferramenta para run (Beta)

**POST** `/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs`

Quando uma run tem o status `requires_action` e `required_action.type` é `submit_tool_outputs`, este endpoint pode ser usado para enviar as saídas das chamadas de ferramenta assim que todas estiverem concluídas. Todas as saídas devem ser enviadas em uma única requisição.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run que requer a saída da ferramenta.

#### Corpo da Requisição

*   `tool_outputs`: `array` - **Obrigatório** - Uma lista de ferramentas para as quais as saídas estão sendo enviadas.
    *   <details><summary>Mostrar propriedades</summary> (Cada item tem `tool_call_id` e `output` (string))</details>
*   `stream`: `boolean` ou `null` - *Opcional* - Se `true`, retorna um stream de eventos.

#### Retorna

O objeto [run](#the-run-object-beta) modificado (ou um stream de eventos).

#### Exemplos

##### Exemplo: Padrão

```bash
curl -X POST https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [
      {
        "tool_call_id": "call_001",
        "output": "70 degrees and sunny."
      }
      // { "tool_call_id": "call_002", "output": "..." } // Se houver múltiplas chamadas
    ]
  }'
```

```json
# Resposta
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued", // Status volta para queued ou in_progress
  "started_at": 1699075592, // Pode ser atualizado
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null, // Não requer mais ação
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [ /* ... */ ],
  "metadata": {},
  "usage": null,
  // ... outros parâmetros
}
```

##### Exemplo: Streaming

> *(Nota: Exemplo para Streaming não foi fornecido, mas seria com `stream: true` e resposta SSE.)*

---

### Cancelar uma run (Beta)

**POST** `/v1/threads/{thread_id}/runs/{run_id}/cancel`

Cancela uma run que está `in_progress`.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run a cancelar.

#### Retorna

O objeto [run](#the-run-object-beta) modificado.

#### Exemplo de Requisição

```bash
curl -X POST https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling", // Status muda para cancelling, depois cancelled
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null, // Preenchido quando cancelado
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [ /* ... */ ],
  "tool_resources": { /* ... */ },
  "metadata": {},
  "usage": null,
  // ... outros parâmetros
}
```

---

### O objeto Run (Beta)

Representa uma execução (run) em uma thread.

*   `assistant_id`: `string` - ID do assistente usado.
*   `cancelled_at`: `integer` ou `null` - Timestamp Unix de cancelamento.
*   `completed_at`: `integer` ou `null` - Timestamp Unix de conclusão.
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `expires_at`: `integer` ou `null` - Timestamp Unix de expiração.
*   `failed_at`: `integer` ou `null` - Timestamp Unix de falha.
*   `id`: `string` - Identificador da run.
*   `incomplete_details`: `object` ou `null` - Detalhes sobre incompletude.
    *   <details><summary>Mostrar propriedades</summary> (Propriedade `reason`)</details>
*   `instructions`: `string` - Instruções usadas nesta run.
*   `last_error`: `object` ou `null` - Último erro associado.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `code`, `message`)</details>
*   `max_completion_tokens`: `integer` ou `null` - Máximo de tokens de conclusão usados.
*   `max_prompt_tokens`: `integer` ou `null` - Máximo de tokens de prompt usados.
*   `metadata`: `map` - Metadados.
*   `model`: `string` - Modelo usado.
*   `object`: `string` - Tipo do objeto (`thread.run`).
*   `parallel_tool_calls`: `boolean` - Se chamadas de função paralelas estão habilitadas.
*   `required_action`: `object` ou `null` - Ação necessária para continuar.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `type` (`submit_tool_outputs`), `submit_tool_outputs` (objeto com `tool_calls`))</details>
*   `response_format`: `"auto"` ou `object` - Formato de saída especificado.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `started_at`: `integer` ou `null` - Timestamp Unix de início.
*   `status`: `string` - Status (`queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, `expired`).
*   `temperature`: `number` ou `null` - Temperatura de amostragem usada.
*   `thread_id`: `string` - ID da thread executada.
*   `tool_choice`: `string` ou `object` - Controle de chamada de ferramenta.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `tools`: `array` - Lista de ferramentas usadas.
    *   <details><summary>Mostrar tipos possíveis</summary></details>
*   `top_p`: `number` ou `null` - Valor de amostragem Nucleus usado.
*   `truncation_strategy`: `object` ou `null` - Estratégia de truncamento usada.
    *   <details><summary>Mostrar propriedades</summary></details>
*   `usage`: `object` ou `null` - Estatísticas de uso (null se não terminal).
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `completion_tokens`, `prompt_tokens`, `total_tokens`)</details>

#### Objeto Run Exemplo (Concluído)

```json
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "Instruções originais do assistente...",
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "tool_resources": { /* ... */ },
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

---

## Run Steps (Passos da Run) (Beta)

Representa os passos (chamadas de modelo e ferramenta) tomados durante a run.

**Guia relacionado:** [Assistants](https://platform.openai.com/docs/assistants/overview) (Especificamente sobre Run Steps)

### Listar run steps (Beta)

**GET** `/v1/threads/{thread_id}/runs/{run_id}/steps`

Retorna uma lista de run steps pertencentes a uma run.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run.

#### Parâmetros de Consulta

*   `after`: `string` - *Opcional* - Cursor de paginação.
*   `before`: `string` - *Opcional* - Cursor de paginação.
*   `include[]`: `array` - *Opcional* - Campos adicionais a incluir (`step_details.tool_calls[*].file_search.results[*].content`).
*   `limit`: `integer` - *Opcional* - **Padrão:** `20` - Número de steps a retornar (1-100).
*   `order`: `string` - *Opcional* - **Padrão:** `desc` - Ordem de classificação por `created_at` (`asc` ou `desc`).

#### Retorna

Uma lista de objetos [run step](#the-run-step-object-beta).

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "object": "list",
  "data": [
    { // Step mais recente (order=desc)
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation", // Tipo do passo
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": { // Detalhes específicos do tipo
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123" // ID da mensagem criada
        }
      },
      "usage": { // Uso deste passo específico
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
       "metadata": {} // Adicionado para completude
    },
    { // Exemplo de step de tool_calls
      "id": "step_def456",
      "object": "thread.run.step",
      "created_at": 1699063290,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "tool_calls",
      "status": "completed", // ou in_progress se esperando output
      "cancelled_at": null,
      "completed_at": 1699063290,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "tool_calls",
        "tool_calls": [
          {
            "id": "call_xyz",
            "type": "code_interpreter",
            "code_interpreter": {
              "input": "print(1+1)",
              "outputs": [ // Pode estar vazio se 'in_progress'
                 {"type": "logs", "logs": "2"}
              ]
            }
          }
          // { "id": "call_uvw", "type": "file_search", "file_search": {}}
        ]
      },
      "usage": null, // Geralmente nulo para tool_calls
      "metadata": {}
    }
  ],
  "first_id": "step_abc123", // ID do primeiro na página
  "last_id": "step_def456", // ID do último na página (corrigido)
  "has_more": false
}
```

---

### Recuperar run step (Beta)

**GET** `/v1/threads/{thread_id}/runs/{run_id}/steps/{step_id}`

Recupera um run step.

#### Parâmetros de Caminho

*   `thread_id`: `string` - **Obrigatório** - ID da thread.
*   `run_id`: `string` - **Obrigatório** - ID da run.
*   `step_id`: `string` - **Obrigatório** - ID do step.

#### Parâmetros de Consulta

*   `include[]`: `array` - *Opcional* - Campos adicionais (`step_details.tool_calls[*].file_search.results[*].content`).

#### Retorna

O objeto [run step](#the-run-step-object-beta) correspondente ao ID especificado.

#### Exemplo de Requisição

```bash
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

#### Resposta

```json
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "metadata": {} // Adicionado para completude
}
```

---

### O objeto Run Step (Beta)

Representa um passo na execução de uma run.

*   `assistant_id`: `string` - ID do assistente associado.
*   `cancelled_at`: `integer` ou `null` - Timestamp Unix de cancelamento.
*   `completed_at`: `integer` ou `null` - Timestamp Unix de conclusão.
*   `created_at`: `integer` - Timestamp Unix de criação.
*   `expired_at`: `integer` ou `null` - Timestamp Unix de expiração.
*   `failed_at`: `integer` ou `null` - Timestamp Unix de falha.
*   `id`: `string` - Identificador do run step.
*   `last_error`: `object` ou `null` - Último erro associado.
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `code`, `message`)</details>
*   `metadata`: `map` - Metadados.
*   `object`: `string` - Tipo do objeto (`thread.run.step`).
*   `run_id`: `string` - ID da run pai.
*   `status`: `string` - Status (`in_progress`, `cancelled`, `failed`, `completed`, `expired`).
*   `step_details`: `object` - Detalhes do passo.
    *   <details><summary>Mostrar tipos possíveis</summary> (Objeto com `type` (`message_creation` ou `tool_calls`) e um objeto aninhado correspondente)</details>
*   `thread_id`: `string` - ID da thread.
*   `type`: `string` - Tipo do run step (`message_creation` ou `tool_calls`).
*   `usage`: `object` ou `null` - Estatísticas de uso (null se `in_progress`).
    *   <details><summary>Mostrar propriedades</summary> (Propriedades `completion_tokens`, `prompt_tokens`, `total_tokens`)</details>

#### Objeto Run Step Exemplo (Message Creation)

```json
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "metadata": {}
}
```

---

### Streaming (Assistants) (Beta)

Transmita o resultado da execução de uma Run ou da retomada de uma Run após enviar saídas de ferramenta. Você pode transmitir eventos dos endpoints Create Thread and Run, Create Run e Submit Tool Outputs passando `"stream": true`. A resposta será um stream de Server-Sent Events (SSE). Nossos SDKs Node e Python fornecem utilitários úteis para facilitar o streaming. Consulte o [quickstart da API Assistants](https://platform.openai.com/docs/assistants/overview/overview) para saber mais.

#### O objeto Message Delta (Beta)

Representa um delta de mensagem, ou seja, quaisquer campos alterados em uma mensagem durante o streaming.

*   `delta`: `object`
    *   O delta contendo os campos que mudaram na Mensagem.
    *   <details><summary>Mostrar propriedades</summary> (Geralmente contém `role` (apenas no primeiro delta) ou `content` (array com deltas de `text` ou `image_file`))</details>
*   `id`: `string` - Identificador da mensagem.
*   `object`: `string` - Tipo do objeto (`thread.message.delta`).

#### Objeto Message Delta Exemplo

```json
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [ // Sempre um array
      {
        "index": 0, // Índice da parte do conteúdo sendo atualizada
        "type": "text",
        "text": { "value": "Hello", "annotations": [] } // Delta do texto
      }
    ]
  }
}
```

#### O objeto Run Step Delta (Beta)

Representa um delta de run step, ou seja, quaisquer campos alterados em um run step durante o streaming.

*   `delta`: `object`
    *   O delta contendo os campos que mudaram no run step.
    *   <details><summary>Mostrar propriedades</summary> (Geralmente contém `step_details` com deltas para `message_creation` ou `tool_calls`)</details>
*   `id`: `string` - Identificador do run step.
*   `object`: `string` - Tipo do objeto (`thread.run.step.delta`).

#### Objeto Run Step Delta Exemplo (Tool Call)

```json
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls", // Tipo do detalhe
      "tool_calls": [ // Array de chamadas de ferramenta (pode ter deltas para múltiplas chamadas)
        {
          "index": 0, // Índice da chamada de ferramenta
          "id": "call_123", // ID da chamada (presente no primeiro delta)
          "type": "code_interpreter", // Tipo da ferramenta (presente no primeiro delta)
          "code_interpreter": { "input": "print", "outputs": [] } // Delta do input ou outputs
        }
      ]
    }
  }
}
```

---

### Eventos de Stream do Assistant (Beta)

Representa um evento emitido ao transmitir uma Run.

Cada evento em um stream SSE tem uma propriedade `event` e `data`:

```
event: thread.run.created
data: {"id": "run_123", "object": "thread.run", ...}
```

Eventos são emitidos sempre que um novo objeto é criado, transita para um novo estado, ou está sendo transmitido em partes (deltas).

**Tipos de Eventos:**

*   `done`: `data` é `[DONE]`. Ocorre quando um stream termina.
*   `error`: `data` é um [objeto de erro](#error). Ocorre quando um erro acontece.
*   `thread.created`: `data` é um [objeto thread](#the-thread-object-beta).
*   `thread.message.completed`: `data` é um [objeto message](#the-message-object-beta).
*   `thread.message.created`: `data` é um [objeto message](#the-message-object-beta).
*   `thread.message.delta`: `data` é um [objeto message delta](#the-message-delta-object-beta).
*   `thread.message.in_progress`: `data` é um [objeto message](#the-message-object-beta).
*   `thread.message.incomplete`: `data` é um [objeto message](#the-message-object-beta).
*   `thread.run.cancelled`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.cancelling`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.completed`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.created`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.expired`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.failed`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.in_progress`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.incomplete`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.queued`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.requires_action`: `data` é um [objeto run](#the-run-object-beta).
*   `thread.run.step.cancelled`: `data` é um [objeto run step](#the-run-step-object-beta).
*   `thread.run.step.completed`: `data` é um [objeto run step](#the-run-step-object-beta).
*   `thread.run.step.created`: `data` é um [objeto run step](#the-run-step-object-beta).
*   `thread.run.step.delta`: `data` é um [objeto run step delta

{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1741601000,
  "model": "gpt-3.5-turbo-instruct", // Corrigido do exemplo original
  "system_fingerprint": "fp_44709d6fcb", // Adicionado do exemplo original
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}